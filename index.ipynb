{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Max said he would grade this\n",
    "### Members: Eli Lichtblau, Muhammad Azlan, Asha Nur\n",
    "# Attempting Optimal grokking through singular value normalization\n",
    "\n",
    "## Introduction\n",
    "What is grokking? [Grokking](https://arxiv.org/pdf/2201.02177.pdf) is a curious phenomenon in neural networks. It in some sense spits in the face of classic understanding of training models. Rather than describe it, as they say, a picture is worth 1,000 words.\n",
    "\n",
    "</br>\n",
    "\n",
    "![](./grokking.png)\n",
    "\n",
    "Taken from the research paper linked earlier, grokking is the behavior observed on some simple problems that long past overfitting, models almost suddenly generalize. And by long past overfitting, in this example we mean *long* past, nearly 4 orders of magnitude!\n",
    "\n",
    "## Its not actually that bad!\n",
    "Okay, so 4 orders of magnitude seem completely untenable, but this was the worst case described in the paper. Lets talk about the problem discussed in the paper a bit.\n",
    "</br>\n",
    "\n",
    "### So what is the problem described in the paper? What does the paper do?\n",
    "### The problem (simplified)\n",
    "Modular division </br>\n",
    "* Choose some prime $P$, the paper chose $P=97$\n",
    "* Generate all equations of the form $a+b \\equiv c$ (mod $P)$\n",
    "    * $a,b,c \\in \\mathbb{Z}^{0\\leq P}$\n",
    "* This will generate $N_{data} = P*P$ equations\n",
    "    * Split the data into training and validating\n",
    "* Train a standard TransformerDecoder of the following structure\n",
    "    * Embedding layer with positional encoding (functionally an encoder)\n",
    "    * 2 Layers\n",
    "        * width 128\n",
    "        * 4 attention heads\n",
    "* With an Adam optimizer having parameters\n",
    "    * learning rate $10^{-3}$\n",
    "    * weight decay $10^{-2}$ - they said 1, but pretty sure they meant $1e-2$... 1 is insane\n",
    "    * $B_1 = 0.9$, $B_2=0.98$\n",
    "\n",
    "## The problem actually described in the paper\n",
    "The problem described above is a lemma of what the paper actually does. This section is not required to understand anything we did, but we would be remiss if we did not talk about the finer details of the paper. </br>\n",
    "* Not just modular division\n",
    "    * $a \\circ b \\equiv c$(mod $P$) \n",
    "    * For the following ops\n",
    "        *  $a \\circ b$ $ = a + b$ (mod $P$) for $0 \\leq a,b \\le P$\n",
    "        *  $a \\circ b$ $ = a- b$ (mod $P$) for $0 \\leq a,b \\le P$\n",
    "        *  $a \\circ b$ $ = [a/b$ (mod $P$) for $0 \\leq a \\le P$, $0 \\le b \\le P$\n",
    "        *  $a \\circ b$ $ = [a/b$ (mod $P$) if $b$ is odd, otherwise $a-b$ (mod $P$)] for $0 \\leq a,b \\le P$\n",
    "        *  $a \\circ b$ $ = a^2 + b^2$ (mod $P$) for $0 \\leq a,b \\le P$\n",
    "        *  $a \\circ b$ $ = a^2 + ab + b^2$ (mod $P$) for $0 \\leq a,b \\le P$\n",
    "        *  $a \\circ b$ $ = a^2 + ab + b^2 + a$ (mod $P$) for $0 \\leq a,b \\le P$\n",
    "        *  $a \\circ b$ $ = a^3 + ab$ (mod $P$) for $0 \\leq a,b \\le P$\n",
    "        *  $a \\circ b$ $ = a^3 + ab^2 + b$ (mod $P$) for $0 \\leq a,b \\le P$\n",
    "        *  $a \\circ b$ $ = a * b$ for $a,b \\in \\mathbb{S}^5$\n",
    "        *  $a \\circ b$ $ = a * b * a^{-1}$ for $a,b \\in \\mathbb{S}^5$\n",
    "        *  $a \\circ b$ $ = a * b * a$ for $a,b \\in \\mathbb{S}^5$\n",
    "* This means every input was 5 tokens\n",
    "    * \"a\", \"op\", \"b\", \"=\", \"c\"\n",
    "* Generate all equations of this form for some specific op\n",
    "* Convert the 5 char arrays to 5 int arrays\n",
    "* Split the data as before\n",
    "* The transformer structure is unchanged\n",
    "* They used a variety of optimization techniques and hyperparameter tuning\n",
    "    * Minibatching and full batching\n",
    "    * 10 warm up updates of mini batch size $[512, \\frac{N_{trainingData}}{2}]$\n",
    "    * optimization budget of $10^5$ gradient updates - I read this as steps.\n",
    "    * learning rate $3e-4$, $3e-3$\n",
    "    * weight decay same as before\n",
    "    * Gaussian noise on weights\n",
    "    * residual dropout 0.1\n",
    "* They also put outliers in the dataset to see how this effected grokking\n",
    "\n",
    "Importantly this reperesents a more full scope of what the study did. </br>\n",
    "For our purposes we will just take some of their better presets as a base model.\n",
    "\n",
    "## Results figure\n",
    "![](./grokkingResults.png)\n",
    "* Yes this is the worst graph in terms of labeling ever\n",
    "* No the figure explanation does not help\n",
    "* Below we talk about the key findings of the paper mostly ignoring this graph\n",
    "\n",
    "## Key Results\n",
    "* Adam is seemingly very important to grokking, at least momentum optimizers\n",
    "* Grokking didn't happen until the singular values of weights became small\n",
    "* Minibatching is superior\n",
    "* Weight decay is *extremely* *extremely* important\n",
    "* They didn't give precise results as far as We could tell\n",
    "    * No statement that is this problem, this training data split, N optimization steps to train, M optimizations steps to grok\n",
    "    * There exists some parameters such that grokking happens within an order of magnitude\n",
    "\n",
    "\n",
    "\n",
    "## What we took from this as our base model\n",
    "* The transformer model with dropout\n",
    "* Adam optimizer \n",
    "    * $lr = 3e-4$\n",
    "    * $weightDecay = 1e-2$\n",
    "    * $B_1 = 0.9$, $B_2=0.98$\n",
    "* Full batch training\n",
    "\n",
    "Essentially this represented their best presets minus minibatching which preformed significantly better in their training. \n",
    "\n",
    "\n",
    "\n",
    "### Why didn't we do minibatching?\n",
    "* Initally there was a plan to test the TrueGrad Adam implementation from below\n",
    "    * The implementation is currently broken and do the scope of the singular value implementation we did not have time to implement it\n",
    "    * Unfortunately do to compute time we are in some sense tied to this full batch training\n",
    "    * We chose it for the following reasons below\n",
    "* We believe on intuition that TrueGrad Adam should be much more stable\n",
    "* The best way to show this is to use the \"worst\" case for the optimizer\n",
    "* Still good presets for Adam, but a hard situation\n",
    "\n",
    "\n",
    "### What we did\n",
    "* Below we will reimplement the paper but to set a scene for later - what are we trying to do?\n",
    "* The paper noted grokking did not happen until the singular values of the weight matrices became small\n",
    "* We will implement weight matrices with a householder trick which allows us to enforce precise rules on the singular values directly. \n",
    "* We first explore this implementation on mnist and then try to use it on the problem described in the paper\n",
    "\n",
    "\n",
    "## Paper re-Implementation\n",
    "* Before we can add anything to the research we must first reimplement the paper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used libraries for complete implementation\n",
    "* [pytorch](https://github.com/pytorch/pytorch)\n",
    "* [Tensorflow](https://github.com/tensorflow/tensorflow) (Just for mnist dataset)\n",
    "* [numpy](https://github.com/numpy/numpy)\n",
    "* [TrueGrad](https://github.com/ClashLuke/TrueGrad)\n",
    "* [fasth](https://github.com/AlexanderMath/fasth)\n",
    "* [pandas](https://github.com/pandas-dev/pandas)\n",
    "* [matplotlib](https://matplotlib.org/)\n",
    "#### All neccessary imports for paper re-implementation and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn import Parameter\n",
    "from typing import Optional, List, Tuple\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preset parameters from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 97\n",
    "DEVICE = \"cuda\"\n",
    "D_MODEL = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation\n",
    "\n",
    "Unlike the paper we generate the smaller verison so. So our data looks as follows\n",
    "* $x \\in x_{train}$ x = \\[10, 17, 0\\]\n",
    "* corresponding y = \\[10, 17, (10 + 17) % p \\]\n",
    "* Essentially x is just y without the answer\n",
    "We split the data into training and validation to the specified amount of training data.\n",
    "* $x_{train}, y_{train}$ are shape (n_training_data, 3)\n",
    "* $x_{test}, y_{test}$ are shape ($P*P$ - n_training_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(n_training_data: int, p: int, device: str = \"cuda\"):\n",
    "    # generate all possible equations for mod p\n",
    "    all_data = []\n",
    "    for i in range(p):\n",
    "        for j in range(p):\n",
    "           all_data.append([i,j,(i+j)%p])\n",
    "    \n",
    "    all_data = np.array(all_data)\n",
    "    indices = np.random.permutation(all_data.shape[0])\n",
    "    train_indices = indices[:n_training_data]\n",
    "    valid_indices = indices[n_training_data:]\n",
    "    \n",
    "    input_seq: np.ndarray = all_data.copy()\n",
    "    output_seq = input_seq.copy()\n",
    "    input_seq[:, -1] = 0 # don't include answers\n",
    "\n",
    "    train_x = torch.tensor(input_seq[train_indices]).long().to(device)\n",
    "    train_y = torch.tensor(output_seq[train_indices]).long().to(device)\n",
    "    valid_x = torch.tensor(input_seq[valid_indices]).long().to(device)\n",
    "    valid_y = torch.tensor(output_seq[valid_indices]).long().to(device)\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The embedding layer\n",
    "Pytorch doesn't seem to have an embedding with position encoding built in yet. It might seem overkill to implement but transformers are permutation invariant which on a symmetric problem might give us an unfair advantage.\n",
    "\n",
    "Our implementation is standard or positional encoding - we used the [following](https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/) as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingWithPE(torch.nn.Embedding):\n",
    "    def __init__(self, num_embeddings: int, embedding_dim: int, seq_len: int, N: int= 10_000,\n",
    "            padding_idx: Optional[int] = None, max_norm: Optional[float] = None,\n",
    "            norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool=False,\n",
    "            device: Optional[torch.device] = None, dtype: Optional[torch.dtype] = None\n",
    "        ):\n",
    "        super().__init__(\n",
    "            num_embeddings, embedding_dim, padding_idx, max_norm, norm_type,\n",
    "            scale_grad_by_freq, sparse, device, dtype\n",
    "        )\n",
    "       \n",
    "        pe = torch.zeros((seq_len, embedding_dim))\n",
    "        buf = torch.arange(embedding_dim//2)\n",
    "        denom = torch.pow(N, (2*buf)/embedding_dim)\n",
    "        k = torch.arange(seq_len)\n",
    "        pe[k, ::2] = torch.sin(k.unsqueeze(1)/denom)\n",
    "        pe[k, 1::2] = torch.cos(k.unsqueeze(1)/denom)\n",
    "        # pe should not be a learnable parameter, a buffer not a parameter\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "             \n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return F.embedding(\n",
    "            x, self.weight, self.padding_idx, self.max_norm,\n",
    "            self.norm_type, self.scale_grad_by_freq, self.sparse) + self.pe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Transformer Model\n",
    "Won't rehash the copying of the paper but will mention a few important things.\n",
    "The paper stipulated a standard decoder so this is what we built, this includes masking and layernorms.\n",
    "\n",
    "Also important is a decoder of width N will have an output layer with N neurons. We are classifying a number that is at most P which is num_embeddings. So we add a layer such that the final layer has num_embedding $P$ outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self, seq_length: int, num_embeddings: int, d_model: int, dim_feedforward: int = 2048):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embed = EmbeddingWithPE(\n",
    "            self.num_embeddings, self.d_model, seq_length)\n",
    "\n",
    "        decoder_layer = torch.nn.TransformerDecoderLayer(self.d_model, nhead=4, dim_feedforward=dim_feedforward,\n",
    "                                        dropout=0.1, batch_first=True, norm_first=True)\n",
    "        decoder_norm = torch.nn.LayerNorm(self.d_model)\n",
    "\n",
    "        self.decoder = torch.nn.TransformerDecoder(\n",
    "            decoder_layer, num_layers=2, norm=decoder_norm)\n",
    "        self.linear = torch.nn.Linear(\n",
    "            self.d_model, self.num_embeddings, bias=False)\n",
    "        self.mask = Parameter(\n",
    "            torch.ones([seq_length, seq_length]).tril())\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.embed(x)\n",
    "        x = self.decoder.forward(x, torch.zeros_like(x), self.mask)\n",
    "        return self.linear(x)\n",
    "\n",
    "    def acc(self, prediction: Tensor, labels: Tensor):\n",
    "        return (torch.argmax(prediction, dim=-2) == labels).float().mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "Here we write a simple training loop to do full batch training of the model. We record the training losses and accuracie as well as the validation losses and accuracies. \n",
    "\n",
    "We use cross entropy because always use cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_train(\n",
    "    model: Transformer,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    train_x: Tensor,\n",
    "    train_y: Tensor, \n",
    "    valid_x: Tensor, \n",
    "    valid_y: Tensor,\n",
    "    epochs: int = 10_000,\n",
    "    quiet: bool = False\n",
    ") -> Tuple[ Tuple[List[Tensor], List[Tensor]],  Tuple[List[Tensor], List[Tensor]]  ]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Simple training method, does full batch training on transformer model\n",
    "    returns (train_accs, train_losses), (valid_accs, valid_losses) \n",
    "    where each list is length epochs\n",
    "    \"\"\"\n",
    "\n",
    "    model.zero_grad()\n",
    "    train_losses: List[Tensor] = []\n",
    "    train_accs: List[Tensor] = []\n",
    "    validation_losses: List[Tensor] = []\n",
    "    validation_accs: List[Tensor] = []\n",
    "    for i in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(train_x)\n",
    "        print(output.shape)\n",
    "        # model.forward shape is (n_inputs, 3, 97)\n",
    "        # transpose to (n_inputs, 97, 3)\n",
    "        pred = output.transpose(-2, -1)\n",
    "        # -1: to not drop the dim\n",
    "        pred = pred[..., -1:] \n",
    "        label = train_y[:, -1:]\n",
    "\n",
    "        loss = F.cross_entropy(pred, label)\n",
    "        acc = model.acc(pred, label)\n",
    "        \n",
    "        # keep track of losses\n",
    "        train_accs.append(acc.item())\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred_valid = model.forward(valid_x).transpose(-2, -1)[..., -1:]\n",
    "            label_valid = valid_y[:, -1:]\n",
    "            valid_loss = F.cross_entropy(pred_valid, label_valid)\n",
    "            valid_acc = model.acc(pred_valid, label_valid)\n",
    "            validation_accs.append(valid_acc.item())\n",
    "            validation_losses.append(valid_loss.item())\n",
    "        if i % 100 == 0 and not quiet:\n",
    "            print(f\"Epoch {i}: loss {loss.item():e}, training_accuracy {acc}, valid_acc {valid_acc:4f}, valid_loss: {valid_loss:4f}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return (train_accs, train_losses), (validation_accs, validation_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model on a variety of parameters\n",
    "\n",
    "We want to generate an amount of results to compare so we do grid search on the following parameters.\n",
    "* N_epochs = 15,000\n",
    "* n_training_data = 800 + 100k $k \\in \\mathbb{Z}^{0 \\le 12}$\n",
    "* d_model = \\[64, 128, 256\\]\n",
    "* dim_feedforward = \\[256, 512, 1024, 2048\\]\n",
    "</br>\n",
    "\n",
    "This took 1.5 *days* of compute on an rtx 2060 12GB.\n",
    "We save all fully trained models to do later analysis on their singular values as well the train and validation losses and accuracies.\n",
    "\n",
    "The naming scheme for the saved files is\n",
    "* .csv or .model depending on if its the model state dict or the training accuracies losses etcetera\n",
    "* \\<n_training_data\\>_\\<d_model\\>_\\<dim_feedforward\\>\n",
    "* To not confuse anyone from earlier d_model is the same as width from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of not running this biaccident we put this behind a function\n",
    "def DO_NOT_RUN():\n",
    "    for n_training_data in range(800, 2001, 100):\n",
    "        # For consistency training data must be the same for the models of different params\n",
    "        (train_x, train_y), (valid_x, valid_y) = gen_data(n_training_data, P, device=DEVICE)\n",
    "\n",
    "        for d_model in [64, 128, 256]:\n",
    "            for dim_feedforward in [256, 512, 1024, 2048]:\n",
    "                model = Transformer(train_x.size(-1), P, d_model, dim_feedforward=dim_feedforward).to(DEVICE)\n",
    "\n",
    "                optimizer = torch.optim.Adam(\n",
    "                    model.parameters(),\n",
    "                    lr=3e-4,\n",
    "                    betas=[.9, .98],\n",
    "                    weight_decay=1e-2,\n",
    "                    eps=1e-8,\n",
    "                    amsgrad=False,\n",
    "                )\n",
    "                print(f\"Training model: n_train_data: {n_training_data}, d_model: {d_model} dim_feedforward: {dim_feedforward} \")\n",
    "                (acc, loss), (valid_acc, valid_loss) = simple_train(model, optimizer, train_x, train_y, valid_x, valid_y, quiet=False,epochs=15_000)\n",
    "                df_cols = [\"Training Accuracy\", \"Training Loss\", \"Validation Accuracy\", \"Validation Loss\"]\n",
    "                df = pd.DataFrame(list(zip(acc, loss, valid_acc, valid_loss)), columns=df_cols)\n",
    "                df.to_csv(f\"output/{n_training_data}_{d_model}_{dim_feedforward}.csv\")\n",
    "                torch.save(model.state_dict(), f\"output/{n_training_data}_{d_model}_{dim_feedforward}.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of accuracies\n",
    "\n",
    "First lets make a series plots as follows where <> denotes an immutable parameter\n",
    "* (training_data, \\<d_model=64\\>, dim_feedforward)\n",
    "* (training_data, \\<d_model=128\\>, dim_feedforward)\n",
    "* (training_data, \\<d_model=256\\>, dim_feedforward)\n",
    "\n",
    "So each set of plots is 13 by 4 and we can visually examine them before doing any statisical testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-02997fcc6aab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcount\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(fullPath)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msubplots\u001b[0;34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     \"\"\"\n\u001b[1;32m   1442\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfig_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m     axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,\n\u001b[0m\u001b[1;32m   1444\u001b[0m                        \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplot_kw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubplot_kw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m                        \u001b[0mgridspec_kw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgridspec_kw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight_ratios\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheight_ratios\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msubplots\u001b[0;34m(self, nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_gridspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgridspec_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         axs = gs.subplots(sharex=sharex, sharey=sharey, squeeze=squeeze,\n\u001b[0m\u001b[1;32m    895\u001b[0m                           subplot_kw=subplot_kw)\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/gridspec.py\u001b[0m in \u001b[0;36msubplots\u001b[0;34m(self, sharex, sharey, squeeze, subplot_kw)\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0msubplot_kw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sharex\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_with\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msharex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0msubplot_kw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sharey\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_with\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msharey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                 axarr[row, col] = figure.add_subplot(\n\u001b[0m\u001b[1;32m    309\u001b[0m                     self[row, col], **subplot_kw)\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m             projection_class, pkw = self._process_projection_requirements(\n\u001b[1;32m    744\u001b[0m                 *args, **kwargs)\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_axes_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/axes/_subplots.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \"\"\"\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# _axes_class is set in the subplot_class_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axes_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m# This will also update the axes position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_subplotspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSubplotSpec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_subplot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, rect, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, **kwargs)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterization_zorder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;31m# funcs used to format x and y - fall back on major formatters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mclear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__clear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__clear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis_on\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_clip_path\u001b[0;34m(self, clippath, transform)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclippath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclippath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminorTicks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m             \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclippath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, instance, cls)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminorTicks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m                 \u001b[0mtick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminorTicks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminorTicks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick\u001b[0;34m(self, major)\u001b[0m\n\u001b[1;32m   1481\u001b[0m                 \"_tick_class or reimplement _get_tick()\")\n\u001b[1;32m   1482\u001b[0m         \u001b[0mtick_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_major_tick_kw\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmajor\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minor_tick_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tick_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtick_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_tick_label_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0;31m# x in data coords, y in axes coords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, axes, loc, size, width, color, tickdir, pad, labelsize, labelcolor, zorder, gridOn, tick1On, tick2On, label1On, label2On, major, labelrotation, grid_color, grid_linestyle, grid_linewidth, grid_alpha, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpolation_steps\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mGRIDLINE_INTERPOLATION_STEPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         self.label1 = mtext.Text(\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabelsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabelcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel1On\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Don't modify *func*'s signature, as boilerplate.py needs it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, text, color, verticalalignment, horizontalalignment, multialignment, fontproperties, rotation, linespacing, rotation_mode, usetex, wrap, transform_rotates_text, parse_math, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         self.set_color(\n\u001b[1;32m    169\u001b[0m             color if color is not None else mpl.rcParams[\"text.color\"])\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_fontproperties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfontproperties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_usetex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musetex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         self.set_parse_math(parse_math if parse_math is not None else\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mset_fontproperties\u001b[0;34m(self, fp)\u001b[0m\n\u001b[1;32m   1278\u001b[0m             \u001b[0mabsolute\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfont\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \"\"\"\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFontProperties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36m_from_any\u001b[0;34m(cls, arg)\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, family, style, variant, weight, stretch, size, fname, math_fontfamily)\u001b[0m\n\u001b[1;32m    680\u001b[0m                  math_fontfamily=None):\n\u001b[1;32m    681\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_family\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_variant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36mset_style\u001b[0;34m(self, style)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstyle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0mstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'font.style'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m         \u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_in_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'normal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'italic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oblique'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cmsc/lib/python3.8/site-packages/matplotlib/_api/__init__.py\u001b[0m in \u001b[0;36mcheck_in_list\u001b[0;34m(_values, _print_supported_values, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{val!r} is not a valid value for {key}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_print_supported_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 43 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataDir = Path(\"./output\")\n",
    "count=0\n",
    "for fname in sorted(os.listdir(dataDir)):\n",
    "    if fname.endswith(\"model\"):\n",
    "        continue\n",
    "    fullPath = dataDir/Path(fname)\n",
    "    count+=1\n",
    "    #print(fullPath)\n",
    "fig, ax = plt.subplots(4, 13)\n",
    "for row in range(4):\n",
    "    for col in range(13):\n",
    "        csvName = f\"output/{int(800+col*100)}_64_{int(2**row * 256)}.csv\"\n",
    "        plt.setp(ax[row][col].get_xticklabels(), visible=False)\n",
    "        if col != 0:\n",
    "            plt.setp(ax[row][col].get_yticklabels(), visible=False)\n",
    "        df = pd.read_csv(csvName)\n",
    "fig.set_size_inches(28, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So we have a base model \n",
    "* Roughly matches the paper\n",
    "* Can we do better?\n",
    "\n",
    "### We mentioned rules on singular values\n",
    "* Enforcing rules on the singular values\n",
    "* (As mentioned we do not have time to explore TrueGrad Adam but we think its very worthwhile for a future study!)\n",
    "\n",
    "### Lets explore singular values\n",
    "* Relevant to the paper was that the model didn't seem to \"grok\" until the singular values became small\n",
    "* Can we enforce this somehow?\n",
    "    * Is this idea new?\n",
    "    * No idea is new...\n",
    "\n",
    "### Relevant lit.\n",
    "\n",
    "#### Paper 1\n",
    "* This [paper](https://arxiv.org/pdf/1611.06013.pdf) put a hard bound on singular values keeping them near 1\n",
    "    * This preformed reasonably well \n",
    "    * But they have a problem! They have to somewhat regularly compute an svd composition to enforce the rules on their weight matrix!\n",
    "        * This is extremely expensive!\n",
    "\n",
    "#### Paper 2\n",
    "* Another [paper](https://www.microsoft.com/en-us/research/wp-content/uploads/2013/01/svd_v2.pdf) use the svd to improve sparcity for generalization\n",
    "    * This is (no pun) in some sense orthogonal to what we are doing, but an easily transferable task worth mentioning\n",
    "* There actually isn't a ton of relevant literature on enforcing singular values (although there is a lot of research on orthogonal matrices and CNN's)\n",
    "    * Why is this though?\n",
    "    * We like to believe it is because methods involved computing the svd of the weights\n",
    "    * this is prohibitively expensive\n",
    "\n",
    "\n",
    "#### Paper 3\n",
    "* But there is one very interesting paper!\n",
    "* This beautiful [paper](https://arxiv.org/pdf/2009.13977.pdf) which recieved a neurips spotlight proposed SVD neural networks\n",
    "* Essentially they represented each weight as its SVD decompositions ($U$, $S$, $V$) and trained them\n",
    "    * This would be nice... but U and V must be orthogonal for this to make any sense\n",
    "        * Regularization on gradient descent isn't enough!\n",
    "        * We need math!\n",
    "    * They represent $U$ and $V$ as a product of house holder matrices!\n",
    "        * A householder matrix is a special orthogonal matrix which *stays orthogonal on gradient descent!!!!*\n",
    "        * Limitations\n",
    "            * $U$ $S$ $V$ doesn't necessarily span the most useful space when $U$ and $V$ must be householder matrices\n",
    "        * Solution!\n",
    "            * Any orthogonal matrix $A \\in R^{(N, N)}$ can be represented by $N$ house holder matrices\n",
    "        * Limitation of solution\n",
    "            * Oh my god that turns the first layer of mnist into a minium of 784 matrix multiplications\n",
    "        * They wrote the library mentioned at the top [fasth](https://github.com/AlexanderMath/fasth) which does the math much faster\n",
    "        * Still not ideal\n",
    "### Proposed ideas\n",
    "* Okay we have some reasons to believe we might be able to accomplish the task\n",
    "    * This looks like enforcing some \"smallness\" rules on our singular values\n",
    "* Lets implement some layers and test on mnist\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using householder matrices on mnist\n",
    "* Mnist is great because its very learnable\n",
    "#### Key limitation of householder\n",
    "* You can *not* use momentum optimizers\n",
    "* Householder matrices hold their properties on $SGD$ but non linear operators on the gradient break the properties\n",
    "#### Householder defintion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def householder(vector: Tensor):\n",
    "    # assert column vector, just a good sanity check\n",
    "    assert vector.shape[1] == 1\n",
    "    assert len(vector.shape) == 2\n",
    "    I = torch.eye(vector.shape[0])\n",
    "    return I - 2*vector@vector.T/(vector.T@vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of Necessary classes\n",
    "* Essentially we want a linear layer that stores the singular values\n",
    "* It's useful to abstract the house holder matrices to modules\n",
    "    * We can vary the number of house holder matrices later\n",
    "#### Glossed over but non square weight matrices are annoying\n",
    "* Defined as follows $W \\in R^{(N, M)}$\n",
    "    * $U \\in R^{(N, N)}$, $S \\in R^{(N, M)}$, $M \\in R^{(M, M)}$\n",
    "\n",
    "#### What the hell is setHouseOrthNHouseHolders!!!\n",
    "* Why I'm glad you asked\n",
    "* For reasons well beyond me I can't properly segment the parameters when using a parameter list\n",
    "* So I write a function that outputs the houseOrth as a string with the right number of parameters\n",
    "* We can then call exec on that object to set the number of householder matrices\n",
    "* I'm as upset as you are about this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.nn import init\n",
    "#from torch import device, dtype\n",
    "# A major todo is to verify this preserves the singular values \n",
    "# It doesn't really change the \"hardness\" of the problem\n",
    "# But my math ability is questionable\n",
    "# V @ (S.T @ (U @ x.T))#\n",
    "class HouseOrth(torch.nn.Module):\n",
    "    def __init__(self, N: int, device=None, dtype=None):\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        # random initialization... this could be improved\n",
    "        self.U = Parameter(householder(torch.empty(N,1, **factory_kwargs).uniform_(-1/math.sqrt(N), 1/math.sqrt(N))))\n",
    "        \n",
    "    def forward(self, x: Tensor):\n",
    "        \n",
    "        return self.U @ x.T\n",
    "\n",
    "def setHouseOrthNHouseHolders(n_householders):\n",
    "    \"\"\"\n",
    "    Father forgive me for I hath sinned\n",
    "    \"\"\"\n",
    "    u = [f\"\\t\\tself.U{i} = Parameter(householder(torch.empty(N,1, **factory_kwargs).uniform_(-1/math.sqrt(N), 1/math.sqrt(N))))\" for i in range(n_householders)]\n",
    "    u = '\\n'.join(u)\n",
    "    u = u.replace(\"\\t\", \" \"*4)\n",
    "    def helper(i):\n",
    "        if i == 0:\n",
    "            return \"self.U0 @ x.T\"\n",
    "        return f\"self.U{i} @ ({helper(i-1)})\"\n",
    "    \n",
    "\n",
    "    s = f\"\"\"\n",
    "class HouseOrth(torch.nn.Module):\n",
    "    def __init__(self, N: int, device=None, dtype=None):\n",
    "        factory_kwargs = {{'device': device, 'dtype': dtype}}\n",
    "        super().__init__()\n",
    "        # random initialization... this could be improved\n",
    "{u}\n",
    "    def forward(self, x: Tensor):\n",
    "        \n",
    "        return {helper(n_householders-1)}\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "class LinearSVD(torch.nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True, device=None, dtype=None):\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        N,M = in_features, out_features\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.U = HouseOrth(N, **factory_kwargs)\n",
    "        # we normalize the singular values in the multiplication - smart initialization probably doesn't matter too much\n",
    "        # and if it does we do not know what that would be\n",
    "        self.singulars = Parameter(torch.empty(M, **factory_kwargs).uniform_(-1/math.sqrt(out_features), 1/math.sqrt(in_features)))\n",
    "        self.register_buffer(\"S\", torch.eye(N,M, **factory_kwargs)) # singulars are trainable - the matrix isn't (only the diagonal are parameters)\n",
    "        self.V = HouseOrth(M, **factory_kwargs) # Whether or not this is transposed doesn't really matter - its valid either way just a diff matrix\n",
    "        # copy torch.nn.Linear for what its worth here\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty((out_features,), **factory_kwargs) )\n",
    "            #step = self.U()\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.V(self.U( (self.singulars*self.S).T)))\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        if self.bias is not None:\n",
    "            return self.V( ((self.singulars/self.singulars.norm() * self.S).T @ self.U(x)).T ).T + self.bias\n",
    "        else:\n",
    "            return self.V( ((self.singulars/self.singulars.norm() * self.S).T @ self.U(x)).T ).T \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test how well this learns on minibatch mnist\n",
    "* Use simple linear model\n",
    "* We do minibatching for stability reasons, just makes our lives easier given slow runtime\n",
    "* The models are farily usntable due in part to the terrible initialization policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.datasets.mnist as mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = torch.tensor(x_train).cuda().reshape(x_train.shape[0], math.prod(x_train.shape[1:])).float() #/ 255 # normalize b/c uh this is prolly smart?\n",
    "y_train = torch.tensor(y_train).cuda()\n",
    "\n",
    "x_test = torch.tensor(x_test).cuda().reshape(x_test.shape[0], math.prod(x_test.shape[1:])).float()\n",
    "y_test = torch.tensor(y_test).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, useSVD=True):\n",
    "        super().__init__()\n",
    "        if useSVD:\n",
    "            Linear = LinearSVD\n",
    "        else:\n",
    "            Linear = torch.nn.Linear\n",
    "        self.fc1 = Linear(784, 128)\n",
    "        self.fc2 = Linear(128, 128)\n",
    "        self.fc3 = Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x: Tensor):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.softmax(self.fc3(x), -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare linearSVD with Linear\n",
    "* We cannot use Adam on HouseOrth\n",
    "* We can on singulars\n",
    "    * So we write a helper function which returns two optimizers one for the householder matrices which SGD and another which is Adam for all other parameters\n",
    "* We do not care about generalization on mnist\n",
    "    * Only inspecting training accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentHouseHolderParameters(model: torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Returns tuple[0] = HouseParameters for SGD optimizer \n",
    "    tuple[1] = All other Parameters for Adam\n",
    "    \"\"\"\n",
    "    houseParams: List[Parameter] = []\n",
    "    otherParams: List[Parameter] = []\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, HouseOrth):\n",
    "            for p in module.parameters(False): houseParams.append(p) \n",
    "        else:\n",
    "            for p in module.parameters(False): otherParams.append(p)\n",
    "    return houseParams, otherParams\n",
    "\n",
    "def getOptimizers(model: torch.nn.Module, betas=[.9, .98], weight_decay=0):\n",
    "    \"\"\"\n",
    "    Optimizers get unhappy when you give them an empty list, so we don't do that\n",
    "    Just an abstraction to avoid rewriting a lot of code\n",
    "    \"\"\"\n",
    "    hParams, nParams = segmentHouseHolderParameters(model)\n",
    "    optimizers: List[torch.optim.Optimizer] = []\n",
    "    if len(hParams) != 0:\n",
    "        optimizers.append(torch.optim.SGD(hParams, lr=3e-3))\n",
    "    if len(nParams) != 0:\n",
    "        optimizers.append(torch.optim.Adam(nParams, lr=3e-4, betas=betas, weight_decay=weight_decay))\n",
    "    return optimizers \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatchTrain(model: torch.nn.Module, optimizers: List[torch.optim.Optimizer], epochs: int = 100, batch_size: int = 1000) -> List[Tensor]:\n",
    "    \"\"\"\n",
    "    Train the model, return list of accuracies\n",
    "    the optimizers are a list because we want to be able to use different optimizers\n",
    "    on different parameters in the network. \n",
    "\n",
    "    Our problem doesn't do minibatching - but not minibatching makes result pretty unstable so for testing we use minibatching.\n",
    "    Note: I refuse to learn how to use pytorch's dataloader it confused me once 4 years ago and I took it personally.\n",
    "    Note: Yes the batch size is non standard but idk divisible by 60k is nice\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "    samples = x_train.shape[0]\n",
    "    n_batches = samples // batch_size\n",
    "    for i in range(epochs):\n",
    "        perm = np.random.permutation(samples) # switch order every epoch generally good practice\n",
    "        for batch in range(n_batches):\n",
    "            x = x_train[perm[batch*batch_size:(batch+1)*batch_size]]\n",
    "            y = y_train[perm[batch*batch_size:(batch+1)*batch_size]]\n",
    "            for opt in optimizers: opt.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = F.cross_entropy(pred, y)\n",
    "            loss.backward()\n",
    "            for opt in optimizers: opt.step()\n",
    "        with torch.no_grad():\n",
    "            acc = (torch.argmax(model(x_train), -1) == y_train).float().mean()\n",
    "            accuracies.append(acc.clone().detach().cpu().numpy())\n",
    "    return accuracies\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a standard model fully with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal linear model\n",
    "standardModel = Model(useSVD=False).cuda()\n",
    "standardOpt = getOptimizers(standardModel)\n",
    "standardAcc = minibatchTrain(standardModel, standardOpt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with 1 householder matrix for each orthogonal matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = setHouseOrthNHouseHolders(1)\n",
    "exec(s) # yes this is insane\n",
    "svdModel1 = Model(useSVD=True).cuda()\n",
    "svdOpt1 = getOptimizers(svdModel1)\n",
    "svdAcc1 = minibatchTrain(svdModel1, svdOpt1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with 20 householder matrix for each orthogonal matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd linear model\n",
    "s = setHouseOrthNHouseHolders(20)\n",
    "exec(s) # yes this is insane\n",
    "svdModel20 = Model(useSVD=True).cuda()\n",
    "svdOpt20 = getOptimizers(svdModel20)\n",
    "svdAcc20 = minibatchTrain(svdModel20, svdOpt20)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with 60 householder matrix for each orthogonal matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd linear model\n",
    "s = setHouseOrthNHouseHolders(60)\n",
    "exec(s) # yes this is insane\n",
    "svdModel60 = Model(useSVD=True).cuda()\n",
    "svdOpt60 = getOptimizers(svdModel60)\n",
    "svdAcc60 = minibatchTrain(svdModel60, svdOpt60)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oh my god it works!\n",
    "* I was not expecting that!\n",
    "* The model performs better with more householder matrices repersenting each orthogonal matrix\n",
    "* It learns slightly slower (and is less stable (analysis would take too long in compute time))\n",
    "    * But it does nearly as well as the standard model!\n",
    "* We can now try to implement the actual problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5e6d672a30>"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAABDoklEQVR4nO3dd3wc9Z3/8dd3Zrt6cZfcMAZXmgE7YDDkklBytCQHPggQkpCEAOm/kEsB7pLLlVy4I8eROLk0cpQESDCEkgDGBIIBG1ywjXG3JcuW1aWtU76/P2a1kmw1q3pXn+fjsQ9pZ2dnvqPVvve73/nO96u01gghhMh+xmgXQAghxNCQQBdCiBwhgS6EEDlCAl0IIXKEBLoQQuQI32jtuLy8XE+fPn20di+EEFlp3bp1dVrrcd09NmqBPn36dNauXTtauxdCiKyklNrb02PS5CKEEDlCAl0IIXKEBLoQQuQICXQhhMgRfQa6UurnSqlapdQ7PTyulFL3KqV2KKU2KqVOH/piCiGE6Et/aui/BC7q5fGLgRPTt5uB+wdfLCGEEMeqz0DXWr8MNPSyyuXAr7VnDVCslJo0VAUUQgjRP0PRD30KsL/T/ar0spojV1RK3YxXi2fq1KlDsGshjqa1xtXgao3jalKOi+N4w0QbSqEMcByN5bikHJfOI0hrDZbr4rgaV2sUCqW8x2zH255SEPIbhPwmpqGIpRziKYeU45If9FEQ8hH2myQsl1jKJuW4BH0mkYBJOGBSEPSh2jfaie24RFMOsZSNaSgiAW87ccuhMZqiIZoi5bgoSJfJ24ZSXrldrXFdjWko8kM+8oM+AqZBwnJJ2A6W4xIwDQI+A4WiMZaiIZaiJW6ljxcMBYUhPyV5AYrCfhKWQ2vCJpr0jsNyXGxH03nQbQWYhsIwFEanw3JcjZX+OztuxzMMpQj4DPymIugzCfoNgj4Dn2Fgp18Tx9WZ18BxIWk7JG2XlO1iuxrHdXFc8JvetgKmgabjb5BytPccyyUvaFKaF6QsL0DAZ2T+VnHLoSVu0ZqwcVyN31T4048nLO81NQxFWV6AcQVBQn6ThvTr0Ja0Cfm91zTk9/6e7a9FwDQI+r3jaUlYNEZTNMctAHymgc9QnDOrnDmTCgf3j96NEb2wSGu9AlgBsGjRIhmIHe+fvi1pZ/7pbVfjM1T6ZtCWsmmKpWiOWcQth5TdNYTa38yOq3G09+ZJWC4Jy8F2NH6fwm94X8QSlkMi/U/e/uawHBelFKYBCkXK8ZYnbRfH9d48nYNNKYVluyRtL8DaQ85Jh2f7rXNIKpUOUgWuq7Hcjjd5+5tLAf70m1op0mVwcDXkBUzyQz4ifl8mNNrXab/FLScTXMf7EP9+U1GWF6Q44idlu7QmbVoTFgnLHe2iiRHy3SvmH7eBXg1UdrpfkV6W8yzHpTGaoj6aoilmEUvZRFMObQmb5rhFUzxFW8LO1GqSjktzzFveGLVoSXi1g5FkKAj5TYI+g6DPxGeqzAeCRmdqOwGfid9UGEphpqtdbrrmGzC92mOxz6tttNfO2n83lfe8dpp0jdnVGIbCbxpdtq0AV4Pteh8wWuOVz2+iFMSSDm1Jm1jKzmxHQ6a2GfAZhP1e7TfoM9Lb9ILfNL0PNNNIf6BorwbvM7zamN8wMAyF1t42TaXwmSrzwaK1V34An+Edr6s1CbvjQzMvaBIJ+PCZiraETVvSJp5yMjW4gM8gaTvEUy7RpE1DLEV9W5KGqEXIb1CQrk3nB/3kBU3ygj5sVxNP2cRSDmG/SUlegNJIgKDfSJcp/bft9OnV/re3XE00adOW8GrVIb9JOP1twkp/YLtaU5oXyNTEfem/mas1zXErU3MP+b1vFPkhH4H0B277a9eu/ZuQqzs+yHW6PH7DwO/zypWuxOK63nunvVKRcjpVQEyFDxdfIo6Zn4/h8/6uAVMRTCUxY20Eysvwh0MYKl0BSSRJ1h6G1hZULAaxGP7CfMITxhMaV05ba5TGqkM0H6zFcTQqPw/CEYLaIS/WSjDagr+kGGPhKdiBEADBRBS99g2Se/cRM3y0GQFSgRAFZSUUjSshUlyIpRVxxyUZTaD37MbdvRNdXYULOBi4hkEgHCKUHyEUCYFSuOlvFoWBKcC0IX9/D0WgrwRuVUo9DJwNNGutj2puyTZaaw63JdlxqI36aCpTa61pjrO1poWtNa1UN8V73UbA9N6sftMLlKDPoCjiZ3xBiNnjCygM+ykK+yno9GYxDXDS//BW+it8ccRPUTiQCYf27bWHkKG88DKUF5bhQNc3sO1qtNaE/CZ+U3qqjnXacUjt3YvTdBjnYDNuSwtuPI4bT6CTSQpCQabm5WFEIl4yOzbadtCWlbm5sRhuWxtutA3tugR8fpQvHSfaRbsubjSG09hIorER5fcTmDaNwPRpmOEw6lAtxqGDBJqavG27DjoWxzpci1NX732SKoVZVISKhEk0NhGPd7zfzOJizLIynKYmnPr6fh13qJtlifQNAL+f8IIFKMOg4e23wXEy6/nTNxdoTN+OYhj4J07ENAx8joO2LXTKIpFMEk8mO9ZTivyKSXD6qf0q97HoM9CVUg8By4BypVQVcCfesaG1/jHwNHAJsAOIAZ8Y8lKOgJTtsn5/E2t21bNmVz1balpoillHrWcomDkunzOmlfDRMyoozw9Qlh+kOOwnL+gjL2iSH/SCOuQ3um0rHUmmYY7q/sci7Ti4sRjKMMDnA8fBqq4mtW8f1sGDGKEwZnERRkEBaNIhmcJtacFpasJubEQnU2jbBsfGLC1Lh+F0lN+H09CA3dgIjoMKhzFCYez6OuIbNhDfsAGnrh6zpASzpATf+HEEpk8nOHMmGAZtL62m7aWXcBp66+fQPyoSwczLA8NA2zbatr1KuGGAUhiRiFeOslJ0Ikl0zRqan3jCe24wiG/iBHzFJeD3oQwTo7yM4Nw5+MdPwCgsyPw93GgUs6QU37hyjPwCnMYGrIMHceobMIuL8U2YgG/cOMyiIoyCfIxIBLctil1fh1PfgAoF8ZWVYZaWAuC2RXGjUZTfj6+sFLO0FKvmILHXXyf6+uto26bs058i/7zzCc05GTeRQMdiOG1R3LZWnJYW3GjM++ByHJTPT3DmDAIzZ2KEuvvYGDlqtOYUXbRokR7twbm01ry9v4nfra3iqQ0HaE3aKAVzJhZySmURJ44vYPaEAiYUBjNf7UsiAUJ+Ccls57S1kdq9m9SuXTgtrZnwdJNJdDyOG4t7oZSuqSq/D51K4aZSuC2tWNXVWAcO4DQ2ooJBVDDobbexEaepyWtXGCjD8Lbp86EMA6elhf6cGDDy8gifshDfxElezbWxEevQQewDHV+YjYIC8s87j7xzzkmHYCFGQQFGJA8jEkYFg+njj+HGYqAMlM8Ew0T5/aiAVxM3IhGUeezvAzcWw00mMYuLR72yk62UUuu01ou6e2zURlscLXvqory2q5639jbyxp4G9tbHCPkNLpk/iQ/Om8jimaUURwKjXcwxz66vJ75xI1ZVNWZhAUZREUYggF1Xh11bi3WoFru2FvvwYez6OnQiiU6la7WGgTIMlN9PcNYswqeeQmj+fKwDNcTffpv4229jHTjQ475VIIARDnu9JqJRsLue5zAKCvBPmYK/spLQwgVgWbjJFDhOpkZqFhSC1uj013b/5MkEpk3FP2kSbiKJ09yE29rqBabfh/L5MAsLMUtKMAoKvNp9mptMYu3bR3LPHnA1vlKv9q18PtxEAjfutTcHZs7sNmTdWIzU3r24sZjXpBDo4/87EMAsKur3a3UsjEjEa8oRw2JM1dCbYikWffd5bFdTEvFz+tQSPjB3ApcunERByD+iZclFbipFYtMm4m+/jb+ikvwLL8BIh4fT0kLL08+Q2PYuTn0Ddn09Oh4H0/TCyzDAddFa49TV9Rq44NVGfRMm4Bs/Hl9ZGSoc8mqQPn86SG10Ikli61aS772XqTH7xo8nfPrphObMIXjCTAIzZ2bCUZkmKhDoaAvG+xanUymwbS8Ifd13ORRipEgNPW1HbRu2q/nh353CladNkTdmD9xYjPg776ATCa9tNJnEbmzEqavHaW0lPH8eeeeei6+sDKe5mZY//YnWZ54htu4tdKeTP2ZJCUWX/S12YyOtz/0JnUxiFhVhjivHV1qGOW4c2nXTJ580GCYYikBFBSUf/zjhhQsITJuGG43iNDd7zy8vxz9+PEZeXv+PJxolsW0bvvET8E+ZfEyvu1LKa05JN6kIcTwbU4G+pz4GwKmVud9+p10XNxZHx9NtoZD5Ou9Go0Rf/Sttq1eT2rmTwPRpBE6YhZGfR/TlvxB97bUuwZyhFCoUovGBB0ApgrNOILlnL1gWgWnTKLnmaiJnnkn4tNNIbNlC06OP0fDgQxjBIEVXXkHxRz9GaN7cY//bl5cP6m9h5OUROV2GGBK5b2wFel0U01BUlOROG17b6tVEX38Dq+YA9oEa7IYG7yx8a2v3J+Z8vvSVSA5GYSGh2bOJvv4GzU+sBLy23uK/+zvyl56LWVgIPu9EmC/dawLDILFlK20vrya+di155y6l8NJLjwrq/KVLyV+6FKetzTuJNspn/4UYC8ZWoNdHmVIcJuA7/vtia8chuX07yR07Se3Zg7V/P+FTT6HoIx/BCARwk0kOff/7ND38CCoYxD9pEr5JEwlPPdU7uVZUiJGXj5EX8U7waY3T2OR1VzMN8s85h/Bpp2Xai522NpzGRvwVFX3WoMPz5xGeP69fx2Hm5w/6byGE6J8xF+jTy/vf9jqcnJYWUvv2Y1VXYx+s8foip0/AJTZuIvbWW14tG7wLLEpLaX7iCeru/zGl13+c5qf+SPLddyn71CcZ94UvoPyDO6lr5udL+AqR5cZMoGut2VsX4/SpJaNahuhf/0rjA7+hbfXqHvsWB2bMoPDii4mcuYjQySfjnzoVFQgQe/116u77H2p/8B+YxcVU/uTH5J9//ggfhRDieDVmAr0+mqI1aTO9bORq6PH166n/5a+83iKOg7V/P6k9ezDLyii7+WZC8+YSqKjAP3my1yVOKTDNTFe/I+UtXkze4sXEN23CN2EC/vHjR+xYhBDHvzET6HvrowDMGKEml9YXX6T6S1/2+ktPnIDy+fFPnkz55z5LwcUX9xja/RFesGAISyqEyBVjJtB313ld96aVDX8Pl8bf/Y6Dd95FaN48Kn/yY3zpMSSEEGI4jZlA31s/fF0WndZW2l5+mcTGTcQ3biT+9tvkLV1KxX/ec0wXwAghxGCMmUDfXTe4LotuIkH1F76IdfAg47/8JfLOOw+lFC1/+hMH/+mfcA7XoYJBQnPnUn7rrZR/5uZB9zwRQohjMWYCfW99bMBdFt1kkqrP30r0r3/FN2ki+z/zWfLetwQjL4/WPz9PcM4cKu65h/App0iICyFGzZgIdK01e+qinDa1+Jif66ZSVN16G9G//pVJ3/0uRX/7YRoffpjD9/0POh5n3Je/TNknbpQgF0KMujER6A0D6LJoHTpE63N/oukPvye5ZSuTvvtPFH/kKgBKr7+e4o98BG3bwzbMqBBCHKsxEeh70l0Wp5f3fUJUp1JU/7+v0/rsswAEZ89m8g9+QNGHL+2ynpzsFEIcb8ZGoKe7LPZVQ9daU/Pt79D67LOUffpTFF15pTd1lxBCZIGxEej1UQxFn10W6/77PpqfeILy225l3Oc/P0KlE0KIoXH8Dzs4BPbUx6goifTaZbHp8d9Td999FF11FeW33DKCpRNCiKExNgK9LtrrFaJaaw79678SOfNMJt19V85PfiGEyE05H+jtXRZ7G8PFbWnBbW4m//0XSvdDIUTWytk29FjKZsuBFt7e19Rnl8X2CYn9kyaPVPGEEGLI5WSgP/tODV94eD1J25uCbUJhkMUzy3pc36qpAcA/edKIlE8IIYZDzgX6i+8e4raH3mb+lCI+v2wWCyqKGF8Q7LVd3DqQDvRJEuhCiOyVU4H+6o46Pvubtzh5YiG/uuksCkP9aw+3ag6gAgHMsp5r8UIIcbzLmZOie+qifOpXa5lRlsevjyHMAeyaGvyTJknvFiFEVsuZQN9Q1UTccrjn6lMpyTu22YCsAzX4pP1cCJHlcibQG6MpwDsBeqysmhrp4SKEyHo5E+hNcQuAovCx9SPXqRR2ba2cEBVCZL3cCfSYRUHIh888tkOyamtBa+myKITIejkU6ClKIsfWdg6dLyqSQBdCZLecCfTGmEVx5Ngv27fTFxX5JNCFEFkuZwK9KW5RPJAaeo1cVCSEyA25E+ixFMV9nBBN7trFnquvIbZuXWaZdaAGs7QUIxQa7iIKIcSw6legK6UuUkptU0rtUErd0c3jU5VSq5RSbyulNiqlLhn6ovauKWZR0kuTS2rfPvbd+AniGzbQ9PjjmeVW+qIiIYTIdn0GulLKBO4DLgbmAsuVUnOPWO1bwG+11qcB1wD/M9QF7Y3jaloSFkU9NLlY1dXsvfFGdCpFaMECYq+tQWvtPVZzQHq4CCFyQn9q6GcBO7TWu7TWKeBh4PIj1tFAYfr3IuDA0BWxby1xC63ptoZu1day98ZP4LZFmfrz/6XoyiuwDhzA2r8frTXWgRr8k+WiIiFE9uvP4FxTgP2d7lcBZx+xzl3An5RStwF5wN90tyGl1M3AzQBTp0491rL2qDHmXSV6ZC8Xp7WV/Td/Bru+nmm/+DmhuXNRoTAA0dfWUFhYiI7FpIeLECInDNVJ0eXAL7XWFcAlwANKqaO2rbVeobVepLVeNG7cuCHadcdVop17ubipFFW33U5yxw4q/uu/CJ9yCgCBGdPxTZhAdM1rnXq4SA1dCJH9+hPo1UBlp/sV6WWdfRL4LYDW+jUgBJQPRQH7o6m9hp7u5aJdlwNf/zqxNWuY/L3vkr/03My6SinyFi8mtuZ1rGrvMKQNXQiRC/oT6G8CJyqlZiilAngnPVcesc4+4P0ASqk5eIF+eCgL2pummFdDb79StG3VKlqfeZZxX/4yRZcf2dwPkSWLcRobaVu9GpA+6EKI3NBnG7rW2lZK3Qo8B5jAz7XWm5VS/wis1VqvBL4C/FQp9SW8E6Q36vZuJCOgMdbe5OLV0Jv/8AfM8nLKbvpEt+vnLVkCQMvTz3gTW5SWjkxBhRDdak42cyh2iCn5U8jze/P/utrlYPQgtbFaIv4IhYFC8vx52K5N0kkSt+M0JBqoi9fRmGjEUAZ+w0/QDBI0g4R8IQJmgNZUK3XxOuridaScFIYyMA3T+6nMzE0phalMXO1iuRYpN0XcjtOSbKEp2UTCSRA2w4R8IYJmEEMZGMpAa01rqpUWq4VoKkrKTWG5FpZjdfnp4qK1RmvN1878GleeeOWQ/x37NWOR1vpp4Okjln2n0+9bgHOGtmj91xxLoRQUhvw4TU20vrSa0r//e5Sv+8PzT5hAYMYMUrt34582FWXkzPVVYgzRWlOfqGdH0w5qY7XErThxO47lehWc9oCK+CJE/BH8pp+2VBttqTZaUi20pFpoTjbTmmol5aZIOSm01hQFiygPl1MaKsVneO8hV7s0JBo4FDvE4dhhEk4iE1RhX5iSUAklwRIsbdGYaKQh0YCpTMpCZZSGSjGUQXOqmeZkMwCT8iYxOX8yjnZYX7ueHU07MsdVGiqlKFjEgbYDJJ3kkP29FArT8ALb1W6/nuM3/BQHiykKFhE0gxxyDhG346ScVGY7SikKAgUU+AvID+RTaBbiN/z4DB8BI4Df9OM3/CgUhjJQSjG9aPqQHVdnOTEFXWPMoijsxzAUjc88A5ZF0eWX9fqcvCWLvUCXE6KiE1e7HI4dpiZaQ0uqBcd1cLSDQuEzfB1vVDNAwAyg0TQnmmlKNtGSaiFue6GasBPeTydB0kliu3aXbSmlUCgSToKYFSNmx3BcJ1OLC/lC5PvzyQ/kk7STNCWbaEw24rouftOrhTYkGmhKNg3oOA1lUBQooihYREGggIAZIOwLYyiDungd2xq20ZBowNFO5jmloVLGR8YzKW8SYX8Yv+EFVcyK0ZBs4ED0AH7DT2molFnFs3C1S328ngPRA7japThYzLTCabjapSZaw4bDG9Bas3D8Qi6ecTEV+RUciB6gqrWKpmQT5005j2lF05gYmejVlFMtRK1oRy3cF6Q0VJr58AFIOknvZiczv+cH8hkXHtflA0prnQlkW9torXG0kwnogBHAb/gxDXPQ/1MjKScCvSluZdrPm59YSfDEEwnOmdPrcyKLF9P44EPSfp4lLNciZsUytR6f4ctMGai15mD0IDubd7KneQ+18Vrq4/XUx+tJuSkvTLWDT/kyX8fLwmVUFFQwKW8SDYkGttRvYWv9Vva17svUcAcjYAQI+8OETO/reXs4mMoLCFe7uLiEzTARfyQTNu1BH7fjtKZaOdB2gJAZYlxkHCeWnIjf8GeC6rTAaZxYciKzimcxOW8yYX+YsM8L2na2axO1osTsGJZjkR/IpyBQQMQXGdNTLrZ/ezEx8XPsg/odr3Ij0GMpisJ+Unv2EF+/nvFf+2qf/6x5Z58Nfj+BadNGqJRjS8yKsa91H/ta9tGaasXRXu20OFjMrOJZTC+cjmmYHI4dZn/rfrY3bWfT4U1sqtvEwehBwr5wpsbYnGym1Wo9ah+mMvEZPrTWpNxUZrnf8GdqbSFfiIARwFAGjnaI2TEaEg1srNtIQ6Ih85zx4fHMLZvL+ZXnMzlvMpPzJ1MULMJn+DIhbLu21ybqWqScdBMFmuJgMcWhYgoDhUR8EUK+EMbRvXZHRcAMEPFHRrsYYoTkSKBblOcHaF75JChF4Yc/3OdzzKIiZjz2KIEpU0aghNmjPRxbU61UtVaxr3UfB6MHKQgUUB4upzxcTlGwiMJAIWFfmA21G3jlwCusqVlDc7IZ27WxXZuWVEuv+/EpH6ZhdmkjLQuVsWDcAs6vOD/TFGFrm5JgCcWhYvL9+TiukwnV9n1pNJUFlZxQfAIzimZQEizpV+0zZsWoidZk2oyFyHY5EeiNsRSzxuXR/H8ryVuyBP+ECf16Xmj27GEu2eixXZuEnSDPn4dSiqgV5dXqV3lx/4tsrd+aaYZoD0Vb26ScFEkn2e8TRu0CRoAzJpzBgvIF+JQPn+GjPFzOtMJpTCucRlGwCFN5vQrqE/XsaNzBjqYdpJwUlQWVVBRUMKNoBpPyJo1oM0DEH+GE4hNGbH9CDLecCPTmmMXMuj1YVVWMu+3W0S7OoDmuQ1OyiYZEAz7Dl+mlAF5bctJOsqFuAy/vf5lXD7yKqUwWT1rMkslLsF2bV6pf4bWa12hNtWIqk4JAAVEriuValARLOH3C6QTNoNeGaHjNFj7lw2/6M00dEV+EioIKKgsqmZQ3iTarjfp4PXXxOpqTzbSkWmiz2phdMpszJ55J2Bfu17GVhcuYXZK7H6RCjKasD3TLcWlN2kxq8MYDC5+xaJRL1D+WY/Fuw7tsOLyBzfWbORw/TEOiIdPlqz+15KJgEedOORfHdXil+hWe3PUkAOPC43j/1Pczs2im1z821ULYF+b8ivM5dfypmTP9xyLkC1EeLuckTjrm5wohRkbWB3r7VaLF0SZQCv/4oRsjZiBaU61srd+a6V3RmmplZ9NOdjbvZH/LfqJ2lISdoM1qw3ZtACZEJjApbxKV+ZUsLF9IWbgs03/X1S5RO0rMiqFQmT6tJxSfwMLyhZluVa522d64HYDZJbPHdA8GIcaqrA/05rjXuyG/tR6zvAwVOPZp6AbLci3WHlzLH3b8gRf2vXDUxRA+5WN60XSmF00n359PyBeiIFDAnNI5nDLuFCbk9a/NvzeGMjipVGrPQoxlWR/o7Zf9h5sa8I8ffDD2R1uqjT/s+AOv1bzG3pa9VLVW4WiHgkABV8y6ggsrL8xcmdfeFt25b7AQQgyHrA/09iYXf2MdvpnTh3Vf1W3V/GbLb/j9jt8TtaKcUHQCJ5WcxAenfZA5ZXM4r+I8gmZwWMsghBA9yfpAb5/cQtUdxr/kyHk3hsbu5t38bNPP+OOuP6JQfHD6B/n43I8zv3z+sOxPCCEGIusDvTlmEbST0NqCb+LEQW/P1S5P7HiCTXWbaEg0cDh+mE2HNxE0gyw/eTk3zLuBiXmD348QQgy1rA/0xliK8UnvsnD/hPGD2tbelr1859Xv8FbtWxQHiykPl1MWKuNTCz7FtXOupSxcNhRFFkKIYZH1gd4Ut5jutgHgm3BsNeekk2RfizfeyOb6zfx6y68JGAG+e853ueyEy6TrnxAiq2R/oMdSTHG8QPdP7H8vl13Nu/jEs5/oMkDTsoplfGvxt4akG6EQQoy0HAh0i5PSA0H5+jmGS328nluevwWA7y/9PjMKZzC1cCoFgYJhK6cQQgy3rA/0xpjF+EQzZlERRrjv8UTidpzbX7yd+ng9P//Qz1kwbsEIlFIIIYZf1gd6cyxFSaypX7VzrTX/8Jd/YFPdJu654B4JcyFETjk+RuEfhMaYRWFbE75+tJ9vqtvE8/ue5/bTb+f9U98/AqUTQoiRk9U19ITlELccIi31+Cec3uf6z+55Fr/h5+qTrh6B0gkxBmkNTgrsBLhOp+UuuHb65nj30d76Wqd/d8GxvOe7Dmin07qZDXVsw3U6tqmdjuc6KXBd73ntN/TR5ez8HO2CMgDVsQ/H6roP1+54Xvt2Xcdb3/B5N2V0Kod1xHPdjn0v+TycfMmQ//mzOtCb4xY+1ybY0ncN3dUuz+15jnOnnCsnP8XIct30GzwJdvpn+xtep4NGKS8ErThYsXQoWEcHiWuDnewUfJ3Xc44Or/bQcW1vfSsBdtz7mSlPygsiwwQ6lcOOdwohOvbvWOlQ0x37zATc4OdjHXkqHebpDxUUmP6OkM7cTFCmt65S6fvpD4H2v43res81/WD4O22n07oq/aExDLI60JtiFqVxr4dLX7MUvV37NrWxWr5yxldGomhiJNlJSEW9mxVL1xDba2q2FzKukw7LeMc67eHkpNIhmfR+WnEv1OyEtx070bV22f575xphl5qh06lGmq7BDTvVKXBU1+Wm33vM8IM/BL6w99MMgi8I/sKO4NcaIqXgD3vrdZ713jA71UTNjpDK3BSYAe/mC3r7g3R5FJidarGdw63z72agIwTbP2QyNef2crQHrOHto/24fYGuIdpepi5BStftmIGux5jlsjrQG2MpxiWagb4vKnp297OEzBDLKpeNQMkE4IWDFYN4E8QbIdHkha6dDk47HbDtQZxsg1Sr99OKQSoGqU6/24lOYWFCshUSzd7ywVKGF3D+EPjab+nA84W8oPCFOoWa3wsoM5AOxnSQtQeqMrrW6nyBjgBtDz3T36lmqL0QbQ9SX6Br7bB9u6a/6/PNdIgZWX86TAyBrA70pphFWdwL9N4uKrJdmz/t/RNLK5bKDOhDKdkKBzd5t0PvQFutF9zxxo4Q7+9XcGVAID99y+u45Y1L/57vhVx77du1IVgAoSIIFXY8zx/pFJrpr73toegPpR9Ph7XhS4di0AtnIbJcVv8Xv3eolfJ4E0CvA3OtPbSWhkQDF02/aIRKluMcC/56L6z+t47acaQMCqdAuATGz/F+hoohXNz190B+1xpw5xCWoRaEGJSsDfSk7fDAmr3cGkphRCIY+fk9rvvs7meJ+CIsrVg6giXMUfvfgCe/ALVb4OQPw+k3wMQFUDBRAlmIUZa1gf7E2wc43JrklFAK34QJPQ6kZbkWz+97nmWVy/o9M73owfoH4YnPQ8EkuOZBOPnS0S6REKKTrAx019Ws+Msu5k4qpGh3I0Yv7ed7mvfQnGyW2vlgvfUArLwNZp4PV//Ga78WQhxXsvLU+KptteyobePm82Zi19bi76WHS9SKAlAcLB6h0uWgdb+ElbfCCRfA8oclzIU4TmVloP/k5V1MLgpxybzx2LW1vV5UFLNiAER80rvlmNlJeO6bXpv5rA/ANQ953eqEEMelrGtyWb+/iTd2N/CtS+egGhvBcXq9qChqezX0PH/eSBUxN9Ruhcc+5XVHPPPT8KHveT1RhBDHrawL9LV7GiiJ+LnmrKnY27YAvV9UJDX0Adj2LPzuBq9p5e9/C7M/NNolEkL0Q9YF+qeWzuTqMyvJD/poOXQI6P2iovY2dLmgqJ92vwy/vd7rS37t7yB/cPO0CiFGTtYFOkBByBsjwmloBMAs63ny5pidrqFLoPetai08tBxKZ8DHf++N6SGEyBr9OimqlLpIKbVNKbVDKXVHD+v8nVJqi1Jqs1LqwaEtZvfcmBfWRqTnsI5ZMQxlEDJDI1Gk7HV4G/zmI5BXDh//g4S5EFmozxq6UsoE7gM+AFQBbyqlVmqtt3Ra50TgG8A5WutGpdSIfE93Y15zSm9Tz8XsGBFfpMcLjwSQaIGHr/XGNbn+CSicNNolEkIMQH9q6GcBO7TWu7TWKeBh4PIj1vk0cJ/WuhFAa107tMXsno7HUYEAytfz51LUikpzS2+09q7+bNgFH/sllEwf7RIJIQaoP4E+Bdjf6X5Vellns4HZSqlXlVJrlFLdjoKllLpZKbVWKbX28OHDAytxJ24s3mtzC3hNLtJlsRd//RFsXQkfuBumnzvapRFCDMJQXVjkA04ElgHLgZ8qpYqPXElrvUJrvUhrvWjcuHGD3qkbi6EivV/oErWj0mWxJ3tehefvhLmXw5JbR7s0QohB6k+gVwOVne5XpJd1VgWs1FpbWuvdwHt4AT+s3HjfNfS4FZcaenfiTfD4zVAyAy6/T0ZKFCIH9CfQ3wROVErNUEoFgGuAlUes8we82jlKqXK8JphdQ1fM7rmxGEa490CPWlJD79bTX4XWGvjIT2VsFiFyRJ+BrrW2gVuB54CtwG+11puVUv+olLosvdpzQL1SaguwCvia1rp+uArdzo3H+m5Dt2NyUvRImx6FTb+DZXfAlDNGuzRCiCHSrwuLtNZPA08fsew7nX7XwJfTtxHjxmL4x/c+ObT0ckmzU9BSDQ074akvQ8VZcO6IvlxCiGGWlVeKttP96OUSt+Pk+Y7TNnQ7BfEGb+5NJ5WeUd7xJlOO1kGsHpItHZMn26n0DPbp2eQdq9Ns9OlZ6O1EelLlaHq2+vQs9VaczOzzwUK46icyj6YQOSar39F99XJxXIe4HR+5GrpjQ0sVNFd3zHIfb+r4GW+EtkPQetD7mWzp33bbJ0/2BTomPTb9XWegN3wQiHjzdwbzOyZDbp95PpAHRZVQXAkT5ntXhAohckp2B3ofvVzidhwYpqFzU1Gofguq10H1Wji0GZr2ebXhoyhvdvpwiTf35oR5MOv9ECn3LrEPl3iz1BsmKNObTDlS5t2ChWBk5bD1QogRlrWBrrXus5dL+0iLQzaXaO1W72Tinle8IG8P75IZMGkhzL3CG9iqqNIL6XBJeqb7AgllIcSwy95AtyxwnN4H5kqPtDjoGrrW8Nav4On/54X4lNPhfbfB1CUwZRHk9TzaoxBCjJSsDXQ32o+BuYZicotUDP74FdjwIMy8AK76KeQP/ipXIYQYalkb6DrutY8bvZwUHZIa+qM3wXvPwvlf926GOfBtCSHEMMraQO/PWOiDnq2o5YAX5ku/Ahf8w8C2IYQQIyRrz9S56Rq66k+Ty0ADffPvAQ2nLB/Y84UQYgRlb6BH22voPTenRO10DX2gbejvPAaTToHyWQN7vhBCjKDsDfR4e6D3XUMfUBt6wy6va+L8jwyofEIIMdKyN9D7OZ8oDLAf+juPez/nXXXszxVCiFGQtYGe6eXSx3yiITOEzxjAud93HofKxd6l8kIIkQWyNtD728tlQCdEa7dC7WZpbhFCZJUsDvR0L5c+rhQd0AnRdx4DZcC8KwZYOiGEGHlZHOgx8PlQfn+P6wyohu5YsOERmHEe5I8fZCmFEGLkZG+gx+MY4TCql7kwBzSf6IaHoXkfnP25QZZQCCFGVvYGeiza5+QWxzyfqGPBy/8Ok06F2R8aXAGFEGKEZW2g63QNvTfHPJ/ohoehaS8s+wb0UvMXQojjUdYGutuP6eeOqYbeXjuffJrUzoUQWSmLA7336efAq6H3uw1daudCiCyXvYHex/RzWmtiVj+bXLSGV37o1c5P/OAQllIIIUZO9gZ6H9PPpdwUjnb6V0M//K43dssZN0rtXAiRtbI30OOxfo2F3q9xXHa84P084f1DUTQhhBgVWRvoOhrr1/Rz/aqh73wBymfLuC1CiKyWtYHuxuMYeX3X0PsMdCsOe/8qtXMhRNbLykDXto1OpXqdrShue2O99Nltce+rYCdglgS6ECK7ZWWgu5kJooeghr7jRTCDMO2cISufEEKMhuwM9Pahc3vp5RKz+zm5xc4XYNoSCAxwmjohhDhOZHegD7aG3lzldVmU9nMhRA7I8kDvu5dLrxcW7XzR+ynt50KIHJCVga770Ybe3uTSaw19xwtQMAnGzx3S8gkhxGjIykDvaEPvvYZuKpOAEehhIw7seglOuFCuDhVC5IQsDfS+p59rn62oxwkwqt+CRJMX6EIIkQOyNND7Pina53yiO18AlAS6ECJn9CvQlVIXKaW2KaV2KKXu6GW9jyiltFJq0dAV8WhuvH+9XPpsP59yOkRKh7p4QggxKvoMdKWUCdwHXAzMBZYrpY46i6iUKgC+ALw+1IU8Ur/a0HuroccboXqtdFcUQuSU/tTQzwJ2aK13aa1TwMPA5d2s90/AvwKJISxft3Q8DkqhQqEe14lZvUxusesl0C7M+pvhKaAQQoyC/gT6FGB/p/tV6WUZSqnTgUqt9R9725BS6mal1Fql1NrDhw8fc2HbuemRFns84YkX6GF/DzX4HS9AsAimnDHgMgghxPFm0CdFlVIG8EPgK32tq7VeobVepLVeNG7cuAHv043HUb2MtAi9tKFr7QX6zPPB9A24DEIIcbzpT6BXA50HCq9IL2tXAMwHXlJK7QEWAyuH88RoX7MVQS9t6IffhdYD0twihMg5/Qn0N4ETlVIzlFIB4BpgZfuDWutmrXW51nq61no6sAa4TGu9dlhKTN/ziUIvbejtsxPJ5f5CiBzTZ6BrrW3gVuA5YCvwW631ZqXUPyqlLhvuAnbHjUV77eHiuA4JJ9F9DX3H8zDuZCiqGMYSCiHEyOtXI7LW+mng6SOWfaeHdZcNvlh9lCcWx8jP7/Hx9nFcjhqYq312ojM/NZzFE0KIUZGdV4rG4wMbabFmAzhJmH7ucBZPCCFGRXYGeizW+1WidnosdN8RbehV6WZ96a4ohMhB2Rno8Xjv84la6flEj6yhV6+DokoomDCcxRNCiFGRlR2x++q22JxqBqAgUND1geq1UjsXWceyLKqqqkgkhv0ibHEcCYVCVFRU4Pf7+/2crAt07broProt1sfrASgLlXUsbDsMTfvgrJuHu4hCDKmqqioKCgqYPn16r1dHi9yhtaa+vp6qqipmzJjR7+dlXZNLx2xFPTe5NCQaACgLdwr06nXeT6mhiyyTSCQoKyuTMB9DlFKUlZUd87eyrAt0tx/Tz9XH6wkYAfL9nbo2Vq8FZcKkU4a7iEIMOQnzsWcgr3n2BXp66NzeTorWJ+opCx9Ro6le580dGuhljHQhhMhi2Rfo/ayhd2k/d10v0CukuUWIgfje977HvHnzWLhwIaeeeiqvv+5Ne/Cf//mfxNKVrKEwffp06urqBvz8X/7yl9x6661DVp7uvPTSS3z4wx8e9DrDIetOirrR9skteg70ungdE/Mmdixo2AWJZmk/F2IAXnvtNZ566ineeustgsEgdXV1pFIpwAv06667jkgfYysNF8dxME1zVPZ9PMq+QG+ffq6X4XPrE/XML5/fsaC6/YKiYZ0ZT4hhd/eTm9lyoGVItzl3ciF3/u28Hh+vqamhvLycYDAIQHl5OQD33nsvBw4c4IILLqC8vJxVq1bxuc99jjfffJN4PM5HP/pR7r77bsCred9www08+eSTWJbF7373O04++WTq6+tZvnw51dXVLFmyBK11Zr9XXHEF+/fvJ5FI8IUvfIGbb/Z6qOXn5/OZz3yG559/nvvuu4/t27fz/e9/n+LiYk455ZRMOTu766672L17N7t27WLfvn3cc889rFmzhmeeeYYpU6bw5JNP4vf7eeGFF/jqV7+KbduceeaZ3H///QSDQZ599lm++MUvEolEOPfcjivNo9Eot912G++88w6WZXHXXXdx+eXdzf8zMrKvyaWP6edc7dKYaKQ01Gmu0Op1EMiHcSeNRBGFyCkf/OAH2b9/P7Nnz+aWW25h9erVANx+++1MnjyZVatWsWrVKsBrmlm7di0bN25k9erVbNy4MbOd8vJy3nrrLT73uc/xgx/8AIC7776bc889l82bN3PllVeyb9++zPo///nPWbduHWvXruXee++lvt7rjhyNRjn77LPZsGEDJ5xwAnfeeSevvvoqr7zyClu2bOnxOHbu3MmLL77IypUrue6667jgggvYtGkT4XCYP/7xjyQSCW688UYeeeQRNm3ahG3b3H///SQSCT796U/z5JNPsm7dOg4ePJjZ5ve+9z0uvPBC3njjDVatWsXXvvY1otHo0P3xj1HW1dB1H23oTckmHO107bJYtRYmnwaGfDUT2a23mvRwyc/PZ926dfzlL39h1apVXH311fzLv/wLN95441Hr/va3v2XFihXYtk1NTQ1btmxh4cKFAFx11VUAnHHGGTz++OMAvPzyy5nfL730UkpKSjLbuvfee/n9738PwP79+9m+fTtlZWWYpslHPvIRAF5//XWWLVtG+4Q5V199Ne+99163x3HxxRfj9/tZsGABjuNw0UUXAbBgwQL27NnDtm3bmDFjBrNnzwbghhtu4L777mPZsmXMmDGDE088EYDrrruOFStWAPCnP/2JlStXZj6gEolElw+lkZZ1gd5XL5fMRUXtgW4n4eAmWPL5ESmfELnINE2WLVvGsmXLWLBgAb/61a+OCvTdu3fzgx/8gDfffJOSkhJuvPHGLv2o25tCTNPEtu1e9/fSSy/x/PPP89prrxGJRFi2bFlmW6FQaEDt5u37NwwDv9+f6QVnGEaf5emJ1prHHnuMk07q+u3/0KFDA9reYGVhk0t7Db377of1iSOuEj38LrgWTD51JIonRM7Ztm0b27dvz9xfv34906ZNA6CgoIDW1lYAWlpayMvLo6ioiEOHDvHMM8/0ue3zzjuPBx98EIBnnnmGxsZGAJqbmykpKSESifDuu++yZs2abp9/9tlns3r1aurr6zNt8wN10kknsWfPHnbs2AHAAw88wPnnn8/JJ5/Mnj172LlzJwAPPfRQ5jkf+tCH+NGPfpRp+3/77bcHvP+hkHU19MiiMxj3lS9jhEPdPn5UDb1hl/ezbNZIFE+InNPW1sZtt91GU1MTPp+PWbNmZZocbr75Zi666KJMW/ppp53GySefTGVlJeecc06f277zzjtZvnw58+bN433vex9Tp04F4KKLLuLHP/4xc+bM4aSTTmLx4sXdPn/SpEncddddLFmyhOLiYk499dQBH2coFOIXv/gFH/vYxzInRT/72c8SDAZZsWIFl156KZFIhKVLl2Y+xL797W/zxS9+kYULF+K6LjNmzOCpp54acBkGS3U+qzySFi1apNeuHfpZ6n69+df8+9p/55VrXqEoWAR/+SG8cDd8oxqCPU+KIcTxauvWrcyZM2e0iyFGQXevvVJqnda62y57Wdfk0pf6RD1+w09hoNBb0LAL8sZLmAshcl7OBXpdvI7SUGnHZf+Ne6B05qiWSQghRkLOBXp9op7ycHnHgoZdUNr/4SeFECJb5VygN8QbOk6IWnFoqZYauhBiTMi5QO8yMFfjXu9nidTQhRC5L6cC3dUuDYlONfTG3d5PqaELIcaAnAr0lmQLtrY7aujtfdClDV2IQelu+Ny7776bb3zjG13WW79+faab3fTp01mwYAELFixg7ty5fOtb3+pxBh6lFNddd13mvm3bjBs37piHoO3P8Ls9rZOf331PuBtvvJFHH330mMrR7r//+7+ZNWsWSqlBDQvcXzkV6JmrRDtfVBQqgnBJL88SQvSm8/C5Gzdu5Pnnn6eyspLly5fzyCOPdFn34YcfZvny5Zn7q1atYtOmTbzxxhvs2rWLz3zmM93uIy8vj3feeYd4eqymP//5z0yZMmX4DmqEnHPOOTz//POZK2uHW9ZdKdqboyaHbtjttZ/L9F0iVzxzhzc20VCauAAu/pceH+5p+FyAkpISXn/9dc4++2zAG5zrueeeO2ob+fn5/PjHP6ayspKGhgZKS0uPWueSSy7hj3/8Ix/96Ed56KGHWL58OX/5y18AaGho4KabbmLXrl1EIhFWrFjBwoULex1+9ze/+Q333nsvqVSKs88+m//5n//pcwyYb37zmzz11FOEw2GeeOIJJkyYAHiDiP3whz/k4MGD/Nu//Rsf/ehHe91Ou9NOO61f6w2V3K+hS/u5EIPS0/C5AMuXL+fhhx8GYM2aNZSWlmZGJTxSYWEhM2bM6DIuTGfXXHMNDz/8MIlEgo0bN2Y+JMAbIuC0005j48aN/PM//zPXX3890PPwu1u3buWRRx7h1VdfZf369Zimyf/93//1epzRaJTFixezYcMGzjvvPH76059mHqupqeGVV17hqaee4o477gCgtbWVU089tdtbb8P4DqfcraE7FjTvh/lXjXKphBhCvdSkh0tvw+deffXVvO997+M//uM/jmpu6U5vQ40sXLiQPXv28NBDD3HJJZd0eeyVV17hscceA+DCCy+kvr6elpaWHofffeGFF1i3bh1nnnkmAPF4nPHjx/datkAgkGmzP+OMM/jzn/+ceeyKK67AMAzmzp2bGUmxoKCA9evX97rNkZZTgV4Xr8Nn+CgMFnpXiLq21NCFGAI9DZ9bWVnJjBkzWL16NY899hivvfZaj9tobW1lz549mfHGu3PZZZfx1a9+lZdeeikzocVAaK254YYb+P73v9/v53QeUvfIIX47z4LU/qHU2trK0qVLu93Wgw8+yNy5cwdS9EHJuSaX0lAphjK89nOQPuhCDFJvw+eC1+zypS99iZkzZ1JRUdHtNtra2rjlllu44oorukxicaSbbrqJO++8kwULFnRZvnTp0kyTyUsvvUR5eTmFhYU9Dr/7/ve/n0cffZTa2lrAa4Pfu3fvAI6+Z+019O5uoxHmkGuB3vmiokyXRamhCzEYbW1t3HDDDcydO5eFCxeyZcsW7rrrrszjH/vYx9i8eXO3zS0XXHAB8+fP56yzzmLq1Kn85Cc/6XVfFRUV3H777Uctv+uuu1i3bh0LFy7kjjvu4Fe/+hXgta2//PLLzJs3j8cffzwz/O7cuXP57ne/ywc/+EEWLlzIBz7wAWpqagbxVxiYe++9l4qKCqqqqli4cCGf+tSnhnV/OTV87tVPXU1pqJT7/+Z+eO6b8Ob/wjdrpJeLyGoyfO7YNaaHzz2qhl4qXRaFEGNHzgS61rrrZf/tfdCFEGKMyJlAb0m1YLmWV0N3XW8cF7nkXwgxhvQr0JVSFymltimldiil7ujm8S8rpbYopTYqpV5QSg3bda5aaw5GDx61vMtFRW0HwU5IoAshxpQ+A10pZQL3ARcDc4HlSqkj++S8DSzSWi8EHgX+bagL2u7HG3/Mhx77EHE73mV5l8mhD2/zFpaeMFzFEEKI405/auhnATu01ru01ingYeDyzitorVdprWPpu2uA7jujDoHZJbNxtct7je91WV7VWgXAxMhEqEr3npk8suMoCCHEaOpPoE8B9ne6X5Ve1pNPAs8MplC9mVvqfTnYUt91rITN9ZvJ9+cztXAqVL0B406GcPFwFUOIMUWGzx3Y8LnXXnstJ510EvPnz+emm27CsizAazq+/fbbmTVrFgsXLuStt94a0PaPNKQnRZVS1wGLgH/v4fGblVJrlVJrDx8+PKB9TMybSEmwhK31W7ss31y3mbllczE0sP8NqDxrQNsXQnQlw+cO3LXXXsu7777Lpk2biMfj/OxnPwO8q1q3b9/O9u3bWbFiBZ/73OeGZH/9GculGqjsdL8ivawLpdTfAN8EztdaJ7vbkNZ6BbACvAuLjrm03n6YWza3Sw3dciy2NW7jujnXQf0OSDRBhQS6yD3/+sa/8m7Du0O6zZNLT+brZ329x8dl+NyBD5/beZCxs846i6oqr2n4iSee4Prrr0cpxeLFi2lqaqKmpoZJkyb1a7s96U8N/U3gRKXUDKVUALgGWNl5BaXUacBPgMu01rWDKlE/zCmbw86mnSQd73Pjvab3sFyLeeXzYP/r3kqVZ/eyBSFEf8nwuYMfPteyLB544AEuuugiAKqrq6ms7KgnV1RUUF19VD35mPVZQ9da20qpW4HnABP4udZ6s1LqH4G1WuuVeE0s+cDv0qOV7dNaXzbo0vVgbtlcbG2zvXE788vns7luMwDzyubBxqcgVAxls4Zr90KMmt5q0sNFhs8d/PC5t9xyC+edd16PozMOlX4Nn6u1fhp4+ohl3+n0+98Mcbl6NafUO+mypX6LF+j1mykOFjMlf0pH+7mRM9dMCTHqZPjcgQ+fe/fdd3P48OEuA5NNmTKF/fs7+ppUVVUNyTmDrEy9KflTKAwUZtrRN9dtZl7ZPFSiGQ6/KydEhRhCMnxu9/ozfO7PfvYznnvuOR566CGMTpXMyy67jF//+tdorVmzZg1FRUWDbj+HLJ3govOJ0bgdZ0fTDs6vPL+j/7mcEBViyLS1tXHbbbfR1NSEz+dj1qxZrFixIvP4xz72MW6//XZ+9KMfHfXcCy64AK01ruty5ZVX8u1vf7vXffU2fO5NN93EwoULiUQiXYbPXb58OfPmzeN973tft8Pnuq6L3+/nvvvuG7HJmtt99rOfZdq0aSxZsgSAq666iu985ztccsklPP3008yaNYtIJMIvfvGLIdlf1g6f+8N1P+SBLQ+w4gMruOm5m/ivC/6LC3eugZf/He7YD8Hu+5QKkW1k+Nyxa8wMnzu3bC62a/PEjicAmF8+3+vhMmGehLkQYkzK3kBPXzH63J7nGBcex/hQGVStk+6KQogxK2sDvbKgkgJ/AQkn4fU/r1kPqVZpPxdCjFlZG+hKKeaUeW1L8/wl8OA1ECyEmeePcsmEEGJ0ZG2gQ0d/9Pmv/wL8Yfjkn6Fg4iiXSgghRkdWB/r5RJhqWSwsnQOffhHGnzzaRRJCiFGT1YF+5rYX+GOLSeH1T0Jeed9PEEIMiAyfO7Dhc7XWfPOb32T27NnMmTOHe++9N7P8uB8+d0S1HICdL8Kpy8EX7Ht9IcSAyPC5A/fLX/6S/fv38+6777J161auueYaYHSHzz0+bXgYtAun9D4YkBC55OA//zPJrUM7fG5wzslM/Id/6PFxGT534MPn3n///Tz44IOZy/7bBwgbzeFzjz9aw/r/g6nvgzKZN1SI4STD5w58+NydO3fyyCOPsGjRIi6++OLMsY/a8LnHpao3vYkszvniaJdEiBHVW016uMjwuQMfPjeZTBIKhVi7di2PP/44N910U+Zbx3DIzkB/+zfgj8C8K0a7JEKMCTJ87sCGz62oqOCqq64C4Morr+QTn/gEIMPndkjFYPPvYe7lECwY7dIIkfNk+Nzu9Wf43CuuuIJVq1YBsHr16syHmQyf2+7dpyDZAqdeO9olEWJMkOFzB+6OO+7g2muv5Z577iE/Pz8zSbQMn9tu2zPw1gNw9W9kViIxJsjwuWPXsQ6fm3019JMu9m5CCCG6kCquEELkCAl0IbLAaDWNitEzkNdcAl2I41woFKK+vl5CfQzRWlNfX08oFDqm52VfG7oQY0xFRQVVVVUcPnx4tIsiRlAoFOqxG2hPJNCFOM75/X5mzJgx2sUQWUCaXIQQIkdIoAshRI6QQBdCiBwxaleKKqUOAwMdXKEc6H1aktw0Fo97LB4zjM3jHovHDMd+3NO01uO6e2DUAn0wlFJre7r0NZeNxeMei8cMY/O4x+Ixw9AetzS5CCFEjpBAF0KIHJGtgb6i71Vy0lg87rF4zDA2j3ssHjMM4XFnZRu6EEKIo2VrDV0IIcQRJNCFECJHZF2gK6UuUkptU0rtUErdMdrlGQ5KqUql1Cql1Bal1Gal1BfSy0uVUn9WSm1P/+x5csYspZQylVJvK6WeSt+foZR6Pf16P6KUCox2GYeaUqpYKfWoUupdpdRWpdSSMfJafyn9//2OUuohpVQo115vpdTPlVK1Sql3Oi3r9rVVnnvTx75RKXX6se4vqwJdKWUC9wEXA3OB5UqpuaNbqmFhA1/RWs8FFgOfTx/nHcALWusTgRfS93PNF4Ctne7/K3CP1noW0Ah8clRKNbz+C3hWa30ycAre8ef0a62UmgLcDizSWs8HTOAacu/1/iVw0RHLenptLwZOTN9uBu4/1p1lVaADZwE7tNa7tNYp4GHg8lEu05DTWtdord9K/96K9wafgnesv0qv9ivgilEp4DBRSlUAlwI/S99XwIXAo+lVcvGYi4DzgP8F0FqntNZN5PhrneYDwkopHxABasix11tr/TLQcMTinl7by4Ffa88aoFgpNelY9pdtgT4F2N/pflV6Wc5SSk0HTgNeByZorWvSDx0EJoxWuYbJfwL/D3DT98uAJq21nb6fi6/3DOAw8It0U9PPlFJ55PhrrbWuBn4A7MML8mZgHbn/ekPPr+2g8y3bAn1MUUrlA48BX9Rat3R+THv9TXOmz6lS6sNArdZ63WiXZYT5gNOB+7XWpwFRjmheybXXGiDdbnw53gfaZCCPo5smct5Qv7bZFujVQGWn+xXpZTlHKeXHC/P/01o/nl58qP0rWPpn7WiVbxicA1ymlNqD15R2IV7bcnH6Kznk5utdBVRprV9P338UL+Bz+bUG+Btgt9b6sNbaAh7H+x/I9dcben5tB51v2RbobwInps+EB/BOoqwc5TINuXTb8f8CW7XWP+z00ErghvTvNwBPjHTZhovW+hta6wqt9XS81/VFrfW1wCrgo+nVcuqYAbTWB4H9SqmT0oveD2whh1/rtH3AYqVUJP3/3n7cOf16p/X02q4Erk/3dlkMNHdqmukfrXVW3YBLgPeAncA3R7s8w3SM5+J9DdsIrE/fLsFrU34B2A48D5SOdlmH6fiXAU+lf58JvAHsAH4HBEe7fMNwvKcCa9Ov9x+AkrHwWgN3A+8C7wAPAMFce72Bh/DOEVh438Y+2dNrCyi8Xnw7gU14PYCOaX9y6b8QQuSIbGtyEUII0QMJdCGEyBES6EIIkSMk0IUQIkdIoAshRI6QQBdCiBwhgS6EEDni/wN0Z6CFBuWalgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# plotting\n",
    "x = np.arange(len(standardAcc))\n",
    "ax.plot(x, standardAcc, label=\"Standard model\")\n",
    "ax.plot(x, svdAcc1, label = \"SVD Model hh=1\")\n",
    "ax.plot(x, svdAcc20, label = \"SVD Model hh=20\")\n",
    "ax.plot(x, svdAcc60, label = \"SVD Model hh=60\")\n",
    "ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dear god we have to implement this\n",
    "* Implement a full transformer under the same rules as our previous network\n",
    "* To make our lives less miserable\n",
    "    * We will one hot encode the inputs so we don't have to implement an embedding layer\n",
    "        * If you think this is cheating we are sorry, but this is an amount of time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation difficulties\n",
    "* Transformers are at most steps are 3D tensors\n",
    "* This... This complicates the task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layernorm\n",
    "* We send the non affine steps off to torch\n",
    "* Implementing the affine steps is very difficult\n",
    "* And not implementing them doesn't seem to be breaking\n",
    "    * If this is an issue we will implement later it seems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "\n",
    "\n",
    "# this is a misnomer since it doesn't do bias lol\n",
    "# It's also wrong: todo fix\n",
    "class ElementWiseSVD(torch.nn.Module):\n",
    "    def __init__(self, N: int, M: int, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        print(f\"N: {N}, M: {M} \")\n",
    "        self.U = HouseOrth(N, **factory_kwargs)\n",
    "        self.singulars = Parameter(torch.empty(M, **factory_kwargs).uniform_(-1/math.sqrt(N), 1/math.sqrt(M)))\n",
    "        self.register_buffer(\"S\", torch.eye(N,M, **factory_kwargs)) # singulars are trainable - the matrix isn't (only the diagonal are parameters)\n",
    "        self.V = HouseOrth(M, **factory_kwargs)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # todo check if this reasonable\n",
    "        return self.V( (self.singulars/self.singulars.norm() * self.S).T @ self.U.affine(x))\n",
    "\n",
    "# Currently not doing any affine steps \n",
    "# It's bugged and it doesn't seem to be a big deal\n",
    "# It introduces very high singular values classically\n",
    "class LayerNormSVD(torch.nn.Module):\n",
    "    def __init__(self, normalized_shape: List[int], eps: float = 1e-5, elementwise_affine: bool = False,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super(LayerNormSVD, self).__init__()\n",
    "        if isinstance(normalized_shape, numbers.Integral):\n",
    "            # mypy error: incompatible types in assignment\n",
    "            normalized_shape = (normalized_shape,)  # type: ignore[assignment]\n",
    "        self.normalized_shape = tuple(normalized_shape)\n",
    "        self.eps = eps\n",
    "        self.elementwise_affine = elementwise_affine\n",
    "        if self.elementwise_affine:\n",
    "            if len(self.normalized_shape) > 2: raise RuntimeError(\"Please god\")\n",
    "            # Yea so we treat a 1D tensor as a unsqueeze 2D tensor this \n",
    "            # makes the problem svd-able\n",
    "            special_shape = self.normalized_shape if len(normalized_shape) == 2 else tuple([normalized_shape[0], 1])\n",
    "            self.svdWeight = ElementWiseSVD(special_shape[0], special_shape[1])\n",
    "            #self.weight = Parameter(torch.empty(self.normalized_shape, **factory_kwargs))\n",
    "            self.bias = Parameter(torch.zeros(self.normalized_shape, **factory_kwargs))\n",
    "        else:\n",
    "            #self.register_parameter('weight', None)\n",
    "            self.register_parameter('bias', None)\n",
    "    def forward(self, x: Tensor):\n",
    "        nonaffinestep = F.layer_norm(x, self.normalized_shape,eps=self.eps)\n",
    "        if self.elementwise_affine:\n",
    "            return self.svdWeight(nonaffinestep) + self.bias\n",
    "        return nonaffinestep\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reimplementing LinearSVD etc for 3 Tensors\n",
    "* Why are we reimplementing rather than replacing earlier\n",
    "    * Honestly we do not know if the math here is at all reasonable\n",
    "    * Not that our confidence levels earlier are super high\n",
    "    * But this is lower\n",
    "\n",
    "#### New methods\n",
    "* Split\n",
    "    * Split is a method you could normally apply to a weight matrix\n",
    "    * We only need to segment $U$ to be the new specified shapes\n",
    "    * But we can't just emit new LinearSVD's because this makes more parameters\n",
    "        * *Breaks the gradient*\n",
    "    * So we have a special function that does forward_split\n",
    "        * This also requires shaped_forward for houseOrth - the implementation details are fairly annoying\n",
    "        * But if you do out the math it should all check out\n",
    "\n",
    "#### The singular values aren't enforced to be norm 1\n",
    "* This is mentioned later but forcing the singular values to be norm 1 basically prevented learning\n",
    "* To show the implementation works we try a couple different length enforcement rules, sqrt(N) is shown in results\n",
    "* This is unfortunate but it at least verifies the implementation is most likely correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HouseOrth(torch.nn.Module):\n",
    "    def __init__(self, N: int, device=None, dtype=None):\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        # random initialization... this could be improved\n",
    "        self.U = Parameter(householder(torch.empty(N,1, **factory_kwargs).uniform_(-1/math.sqrt(N), 1/math.sqrt(N))))\n",
    "    \n",
    "    # yea this is kinda insane\n",
    "    def forward(self, x: Tensor):\n",
    "        return x @ self.U\n",
    "\n",
    "    def shaped_forward(self, x: Tensor, s0: int, s1: int):\n",
    "        return x @ self.U[:, s0:s1]\n",
    "\n",
    "\n",
    "# yes this again... sorry\n",
    "def setHouseOrthNHouseHolders(n_householders):\n",
    "    \"\"\"\n",
    "    Father forgive me for I hath sinned\n",
    "    \"\"\"\n",
    "    u = [f\"\\t\\tself.U{i} = Parameter(householder(torch.empty(N,1, **factory_kwargs).uniform_(-1/math.sqrt(N), 1/math.sqrt(N))))\" for i in range(n_householders)]\n",
    "    u = '\\n'.join(u)\n",
    "    u = u.replace(\"\\t\", \" \"*4)\n",
    "    def helper(i):\n",
    "        if i == 0:\n",
    "            return \"x @ self.U0\"\n",
    "        return f\"({helper(i-1)}) @ self.U{i}\"\n",
    "    \n",
    "    def helper_shaped(i):\n",
    "        if i == 0:\n",
    "            return \"x @ self.U0[:, s0:s1]\"\n",
    "        return f\"({helper(i-1)}) @ self.U{i}[:,s0:s1]\"\n",
    "\n",
    "    s = f\"\"\"\n",
    "class HouseOrth(torch.nn.Module):\n",
    "    def __init__(self, N: int, device=None, dtype=None):\n",
    "        factory_kwargs = {{'device': device, 'dtype': dtype}}\n",
    "        super().__init__()\n",
    "        # random initialization... this could be improved\n",
    "{u}\n",
    "    def forward(self, x: Tensor):\n",
    "        \n",
    "        return {helper(n_householders-1)}\n",
    "    \n",
    "    def shaped_forward(self, x: Tensor, s0: int, s1: int):\n",
    "        return {helper_shaped(n_householders-1)}\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "from typing import Union\n",
    "class LinearSVD(torch.nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True, device=None, dtype=None):\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        N,M = in_features, out_features\n",
    "        self.N, self.M = N,M\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.U = HouseOrth(N, **factory_kwargs)\n",
    "        # we normalize the singular values in the multiplication - smart initialization probably doesn't matter too much\n",
    "        # and if it does we do not know what that would be\n",
    "        self.singulars = Parameter(torch.empty(M, **factory_kwargs).uniform_(-1/math.sqrt(out_features), 1/math.sqrt(in_features)))\n",
    "        self.register_buffer(\"S\", torch.eye(N,M, **factory_kwargs)) # singulars are trainable - the matrix isn't (only the diagonal are parameters)\n",
    "        self.V = HouseOrth(M, **factory_kwargs) # Whether or not this is transposed doesn't really matter - its valid either way just a diff matrix\n",
    "        # copy torch.nn.Linear for what its worth here\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty((out_features,), **factory_kwargs) )\n",
    "            #step = self.U()\n",
    "            u = self.U.U if hasattr(self.U, \"U\") else self.U.U0 # householder overwrite mess\n",
    "            step = u @( (self.singulars*self.S))\n",
    "            step2 = self.V(step)\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(step2)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "    \n",
    "    def forward_split(self, tensors: List[Tensor], shapes: List[int]) ->  List[Tensor]:\n",
    "        \"\"\"\n",
    "        implementation of torch.split but now done on the network\n",
    "        \"\"\"\n",
    "        #if dim != 0:\n",
    "        #    raise RuntimeError(\"Not implemented yet, dim must equal 0\")\n",
    "        if isinstance(shapes, list) == False:\n",
    "            raise RuntimeError(\"shapes must be a list... please let this be true\")\n",
    "        s0 = 0\n",
    "        outs: List[Tensor] = []\n",
    "        for s, t in zip(shapes,tensors):\n",
    "            u = self.U(t)\n",
    "            singular = u @ (self.singulars/self.singulars.norm() *(self.in_features**.5) * self.S)\n",
    "            v = self.V.shaped_forward(singular, s0, s0+s) #.U[:, s0:s0+s]\n",
    "            s0+=s\n",
    "            outs.append(v)\n",
    "        return outs\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        #print(self.U.U.shape)\n",
    "        #self.U(x)\n",
    "        step = self.U(x)\n",
    "        step2 = step @ (self.singulars/self.singulars.norm()*(self.in_features**.5)  * self.S)\n",
    "        step = self.V( step2 )\n",
    "        if self.bias is not None:\n",
    "            return step + self.bias\n",
    "        else:\n",
    "            return step\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All of the following code is fundamentally copied\n",
    "* We take from TrueGrad which takes from pytorch implementation I believe\n",
    "* For the sake of being able to navigate the most insane jupyter notebook ever, I don't include the citations\n",
    "    * But it is copied! Changing only to respect SVD linear implementation\n",
    "#### To be clear that doesn't really mean this part is easy\n",
    "* It is by far the worst part so far\n",
    "* Just want to attribute correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _in_projection(\n",
    "        q: Tensor,\n",
    "        k: Tensor,\n",
    "        v: Tensor,\n",
    "        svdQ: LinearSVD,\n",
    "        svdK: LinearSVD,\n",
    "        svdV: LinearSVD,\n",
    "        b_q: Optional[Tensor] = None,\n",
    "        b_k: Optional[Tensor] = None,\n",
    "        b_v: Optional[Tensor] = None,\n",
    "        ) -> Tuple[Tensor, Tensor, Tensor]:\n",
    "    w_qShape = tuple([svdQ.in_features, svdQ.out_features])\n",
    "    w_kShape = tuple([svdK.in_features, svdK.out_features])\n",
    "    w_vShape = tuple([svdV.in_features, svdV.out_features])\n",
    "    Eq, Ek, Ev = q.size(-1), k.size(-1), v.size(-1)\n",
    "    assert w_qShape == (Eq, Eq), f\"expecting query weights shape of {(Eq, Eq)}, but got {w_qShape}\"\n",
    "    assert w_kShape== (Eq, Ek), f\"expecting key weights shape of {(Eq, Ek)}, but got {w_kShape}\"\n",
    "    assert w_vShape == (Eq, Ev), f\"expecting value weights shape of {(Eq, Ev)}, but got {w_vShape}\"\n",
    "    # todo biases...\n",
    "    sq = svdQ(q)\n",
    "    #print(\"Computed svdQ\")\n",
    "    sk = svdK(k)\n",
    "    sv = svdV(v)\n",
    "    return svdQ(q), svdK(k), svdV(v)\n",
    "\n",
    "def _in_projection_packed(\n",
    "        q: Tensor,\n",
    "        k: Tensor,\n",
    "        v: Tensor,\n",
    "        wSVD: LinearSVD,\n",
    "        w: Tensor,\n",
    "        b: Optional[Tensor] = None,\n",
    "        ) -> List[Tensor]:\n",
    "    E = q.size(-1) # this is embed size\n",
    "    if k is v:\n",
    "        if q is k:\n",
    "            # self-attention\n",
    "            #print(f\"Begin k=v=q: {q.shape}, wSVD: U: {wSVD.U.U.shape} V: {wSVD.V.U.shape}\")\n",
    "            return wSVD.forward(q).chunk(3, -1)\n",
    "        else:\n",
    "            # encoder-decoder attention\n",
    "\n",
    "            [l1, l2] = wSVD.forward_split([q, k], [E, E*2])\n",
    "            \n",
    "            if b is None:\n",
    "                b_q = b_kv = 0 #None, 0 not none because I use + not linear method\n",
    "            else:\n",
    "                b_q, b_kv = torch.split(b, [E, E * 2], 0)\n",
    "            return (l1 + b_q,) + (l2 + b_kv).chunk(2, -1)\n",
    "    else:\n",
    "        #w_q, w_k, w_v = chunk(w, 3, 0)\n",
    "        [l1, l2, l3] = wSVD.forward_split([q,k,v], [E, E, E])\n",
    "        if b is None:\n",
    "            b_q = b_k = b_v = 0 # Can't be none cuz linear rules\n",
    "        else:\n",
    "            b_q, b_k, b_v = torch.chunk(b, 3, 0)\n",
    "        return l1 + b_q, l2 + b_k, l3 + b_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def _mha_shape_check(query: Tensor, key: Tensor, value: Tensor,\n",
    "                     key_padding_mask: Optional[Tensor], attn_mask: Optional[Tensor], num_heads: int):\n",
    "    # Verifies the expected shape for `query, `key`, `value`, `key_padding_mask` and `attn_mask`\n",
    "    # and returns if the input is batched or not.\n",
    "    # Raises an error if `query` is not 2-D (unbatched) or 3-D (batched) tensor.\n",
    "\n",
    "    # Shape check.\n",
    "    if query.dim() == 3:\n",
    "        # Batched Inputs\n",
    "        is_batched = True\n",
    "        assert key.dim() == 3 and value.dim() == 3, \\\n",
    "            (\"For batched (3-D) `query`, expected `key` and `value` to be 3-D\"\n",
    "             f\" but found {key.dim()}-D and {value.dim()}-D tensors respectively\")\n",
    "        if key_padding_mask is not None:\n",
    "            assert key_padding_mask.dim() == 2, \\\n",
    "                (\"For batched (3-D) `query`, expected `key_padding_mask` to be `None` or 2-D\"\n",
    "                 f\" but found {key_padding_mask.dim()}-D tensor instead\")\n",
    "        if attn_mask is not None:\n",
    "            assert attn_mask.dim() in (2, 3), \\\n",
    "                (\"For batched (3-D) `query`, expected `attn_mask` to be `None`, 2-D or 3-D\"\n",
    "                 f\" but found {attn_mask.dim()}-D tensor instead\")\n",
    "    elif query.dim() == 2:\n",
    "        # Unbatched Inputs\n",
    "        is_batched = False\n",
    "        assert key.dim() == 2 and value.dim() == 2, \\\n",
    "            (\"For unbatched (2-D) `query`, expected `key` and `value` to be 2-D\"\n",
    "             f\" but found {key.dim()}-D and {value.dim()}-D tensors respectively\")\n",
    "\n",
    "        if key_padding_mask is not None:\n",
    "            assert key_padding_mask.dim() == 1, \\\n",
    "                (\"For unbatched (2-D) `query`, expected `key_padding_mask` to be `None` or 1-D\"\n",
    "                 f\" but found {key_padding_mask.dim()}-D tensor instead\")\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            assert attn_mask.dim() in (2, 3), \\\n",
    "                (\"For unbatched (2-D) `query`, expected `attn_mask` to be `None`, 2-D or 3-D\"\n",
    "                 f\" but found {attn_mask.dim()}-D tensor instead\")\n",
    "            if attn_mask.dim() == 3:\n",
    "                expected_shape = (num_heads, query.shape[0], key.shape[0])\n",
    "                assert attn_mask.shape == expected_shape, \\\n",
    "                    (f\"Expected `attn_mask` shape to be {expected_shape} but got {attn_mask.shape}\")\n",
    "    else:\n",
    "        raise AssertionError(\n",
    "                f\"query should be unbatched 2D or batched 3D tensor but received {query.dim()}-D query tensor\")\n",
    "\n",
    "    return is_batched\n",
    "\n",
    "import warnings\n",
    "def multi_head_attention_forward(query: Tensor, key: Tensor, value: Tensor, embed_dim_to_check: int,\n",
    "                                 num_heads: int,\n",
    "                                 in_proj_svd: Optional[LinearSVD], \n",
    "                                 #in_proj_weight: Optional[Tensor],\n",
    "                                 in_proj_bias: Optional[Tensor], # keeping the biases sue me\n",
    "                                 bias_k: Optional[Tensor],\n",
    "                                 bias_v: Optional[Tensor], \n",
    "                                 add_zero_attn: bool, \n",
    "                                 dropout_p: float,\n",
    "                                 out_projSVD: LinearSVD,\n",
    "                                 #out_proj_weight: Tensor, \n",
    "                                 #out_proj_bias: Optional[Tensor],\n",
    "                                 training: bool = True, \n",
    "                                 key_padding_mask: Optional[Tensor] = None,\n",
    "                                 need_weights: bool = True, attn_mask: Optional[Tensor] = None,\n",
    "                                 use_separate_proj_weight: bool = False,\n",
    "                                 \n",
    "                                 q_projSVD: Optional[LinearSVD] = None,\n",
    "                                 k_projSVD: Optional[LinearSVD] = None,\n",
    "                                 v_projSVD: Optional[LinearSVD] = None,\n",
    "                                 #q_proj_weight: Optional[Tensor] = None,\n",
    "                                 #k_proj_weight: Optional[Tensor] = None,\n",
    "                                 #v_proj_weight: Optional[Tensor] = None,\n",
    "                                 static_k: Optional[Tensor] = None,\n",
    "                                 static_v: Optional[Tensor] = None, average_attn_weights: bool = True):\n",
    "\n",
    "    #print(f\"Begin multi_head_attention_forward\")\n",
    "    is_batched = _mha_shape_check(query, key, value, key_padding_mask, attn_mask, num_heads)\n",
    "    if not is_batched:\n",
    "        # unsqueeze if the input is unbatched\n",
    "        query = query.unsqueeze(1)\n",
    "        key = key.unsqueeze(1)\n",
    "        value = value.unsqueeze(1)\n",
    "        if key_padding_mask is not None:\n",
    "            key_padding_mask = key_padding_mask.unsqueeze(0)\n",
    "    tgt_len, bsz, embed_dim = query.shape\n",
    "    src_len, _, _ = key.shape\n",
    "    if key_padding_mask is not None:\n",
    "        _kpm_dtype = key_padding_mask.dtype\n",
    "        if _kpm_dtype != torch.bool and not torch.is_floating_point(key_padding_mask):\n",
    "            raise AssertionError(\n",
    "                    \"only bool and floating types of key_padding_mask are supported\")\n",
    "    assert embed_dim == embed_dim_to_check, \\\n",
    "        f\"was expecting embedding dimension of {embed_dim_to_check}, but got {embed_dim}\"\n",
    "    if isinstance(embed_dim, torch.Tensor):\n",
    "        # embed_dim can be a tensor when JIT tracing\n",
    "        head_dim = embed_dim.div(num_heads, rounding_mode='trunc')\n",
    "    else:\n",
    "        head_dim = embed_dim // num_heads\n",
    "    assert head_dim * num_heads == embed_dim, f\"embed_dim {embed_dim} not divisible by num_heads {num_heads}\"\n",
    "    if use_separate_proj_weight:\n",
    "        # allow MHA to have different embedding dimensions when separate projection weights are used\n",
    "        assert key.shape[:2] == value.shape[:2], \\\n",
    "            f\"key's sequence and batch dims {key.shape[:2]} do not match value's {value.shape[:2]}\"\n",
    "    else:\n",
    "        assert key.shape == value.shape, f\"key shape {key.shape} does not match value shape {value.shape}\"\n",
    "    \n",
    "\n",
    "    #print(f\"Before this is different\")\n",
    "    # THIS IS DIFFERENT\n",
    "    if not use_separate_proj_weight:\n",
    "        assert in_proj_svd is not None, \"use_separate_proj_weight is False but in_proj_weight is None\"\n",
    "        q, k, v = _in_projection_packed(query, key, value, in_proj_svd, in_proj_bias)\n",
    "    else:\n",
    "        assert q_projSVD is not None, \"use_separate_proj_weight is True but q_proj_weight is None\"\n",
    "        assert k_projSVD is not None, \"use_separate_proj_weight is True but k_proj_weight is None\"\n",
    "        assert v_projSVD is not None, \"use_separate_proj_weight is True but v_proj_weight is None\"\n",
    "        if in_proj_bias is None:\n",
    "            b_q = b_k = b_v = None\n",
    "        else:\n",
    "            b_q, b_k, b_v = torch.chunk(in_proj_bias, 3, 0)\n",
    "        q, k, v = _in_projection(query, key, value, q_projSVD, k_projSVD, v_projSVD, b_q, b_k, b_v)\n",
    "    \n",
    "    #print(\"Computed _in_projection\")\n",
    "    # ----- UNCHANGED ---------------\n",
    "    # prep attention mask\n",
    "    if attn_mask is not None:\n",
    "        if attn_mask.dtype == torch.uint8:\n",
    "            warnings.warn(\"Byte tensor for attn_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.\")\n",
    "            attn_mask = attn_mask.to(torch.bool)\n",
    "        else:\n",
    "            assert attn_mask.is_floating_point() or attn_mask.dtype == torch.bool, \\\n",
    "                f\"Only float, byte, and bool types are supported for attn_mask, not {attn_mask.dtype}\"\n",
    "        # ensure attn_mask's dim is 3\n",
    "        if attn_mask.dim() == 2:\n",
    "            correct_2d_size = (tgt_len, src_len)\n",
    "            if attn_mask.shape != correct_2d_size:\n",
    "                raise RuntimeError(\n",
    "                        f\"The shape of the 2D attn_mask is {attn_mask.shape}, but should be {correct_2d_size}.\")\n",
    "            attn_mask = attn_mask.unsqueeze(0)\n",
    "        elif attn_mask.dim() == 3:\n",
    "            correct_3d_size = (bsz * num_heads, tgt_len, src_len)\n",
    "            if attn_mask.shape != correct_3d_size:\n",
    "                raise RuntimeError(\n",
    "                        f\"The shape of the 3D attn_mask is {attn_mask.shape}, but should be {correct_3d_size}.\")\n",
    "        else:\n",
    "            raise RuntimeError(f\"attn_mask's dimension {attn_mask.dim()} is not supported\")\n",
    "    # add bias along batch dimension (currently second)\n",
    "    if bias_k is not None and bias_v is not None:\n",
    "        assert static_k is None, \"bias cannot be added to static key.\"\n",
    "        assert static_v is None, \"bias cannot be added to static value.\"\n",
    "        k = torch.cat([k, bias_k.repeat(1, bsz, 1)])\n",
    "        v = torch.cat([v, bias_v.repeat(1, bsz, 1)])\n",
    "        if attn_mask is not None:\n",
    "            attn_mask = F.pad(attn_mask, (0, 1))\n",
    "        if key_padding_mask is not None:\n",
    "            key_padding_mask = F.pad(key_padding_mask, (0, 1))\n",
    "    else:\n",
    "        assert bias_k is None\n",
    "        assert bias_v is None\n",
    "\n",
    "    #\n",
    "    # reshape q, k, v for multihead attention and make em batch first\n",
    "    #\n",
    "    q = q.contiguous().view(tgt_len, bsz * num_heads, head_dim).transpose(0, 1)\n",
    "    if static_k is None:\n",
    "        k = k.contiguous().view(k.shape[0], bsz * num_heads, head_dim).transpose(0, 1)\n",
    "    else:\n",
    "        # TODO finish disentangling control flow so we don't do in-projections when statics are passed\n",
    "        assert static_k.size(0) == bsz * num_heads, \\\n",
    "            f\"expecting static_k.size(0) of {bsz * num_heads}, but got {static_k.size(0)}\"\n",
    "        assert static_k.size(2) == head_dim, \\\n",
    "            f\"expecting static_k.size(2) of {head_dim}, but got {static_k.size(2)}\"\n",
    "        k = static_k\n",
    "    if static_v is None:\n",
    "        v = v.contiguous().view(v.shape[0], bsz * num_heads, head_dim).transpose(0, 1)\n",
    "    else:\n",
    "        # TODO finish disentangling control flow so we don't do in-projections when statics are passed\n",
    "        assert static_v.size(0) == bsz * num_heads, \\\n",
    "            f\"expecting static_v.size(0) of {bsz * num_heads}, but got {static_v.size(0)}\"\n",
    "        assert static_v.size(2) == head_dim, \\\n",
    "            f\"expecting static_v.size(2) of {head_dim}, but got {static_v.size(2)}\"\n",
    "        v = static_v\n",
    "    \n",
    "    # add zero attention along batch dimension (now first)\n",
    "    if add_zero_attn:\n",
    "        zero_attn_shape = (bsz * num_heads, 1, head_dim)\n",
    "        k = torch.cat([k, torch.zeros(zero_attn_shape, dtype=k.dtype, device=k.device)], dim=1)\n",
    "        v = torch.cat([v, torch.zeros(zero_attn_shape, dtype=v.dtype, device=v.device)], dim=1)\n",
    "        if attn_mask is not None:\n",
    "            attn_mask = F.pad(attn_mask, (0, 1))\n",
    "        if key_padding_mask is not None:\n",
    "            key_padding_mask = F.pad(key_padding_mask, (0, 1))\n",
    "\n",
    "    # update source sequence length after adjustments\n",
    "    src_len = k.size(1)\n",
    "\n",
    "    # merge key padding and attention masks\n",
    "    if key_padding_mask is not None:\n",
    "        assert key_padding_mask.shape == (bsz, src_len), \\\n",
    "            f\"expecting key_padding_mask shape of {(bsz, src_len)}, but got {key_padding_mask.shape}\"\n",
    "        key_padding_mask = key_padding_mask.view(bsz, 1, 1, src_len). \\\n",
    "            expand(-1, num_heads, -1, -1).reshape(bsz * num_heads, 1, src_len)\n",
    "        if attn_mask is None:\n",
    "            attn_mask = key_padding_mask\n",
    "        elif attn_mask.dtype == torch.bool:\n",
    "            attn_mask = attn_mask.logical_or(key_padding_mask)\n",
    "        else:\n",
    "            attn_mask = attn_mask.masked_fill(key_padding_mask, float(\"-inf\"))\n",
    "    \n",
    "    # convert mask to float\n",
    "    if attn_mask is not None and attn_mask.dtype == torch.bool:\n",
    "        new_attn_mask = torch.zeros_like(attn_mask, dtype=q.dtype)\n",
    "        new_attn_mask.masked_fill_(attn_mask, float(\"-inf\"))\n",
    "        attn_mask = new_attn_mask\n",
    "\n",
    "    # adjust dropout probability\n",
    "    if not training:\n",
    "        dropout_p = 0.0\n",
    "    \n",
    "    #\n",
    "    # (deep breath) calculate attention and out projection\n",
    "    #\n",
    "\n",
    "    B, Nt, E = q.shape\n",
    "    q_scaled = q / math.sqrt(E)\n",
    "    if attn_mask is not None:\n",
    "        attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))\n",
    "    else:\n",
    "        attn_output_weights = torch.bmm(q_scaled, k.transpose(-2, -1))\n",
    "    attn_output_weights = F.softmax(attn_output_weights, dim=-1)\n",
    "    if dropout_p > 0.0:\n",
    "        attn_output_weights = F.dropout(attn_output_weights, p=dropout_p)\n",
    "\n",
    "    attn_output = torch.bmm(attn_output_weights, v)\n",
    "\n",
    "    attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len * bsz, embed_dim)\n",
    "    # ------------- FINISH UNCHANGED -----------------------\n",
    "    # THIS IS CHANGED\n",
    "    attn_output = out_projSVD.forward(attn_output) #+ out_proj_bias #linear(attn_output, out_proj_weight, out_proj_bias)\n",
    "    # FINISH CHANGE\n",
    "    attn_output = attn_output.view(tgt_len, bsz, attn_output.size(1))\n",
    "\n",
    "    if need_weights:\n",
    "        # optionally average attention weights over heads\n",
    "        attn_output_weights = attn_output_weights.view(bsz, num_heads, tgt_len, src_len)\n",
    "        if average_attn_weights:\n",
    "            attn_output_weights = attn_output_weights.sum(dim=1) / num_heads\n",
    "\n",
    "        if not is_batched:\n",
    "            # squeeze the output if input was unbatched\n",
    "            attn_output = attn_output.squeeze(1)\n",
    "            attn_output_weights = attn_output_weights.squeeze(0)\n",
    "        return attn_output, attn_output_weights\n",
    "    else:\n",
    "        if not is_batched:\n",
    "            # squeeze the output if input was unbatched\n",
    "            attn_output = attn_output.squeeze(1)\n",
    "        return attn_output, None\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Callable\n",
    "\n",
    "class MultiheadAttentionSVD(torch.nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0., bias=True, add_bias_kv=False, add_zero_attn=False,\n",
    "                 kdim=None, vdim=None, batch_first=False, device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super(MultiheadAttentionSVD, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.kdim = kdim if kdim is not None else embed_dim\n",
    "        self.vdim = vdim if vdim is not None else embed_dim\n",
    "        self._qkv_same_embed_dim = self.kdim == embed_dim and self.vdim == embed_dim\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.batch_first = batch_first\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        assert self.head_dim * num_heads == self.embed_dim, \"embed_dim must be divisible by num_heads\"\n",
    "\n",
    "        if not self._qkv_same_embed_dim:\n",
    "            # Parameters are backwards with respect to weight matrices\n",
    "            self.q_proj_weight = LinearSVD(embed_dim, embed_dim, **factory_kwargs) #Parameter(torch.empty((embed_dim, embed_dim), **factory_kwargs))\n",
    "            self.k_proj_weight = LinearSVD(self.kdim, embed_dim, **factory_kwargs) #Parameter(torch.empty((embed_dim, self.kdim), **factory_kwargs))\n",
    "            self.v_proj_weight = LinearSVD(self.vdim, embed_dim, **factory_kwargs) #Parameter(torch.empty((embed_dim, self.vdim), **factory_kwargs))\n",
    "            self.register_parameter('in_projSVD', None)\n",
    "        else:\n",
    "            self.in_projSVD = LinearSVD(embed_dim, 3*embed_dim) #Parameter(torch.empty((3 * embed_dim, embed_dim), **factory_kwargs))\n",
    "            self.register_parameter('q_proj_weight', None)\n",
    "            self.register_parameter('k_proj_weight', None)\n",
    "            self.register_parameter('v_proj_weight', None)\n",
    "        \n",
    "        if bias:\n",
    "            # init to 0\n",
    "            self.in_proj_bias = Parameter(torch.zeros(3 * embed_dim, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('in_proj_bias', None)\n",
    "        \n",
    "        self.out_proj = LinearSVD(embed_dim, embed_dim, bias=bias, **factory_kwargs)\n",
    "\n",
    "        if add_bias_kv:\n",
    "            self.bias_k = Parameter(init.xavier_normal_(torch.empty((1, 1, embed_dim), **factory_kwargs)))\n",
    "            self.bias_v = Parameter(init.xavier_normal_(torch.empty((1, 1, embed_dim), **factory_kwargs)))\n",
    "        else:\n",
    "            self.bias_k = self.bias_v = None\n",
    "\n",
    "        self.add_zero_attn = add_zero_attn\n",
    "    \n",
    "    def forward(self, query: Tensor, key: Tensor, value: Tensor, key_padding_mask: Optional[Tensor] = None,\n",
    "                need_weights: bool = True, attn_mask: Optional[Tensor] = None,\n",
    "                average_attn_weights: bool = True) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        # We assume no fast path for sanity\n",
    "        is_batched = query.dim() == 3\n",
    "        if self.batch_first and is_batched:\n",
    "            # make sure that the transpose op does not affect the \"is\" property\n",
    "            if key is value:\n",
    "                if query is key:\n",
    "                    query = key = value = query.transpose(1, 0)\n",
    "                else:\n",
    "                    query, key = [x.transpose(1, 0) for x in (query, key)]\n",
    "                    value = key\n",
    "            else:\n",
    "                query, key, value = [x.transpose(1, 0) for x in (query, key, value)]\n",
    "        \n",
    "        if not self._qkv_same_embed_dim:\n",
    "            attn_output, attn_output_weights = multi_head_attention_forward(\n",
    "                query, key, value, self.embed_dim, self.num_heads,\n",
    "                self.in_projSVD, self.in_proj_bias, self.bias_k, self.bias_v, self.add_zero_attn,\n",
    "                self.dropout, self.out_proj, training=self.training,\n",
    "                key_padding_mask=key_padding_mask, need_weights=need_weights,\n",
    "                attn_mask=attn_mask, use_separate_proj_weight=True,\n",
    "                q_projSVD=self.q_proj_weight, k_projSVD=self.k_proj_weight,\n",
    "                v_projSVD=self.v_proj_weight, average_attn_weights=average_attn_weights\n",
    "            )\n",
    "        else:\n",
    "            attn_output, attn_output_weights = multi_head_attention_forward(\n",
    "                query, key, value, self.embed_dim, self.num_heads,\n",
    "                self.in_projSVD, self.in_proj_bias, self.bias_k, self.bias_v,\n",
    "                self.add_zero_attn, self.dropout, self.out_proj, training=self.training,\n",
    "                key_padding_mask=key_padding_mask, need_weights=need_weights,\n",
    "                attn_mask=attn_mask, average_attn_weights=average_attn_weights\n",
    "            )\n",
    "        if self.batch_first and is_batched:\n",
    "            return attn_output.transpose(1, 0), attn_output_weights\n",
    "        else:\n",
    "            return attn_output, attn_output_weights\n",
    "\n",
    "\n",
    "\n",
    "class TransformerDecoderLayerSVD(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, nhead: int, dim_feedforward: int = 2048, dropout: float = 0.1,\n",
    "                 activation: Union[str, Callable[[Tensor], Tensor]] = F.relu,\n",
    "                 layer_norm_eps: float = 1e-5, batch_first: bool = False, norm_first: bool = False,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super(TransformerDecoderLayerSVD, self).__init__()\n",
    "        self.self_attn = MultiheadAttentionSVD(d_model, nhead, dropout=dropout, batch_first=batch_first,\n",
    "                                            **factory_kwargs)\n",
    "        self.multihead_attn = MultiheadAttentionSVD(d_model, nhead, dropout=dropout, batch_first=batch_first,\n",
    "                                                 **factory_kwargs)\n",
    "        # Implementation of Feedforward model\n",
    "        self.linear1 = LinearSVD(d_model, dim_feedforward, **factory_kwargs)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.linear2 = LinearSVD(dim_feedforward, d_model, **factory_kwargs)\n",
    "\n",
    "        self.norm_first = norm_first\n",
    "        self.norm1 = LayerNormSVD(d_model, eps=layer_norm_eps, **factory_kwargs)\n",
    "        self.norm2 = LayerNormSVD(d_model, eps=layer_norm_eps, **factory_kwargs)\n",
    "        self.norm3 = LayerNormSVD(d_model, eps=layer_norm_eps, **factory_kwargs)\n",
    "        self.dropout1 = torch.nn.Dropout(dropout)\n",
    "        self.dropout2 = torch.nn.Dropout(dropout)\n",
    "        self.dropout3 = torch.nn.Dropout(dropout)\n",
    "\n",
    "        # Legacy string support for activation function.\n",
    "        if isinstance(activation, str):\n",
    "            raise RuntimeError(\"Dont do this\")\n",
    "        else:\n",
    "            self.activation = activation\n",
    "    \n",
    "    def __setstate__(self, state):\n",
    "        if 'activation' not in state:\n",
    "            state['activation'] = F.relu\n",
    "        super(TransformerDecoderLayerSVD, self).__setstate__(state)\n",
    "    \n",
    "    def forward(self, tgt: Tensor, memory: Tensor, tgt_mask: Optional[Tensor] = None, memory_mask: Optional[Tensor] = None,\n",
    "                tgt_key_padding_mask: Optional[Tensor] = None, memory_key_padding_mask: Optional[Tensor] = None) -> Tensor:\n",
    "\n",
    "        x = tgt\n",
    "        if self.norm_first:\n",
    "            x = x + self._sa_block(self.norm1(x), tgt_mask, tgt_key_padding_mask)\n",
    "            x = x + self._mha_block(self.norm2(x), memory, memory_mask, memory_key_padding_mask)\n",
    "            x = x + self._ff_block(self.norm3(x))\n",
    "        else:\n",
    "            x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))\n",
    "            x = self.norm2(x + self._mha_block(x, memory, memory_mask, memory_key_padding_mask))\n",
    "            x = self.norm3(x + self._ff_block(x))\n",
    "\n",
    "        return x\n",
    "    # self-attention block\n",
    "    def _sa_block(self, x: Tensor,\n",
    "                  attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) -> Tensor:\n",
    "        #print(f\"Begin _sa_block\")\n",
    "        x = self.self_attn(x, x, x,\n",
    "                           attn_mask=attn_mask,\n",
    "                           key_padding_mask=key_padding_mask,\n",
    "                           need_weights=False)[0]\n",
    "        #print(f\"Finish _sa_block\")\n",
    "        return self.dropout1(x)\n",
    "\n",
    "    # multihead attention block\n",
    "    def _mha_block(self, x: Tensor, mem: Tensor,\n",
    "                   attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) -> Tensor:\n",
    "        x = self.multihead_attn.forward(x, mem, mem,\n",
    "                                attn_mask=attn_mask,\n",
    "                                key_padding_mask=key_padding_mask,\n",
    "                                need_weights=False)[0]\n",
    "        return self.dropout2(x)\n",
    "\n",
    "    # feed forward block\n",
    "    def _ff_block(self, x: Tensor) -> Tensor:\n",
    "        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
    "        return self.dropout3(x)\n",
    "\n",
    "import copy\n",
    "def _get_clones(module, N):\n",
    "    return torch.nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "# just useful for mnetal segmentation - doesn't really need to be copied\n",
    "class TransformerDecoderSVD(torch.nn.Module):\n",
    "    def __init__(self, decoder_layer, num_layers, norm=None):\n",
    "        super(TransformerDecoderSVD, self).__init__()\n",
    "        self.layers: List[TransformerDecoderLayerSVD] = _get_clones(decoder_layer, num_layers)\n",
    "        self.num_layers = num_layers\n",
    "        self.norm = norm\n",
    "    def forward(self, tgt: Tensor, memory: Tensor, tgt_mask: Optional[Tensor] = None,\n",
    "                memory_mask: Optional[Tensor] = None, tgt_key_padding_mask: Optional[Tensor] = None,\n",
    "                memory_key_padding_mask: Optional[Tensor] = None) -> Tensor:\n",
    "        \n",
    "        output = tgt\n",
    "\n",
    "        for mod in self.layers:\n",
    "            output = mod.forward(output, memory, tgt_mask=tgt_mask,\n",
    "                         memory_mask=memory_mask,\n",
    "                         tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                         memory_key_padding_mask=memory_key_padding_mask)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            output = self.norm(output)\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 5.316059e+00, training_accuracy 0.011538461782038212, valid_acc: 0.00986558198928833\n",
      "Epoch 2: loss 4.836143e+00, training_accuracy 0.01846153847873211, valid_acc: 0.008879023604094982\n",
      "Epoch 4: loss 4.697193e+00, training_accuracy 0.013846153393387794, valid_acc: 0.009125662967562675\n",
      "Epoch 6: loss 4.611234e+00, training_accuracy 0.016153845936059952, valid_acc: 0.011838697828352451\n",
      "Epoch 8: loss 4.588040e+00, training_accuracy 0.01923076994717121, valid_acc: 0.009372302331030369\n",
      "Epoch 10: loss 4.582402e+00, training_accuracy 0.020769231021404266, valid_acc: 0.008755703456699848\n",
      "Epoch 12: loss 4.537904e+00, training_accuracy 0.023846153169870377, valid_acc: 0.009002342820167542\n",
      "Epoch 14: loss 4.527625e+00, training_accuracy 0.023076923564076424, valid_acc: 0.007892465218901634\n",
      "Epoch 16: loss 4.482225e+00, training_accuracy 0.023076923564076424, valid_acc: 0.008879023604094982\n",
      "Epoch 18: loss 4.463223e+00, training_accuracy 0.02846153825521469, valid_acc: 0.007892465218901634\n",
      "Epoch 20: loss 4.453321e+00, training_accuracy 0.0315384604036808, valid_acc: 0.007645825855433941\n",
      "Epoch 22: loss 4.421412e+00, training_accuracy 0.03846153989434242, valid_acc: 0.008509064093232155\n",
      "Epoch 24: loss 4.379590e+00, training_accuracy 0.03846153989434242, valid_acc: 0.0077691455371677876\n",
      "Epoch 26: loss 4.362902e+00, training_accuracy 0.04384615272283554, valid_acc: 0.009002342820167542\n",
      "Epoch 28: loss 4.334793e+00, training_accuracy 0.04461538419127464, valid_acc: 0.008015785366296768\n",
      "Epoch 30: loss 4.298381e+00, training_accuracy 0.04615384712815285, valid_acc: 0.009125662967562675\n",
      "Epoch 32: loss 4.253373e+00, training_accuracy 0.05692307651042938, valid_acc: 0.008755703456699848\n",
      "Epoch 34: loss 4.171753e+00, training_accuracy 0.06615384668111801, valid_acc: 0.009002342820167542\n",
      "Epoch 36: loss 4.116100e+00, training_accuracy 0.08307692408561707, valid_acc: 0.008262424729764462\n",
      "Epoch 38: loss 4.106325e+00, training_accuracy 0.06769230961799622, valid_acc: 0.009618941694498062\n",
      "Epoch 40: loss 4.046295e+00, training_accuracy 0.08307692408561707, valid_acc: 0.009372302331030369\n",
      "Epoch 42: loss 4.003762e+00, training_accuracy 0.10076922923326492, valid_acc: 0.011345419101417065\n",
      "Epoch 44: loss 4.002333e+00, training_accuracy 0.08923076838254929, valid_acc: 0.00924898311495781\n",
      "Epoch 46: loss 3.974684e+00, training_accuracy 0.0915384590625763, valid_acc: 0.008879023604094982\n",
      "Epoch 48: loss 3.878270e+00, training_accuracy 0.10230769217014313, valid_acc: 0.010112221352756023\n",
      "Epoch 50: loss 3.793602e+00, training_accuracy 0.11769230663776398, valid_acc: 0.013318534940481186\n",
      "Epoch 52: loss 3.744506e+00, training_accuracy 0.14384615421295166, valid_acc: 0.01060550007969141\n",
      "Epoch 54: loss 3.717458e+00, training_accuracy 0.14153845608234406, valid_acc: 0.012578616850078106\n",
      "Epoch 56: loss 3.642032e+00, training_accuracy 0.14461538195610046, valid_acc: 0.014921692200005054\n",
      "Epoch 58: loss 3.619202e+00, training_accuracy 0.1553846150636673, valid_acc: 0.014305093325674534\n",
      "Epoch 60: loss 3.562602e+00, training_accuracy 0.16692307591438293, valid_acc: 0.013071895577013493\n",
      "Epoch 62: loss 3.511122e+00, training_accuracy 0.16384615004062653, valid_acc: 0.015908250585198402\n",
      "Epoch 64: loss 3.464880e+00, training_accuracy 0.1884615421295166, valid_acc: 0.017388086766004562\n",
      "Epoch 66: loss 3.470829e+00, training_accuracy 0.16076922416687012, valid_acc: 0.015414970926940441\n",
      "Epoch 68: loss 3.416053e+00, training_accuracy 0.190769225358963, valid_acc: 0.017264768481254578\n",
      "Epoch 70: loss 3.343486e+00, training_accuracy 0.20999999344348907, valid_acc: 0.02121100015938282\n",
      "Epoch 72: loss 3.333831e+00, training_accuracy 0.20692308247089386, valid_acc: 0.018004685640335083\n",
      "Epoch 74: loss 3.225382e+00, training_accuracy 0.2153846174478531, valid_acc: 0.0205944012850523\n",
      "Epoch 76: loss 3.166162e+00, training_accuracy 0.23999999463558197, valid_acc: 0.022567518055438995\n",
      "Epoch 78: loss 3.152448e+00, training_accuracy 0.23846153914928436, valid_acc: 0.024663953110575676\n",
      "Epoch 80: loss 3.114652e+00, training_accuracy 0.2546153962612152, valid_acc: 0.024293994531035423\n",
      "Epoch 82: loss 3.072873e+00, training_accuracy 0.2546153962612152, valid_acc: 0.025527192279696465\n",
      "Epoch 84: loss 2.994281e+00, training_accuracy 0.27000001072883606, valid_acc: 0.027993587777018547\n",
      "Epoch 86: loss 2.980746e+00, training_accuracy 0.26153847575187683, valid_acc: 0.024047354236245155\n",
      "Epoch 88: loss 2.980334e+00, training_accuracy 0.26384615898132324, valid_acc: 0.027007030323147774\n",
      "Epoch 90: loss 2.889555e+00, training_accuracy 0.2846153974533081, valid_acc: 0.027007030323147774\n",
      "Epoch 92: loss 2.824635e+00, training_accuracy 0.29846152663230896, valid_acc: 0.031199902296066284\n",
      "Epoch 94: loss 2.787063e+00, training_accuracy 0.3076923191547394, valid_acc: 0.03107658214867115\n",
      "Epoch 96: loss 2.733504e+00, training_accuracy 0.32076922059059143, valid_acc: 0.03144654259085655\n",
      "Epoch 98: loss 2.706657e+00, training_accuracy 0.3199999928474426, valid_acc: 0.03526945412158966\n",
      "Epoch 100: loss 2.754370e+00, training_accuracy 0.29923078417778015, valid_acc: 0.03526945412158966\n",
      "Epoch 102: loss 2.664369e+00, training_accuracy 0.3369230628013611, valid_acc: 0.035392772406339645\n",
      "Epoch 104: loss 2.622776e+00, training_accuracy 0.3446153998374939, valid_acc: 0.03613269329071045\n",
      "Epoch 106: loss 2.601765e+00, training_accuracy 0.3461538553237915, valid_acc: 0.0388457290828228\n",
      "Epoch 108: loss 2.473583e+00, training_accuracy 0.3799999952316284, valid_acc: 0.041682083159685135\n",
      "Epoch 110: loss 2.422119e+00, training_accuracy 0.38999998569488525, valid_acc: 0.041928719729185104\n",
      "Epoch 112: loss 2.454150e+00, training_accuracy 0.38923075795173645, valid_acc: 0.03970896452665329\n",
      "Epoch 114: loss 2.301208e+00, training_accuracy 0.42615383863449097, valid_acc: 0.04365519806742668\n",
      "Epoch 116: loss 2.304230e+00, training_accuracy 0.4323076903820038, valid_acc: 0.04513503611087799\n",
      "Epoch 118: loss 2.349571e+00, training_accuracy 0.39461538195610046, valid_acc: 0.042545318603515625\n",
      "Epoch 120: loss 2.323197e+00, training_accuracy 0.42230769991874695, valid_acc: 0.0442717969417572\n",
      "Epoch 122: loss 2.301410e+00, training_accuracy 0.4146153926849365, valid_acc: 0.04501171410083771\n",
      "Epoch 124: loss 2.201452e+00, training_accuracy 0.42461538314819336, valid_acc: 0.048834629356861115\n",
      "Epoch 126: loss 2.159476e+00, training_accuracy 0.46000000834465027, valid_acc: 0.050314467400312424\n",
      "Epoch 128: loss 2.125766e+00, training_accuracy 0.4646153748035431, valid_acc: 0.051547665148973465\n",
      "Epoch 130: loss 2.298610e+00, training_accuracy 0.41923075914382935, valid_acc: 0.046121593564748764\n",
      "Epoch 132: loss 2.043124e+00, training_accuracy 0.4753846228122711, valid_acc: 0.05623381584882736\n",
      "Epoch 134: loss 2.089051e+00, training_accuracy 0.45230770111083984, valid_acc: 0.05426069721579552\n",
      "Epoch 136: loss 1.924837e+00, training_accuracy 0.5138461589813232, valid_acc: 0.05796029046177864\n",
      "Epoch 138: loss 1.840250e+00, training_accuracy 0.5453846454620361, valid_acc: 0.060796644538640976\n",
      "Epoch 140: loss 2.027158e+00, training_accuracy 0.4699999988079071, valid_acc: 0.05463065952062607\n",
      "Epoch 142: loss 1.856607e+00, training_accuracy 0.5261538624763489, valid_acc: 0.05944012850522995\n",
      "Epoch 144: loss 1.816981e+00, training_accuracy 0.5446153879165649, valid_acc: 0.0621531642973423\n",
      "Epoch 146: loss 1.774201e+00, training_accuracy 0.557692289352417, valid_acc: 0.061659883707761765\n",
      "Epoch 148: loss 1.699177e+00, training_accuracy 0.5661538243293762, valid_acc: 0.06585275381803513\n",
      "Epoch 150: loss 1.738477e+00, training_accuracy 0.5476922988891602, valid_acc: 0.06597607582807541\n",
      "Epoch 152: loss 1.617573e+00, training_accuracy 0.5915384888648987, valid_acc: 0.07078554481267929\n",
      "Epoch 154: loss 1.670470e+00, training_accuracy 0.5799999833106995, valid_acc: 0.06720927357673645\n",
      "Epoch 156: loss 1.627594e+00, training_accuracy 0.5938461422920227, valid_acc: 0.07029227167367935\n",
      "Epoch 158: loss 1.493360e+00, training_accuracy 0.629230797290802, valid_acc: 0.08151436597108841\n",
      "Epoch 160: loss 1.502634e+00, training_accuracy 0.6246153712272644, valid_acc: 0.07571833580732346\n",
      "Epoch 162: loss 1.482034e+00, training_accuracy 0.6284615397453308, valid_acc: 0.07201874256134033\n",
      "Epoch 164: loss 1.542229e+00, training_accuracy 0.607692301273346, valid_acc: 0.06930571049451828\n",
      "Epoch 166: loss 1.516804e+00, training_accuracy 0.6284615397453308, valid_acc: 0.07374522089958191\n",
      "Epoch 168: loss 1.433541e+00, training_accuracy 0.6392307877540588, valid_acc: 0.07584165781736374\n",
      "Epoch 170: loss 1.490069e+00, training_accuracy 0.6107692122459412, valid_acc: 0.07522506266832352\n",
      "Epoch 172: loss 1.435121e+00, training_accuracy 0.6415384411811829, valid_acc: 0.0784313753247261\n",
      "Epoch 174: loss 1.318819e+00, training_accuracy 0.6792307496070862, valid_acc: 0.08102108538150787\n",
      "Epoch 176: loss 1.216992e+00, training_accuracy 0.7184615135192871, valid_acc: 0.0870637595653534\n",
      "Epoch 178: loss 1.253579e+00, training_accuracy 0.7084615230560303, valid_acc: 0.08607719838619232\n",
      "Epoch 180: loss 1.509367e+00, training_accuracy 0.6100000143051147, valid_acc: 0.07016894966363907\n",
      "Epoch 182: loss 1.182534e+00, training_accuracy 0.7115384340286255, valid_acc: 0.08484400063753128\n",
      "Epoch 184: loss 1.094472e+00, training_accuracy 0.7476922869682312, valid_acc: 0.09150326997041702\n",
      "Epoch 186: loss 1.141804e+00, training_accuracy 0.7292307615280151, valid_acc: 0.0878036767244339\n",
      "Epoch 188: loss 1.162334e+00, training_accuracy 0.7061538696289062, valid_acc: 0.09273646771907806\n",
      "Epoch 190: loss 1.181356e+00, training_accuracy 0.7107692360877991, valid_acc: 0.08953015506267548\n",
      "Epoch 192: loss 1.083275e+00, training_accuracy 0.7484615445137024, valid_acc: 0.09150326997041702\n",
      "Epoch 194: loss 1.012336e+00, training_accuracy 0.7592307925224304, valid_acc: 0.09828585386276245\n",
      "Epoch 196: loss 1.015243e+00, training_accuracy 0.7615384459495544, valid_acc: 0.09273646771907806\n",
      "Epoch 198: loss 9.736270e-01, training_accuracy 0.7484615445137024, valid_acc: 0.09446294605731964\n",
      "Epoch 200: loss 1.007950e+00, training_accuracy 0.7599999904632568, valid_acc: 0.09384634345769882\n",
      "Epoch 202: loss 8.896346e-01, training_accuracy 0.7923076748847961, valid_acc: 0.09828585386276245\n",
      "Epoch 204: loss 8.854908e-01, training_accuracy 0.7792307734489441, valid_acc: 0.10062893480062485\n",
      "Epoch 206: loss 9.016894e-01, training_accuracy 0.7692307829856873, valid_acc: 0.1017388105392456\n",
      "Epoch 208: loss 8.548083e-01, training_accuracy 0.8046153783798218, valid_acc: 0.1009988933801651\n",
      "Epoch 210: loss 8.227616e-01, training_accuracy 0.8030769228935242, valid_acc: 0.10358860343694687\n",
      "Epoch 212: loss 7.980348e-01, training_accuracy 0.8084615468978882, valid_acc: 0.10691823810338974\n",
      "Epoch 214: loss 8.604496e-01, training_accuracy 0.7992307543754578, valid_acc: 0.10136885195970535\n",
      "Epoch 216: loss 8.782272e-01, training_accuracy 0.7846153974533081, valid_acc: 0.10075224936008453\n",
      "Epoch 218: loss 8.307714e-01, training_accuracy 0.7976922988891602, valid_acc: 0.100258968770504\n",
      "Epoch 220: loss 8.067887e-01, training_accuracy 0.8230769038200378, valid_acc: 0.10346528887748718\n",
      "Epoch 222: loss 7.947989e-01, training_accuracy 0.805384635925293, valid_acc: 0.10321864485740662\n",
      "Epoch 224: loss 7.093053e-01, training_accuracy 0.8346154093742371, valid_acc: 0.10580836236476898\n",
      "Epoch 226: loss 6.176371e-01, training_accuracy 0.8753846287727356, valid_acc: 0.10889135301113129\n",
      "Epoch 228: loss 5.886095e-01, training_accuracy 0.870769202709198, valid_acc: 0.11505734175443649\n",
      "Epoch 230: loss 5.643080e-01, training_accuracy 0.879230797290802, valid_acc: 0.11197435110807419\n",
      "Epoch 232: loss 6.361101e-01, training_accuracy 0.8676922917366028, valid_acc: 0.11061783134937286\n",
      "Epoch 234: loss 6.364092e-01, training_accuracy 0.8515384793281555, valid_acc: 0.10926131904125214\n",
      "Epoch 236: loss 5.872583e-01, training_accuracy 0.8776922821998596, valid_acc: 0.11296090483665466\n",
      "Epoch 238: loss 5.703055e-01, training_accuracy 0.8784615397453308, valid_acc: 0.11123443394899368\n",
      "Epoch 240: loss 5.195998e-01, training_accuracy 0.892307698726654, valid_acc: 0.11333087086677551\n",
      "Epoch 242: loss 5.593219e-01, training_accuracy 0.8753846287727356, valid_acc: 0.1118510290980339\n",
      "Epoch 244: loss 5.275413e-01, training_accuracy 0.879230797290802, valid_acc: 0.1127142682671547\n",
      "Epoch 246: loss 5.523750e-01, training_accuracy 0.879230797290802, valid_acc: 0.11394746601581573\n",
      "Epoch 248: loss 7.933183e-01, training_accuracy 0.7976922988891602, valid_acc: 0.10432852804660797\n",
      "Epoch 250: loss 6.254057e-01, training_accuracy 0.8561538457870483, valid_acc: 0.1111111119389534\n",
      "Epoch 252: loss 5.181342e-01, training_accuracy 0.8861538171768188, valid_acc: 0.11197435110807419\n",
      "Epoch 254: loss 5.073992e-01, training_accuracy 0.8769230842590332, valid_acc: 0.11505734175443649\n",
      "Epoch 256: loss 5.067943e-01, training_accuracy 0.8861538171768188, valid_acc: 0.11592058092355728\n",
      "Epoch 258: loss 4.634452e-01, training_accuracy 0.9061538577079773, valid_acc: 0.11678382009267807\n",
      "Epoch 260: loss 4.157792e-01, training_accuracy 0.9023076891899109, valid_acc: 0.11838697642087936\n",
      "Epoch 262: loss 4.142916e-01, training_accuracy 0.9169231057167053, valid_acc: 0.11801701784133911\n",
      "Epoch 264: loss 4.234037e-01, training_accuracy 0.9100000262260437, valid_acc: 0.1188802570104599\n",
      "Epoch 266: loss 4.467723e-01, training_accuracy 0.8969230651855469, valid_acc: 0.11752373725175858\n",
      "Epoch 268: loss 4.110962e-01, training_accuracy 0.9115384817123413, valid_acc: 0.11567394435405731\n",
      "Epoch 270: loss 4.284844e-01, training_accuracy 0.9023076891899109, valid_acc: 0.11715377867221832\n",
      "Epoch 272: loss 4.104250e-01, training_accuracy 0.9084615111351013, valid_acc: 0.11999013274908066\n",
      "Epoch 274: loss 3.723338e-01, training_accuracy 0.9192307591438293, valid_acc: 0.11925021559000015\n",
      "Epoch 276: loss 3.298260e-01, training_accuracy 0.9361538290977478, valid_acc: 0.12073005735874176\n",
      "Epoch 278: loss 3.389106e-01, training_accuracy 0.9230769276618958, valid_acc: 0.1219632551074028\n",
      "Epoch 280: loss 3.320956e-01, training_accuracy 0.9292307496070862, valid_acc: 0.12171661108732224\n",
      "Epoch 282: loss 3.208870e-01, training_accuracy 0.9284615516662598, valid_acc: 0.12257985025644302\n",
      "Epoch 284: loss 3.143719e-01, training_accuracy 0.9253846406936646, valid_acc: 0.12183993309736252\n",
      "Epoch 286: loss 3.250371e-01, training_accuracy 0.9323077201843262, valid_acc: 0.12110001593828201\n",
      "Epoch 288: loss 3.475236e-01, training_accuracy 0.920769214630127, valid_acc: 0.12110001593828201\n",
      "Epoch 290: loss 3.091793e-01, training_accuracy 0.9392307996749878, valid_acc: 0.12220989167690277\n",
      "Epoch 292: loss 3.181840e-01, training_accuracy 0.9330769181251526, valid_acc: 0.12368972599506378\n",
      "Epoch 294: loss 2.927658e-01, training_accuracy 0.9399999976158142, valid_acc: 0.12208656966686249\n",
      "Epoch 296: loss 2.918378e-01, training_accuracy 0.936923086643219, valid_acc: 0.12368972599506378\n",
      "Epoch 298: loss 3.022569e-01, training_accuracy 0.9330769181251526, valid_acc: 0.1235664114356041\n",
      "Epoch 300: loss 3.043215e-01, training_accuracy 0.9307692050933838, valid_acc: 0.12368972599506378\n",
      "Epoch 302: loss 3.151614e-01, training_accuracy 0.9215384721755981, valid_acc: 0.12405968457460403\n",
      "Epoch 304: loss 3.166908e-01, training_accuracy 0.926153838634491, valid_acc: 0.1219632551074028\n",
      "Epoch 306: loss 2.754117e-01, training_accuracy 0.936923086643219, valid_acc: 0.12319645285606384\n",
      "Epoch 308: loss 2.637062e-01, training_accuracy 0.9438461661338806, valid_acc: 0.12368972599506378\n",
      "Epoch 310: loss 2.523780e-01, training_accuracy 0.949999988079071, valid_acc: 0.12627944350242615\n",
      "Epoch 312: loss 2.784916e-01, training_accuracy 0.9461538195610046, valid_acc: 0.1235664114356041\n",
      "Epoch 314: loss 2.614211e-01, training_accuracy 0.942307710647583, valid_acc: 0.12541620433330536\n",
      "Epoch 316: loss 2.636900e-01, training_accuracy 0.947692334651947, valid_acc: 0.1243063285946846\n",
      "Epoch 318: loss 2.481964e-01, training_accuracy 0.947692334651947, valid_acc: 0.12615612149238586\n",
      "Epoch 320: loss 2.407447e-01, training_accuracy 0.949999988079071, valid_acc: 0.12529288232326508\n",
      "Epoch 322: loss 2.337893e-01, training_accuracy 0.947692334651947, valid_acc: 0.12553952634334564\n",
      "Epoch 324: loss 2.425724e-01, training_accuracy 0.947692334651947, valid_acc: 0.1275126338005066\n",
      "Epoch 326: loss 2.211250e-01, training_accuracy 0.9546154141426086, valid_acc: 0.12442965060472488\n",
      "Epoch 328: loss 2.234507e-01, training_accuracy 0.9515384435653687, valid_acc: 0.1265260875225067\n",
      "Epoch 330: loss 2.306076e-01, training_accuracy 0.9484615325927734, valid_acc: 0.12344308942556381\n",
      "Epoch 332: loss 2.372089e-01, training_accuracy 0.9376922845840454, valid_acc: 0.12492292374372482\n",
      "Epoch 334: loss 2.345746e-01, training_accuracy 0.9438461661338806, valid_acc: 0.1265260875225067\n",
      "Epoch 336: loss 2.001883e-01, training_accuracy 0.9592307806015015, valid_acc: 0.12603279948234558\n",
      "Epoch 338: loss 2.228008e-01, training_accuracy 0.9584615230560303, valid_acc: 0.12603279948234558\n",
      "Epoch 340: loss 1.913314e-01, training_accuracy 0.9592307806015015, valid_acc: 0.12763595581054688\n",
      "Epoch 342: loss 1.857416e-01, training_accuracy 0.9576923251152039, valid_acc: 0.1282525658607483\n",
      "Epoch 344: loss 1.892536e-01, training_accuracy 0.9615384340286255, valid_acc: 0.12714268267154694\n",
      "Epoch 346: loss 2.084072e-01, training_accuracy 0.9584615230560303, valid_acc: 0.1273893266916275\n",
      "Epoch 348: loss 2.022664e-01, training_accuracy 0.949999988079071, valid_acc: 0.12948575615882874\n",
      "Epoch 350: loss 2.311242e-01, training_accuracy 0.944615364074707, valid_acc: 0.1267727166414261\n",
      "Epoch 352: loss 1.859051e-01, training_accuracy 0.9576923251152039, valid_acc: 0.12479960918426514\n",
      "Epoch 354: loss 1.781846e-01, training_accuracy 0.9646154046058655, valid_acc: 0.12862251698970795\n",
      "Epoch 356: loss 2.104211e-01, training_accuracy 0.9484615325927734, valid_acc: 0.12911580502986908\n",
      "Epoch 358: loss 1.796585e-01, training_accuracy 0.9638461470603943, valid_acc: 0.12874583899974823\n",
      "Epoch 360: loss 1.717913e-01, training_accuracy 0.9599999785423279, valid_acc: 0.12948575615882874\n",
      "Epoch 362: loss 1.699230e-01, training_accuracy 0.9646154046058655, valid_acc: 0.12689603865146637\n",
      "Epoch 364: loss 1.744581e-01, training_accuracy 0.9592307806015015, valid_acc: 0.12788259983062744\n",
      "Epoch 366: loss 1.871790e-01, training_accuracy 0.9515384435653687, valid_acc: 0.12985572218894958\n",
      "Epoch 368: loss 1.694800e-01, training_accuracy 0.9707692265510559, valid_acc: 0.13022567331790924\n",
      "Epoch 370: loss 1.532874e-01, training_accuracy 0.9661538600921631, valid_acc: 0.1297324001789093\n",
      "Epoch 372: loss 1.506360e-01, training_accuracy 0.9684615135192871, valid_acc: 0.12701936066150665\n",
      "Epoch 374: loss 1.704613e-01, training_accuracy 0.9599999785423279, valid_acc: 0.13145887851715088\n",
      "Epoch 376: loss 1.556827e-01, training_accuracy 0.9676923155784607, valid_acc: 0.12923911213874817\n",
      "Epoch 378: loss 1.564880e-01, training_accuracy 0.9646154046058655, valid_acc: 0.1288691610097885\n",
      "Epoch 380: loss 1.563526e-01, training_accuracy 0.9630769491195679, valid_acc: 0.12948575615882874\n",
      "Epoch 382: loss 1.379273e-01, training_accuracy 0.9653846025466919, valid_acc: 0.12714268267154694\n",
      "Epoch 384: loss 1.382267e-01, training_accuracy 0.9715384840965271, valid_acc: 0.13108891248703003\n",
      "Epoch 386: loss 1.489157e-01, training_accuracy 0.9676923155784607, valid_acc: 0.12640276551246643\n",
      "Epoch 388: loss 1.694537e-01, training_accuracy 0.9592307806015015, valid_acc: 0.12788259983062744\n",
      "Epoch 390: loss 1.432322e-01, training_accuracy 0.9700000286102295, valid_acc: 0.12862251698970795\n",
      "Epoch 392: loss 1.473278e-01, training_accuracy 0.9692307710647583, valid_acc: 0.1297324001789093\n",
      "Epoch 394: loss 1.505911e-01, training_accuracy 0.9684615135192871, valid_acc: 0.13022567331790924\n",
      "Epoch 396: loss 1.576215e-01, training_accuracy 0.9630769491195679, valid_acc: 0.1305956393480301\n",
      "Epoch 398: loss 1.302018e-01, training_accuracy 0.9723076820373535, valid_acc: 0.1282525658607483\n",
      "Epoch 400: loss 1.486411e-01, training_accuracy 0.9692307710647583, valid_acc: 0.1304723173379898\n",
      "Epoch 402: loss 1.408331e-01, training_accuracy 0.9707692265510559, valid_acc: 0.13034899532794952\n",
      "Epoch 404: loss 1.505869e-01, training_accuracy 0.9630769491195679, valid_acc: 0.12948575615882874\n",
      "Epoch 406: loss 1.372328e-01, training_accuracy 0.9623076915740967, valid_acc: 0.12862251698970795\n",
      "Epoch 408: loss 1.357814e-01, training_accuracy 0.9700000286102295, valid_acc: 0.12800592184066772\n",
      "Epoch 410: loss 1.278943e-01, training_accuracy 0.9730769395828247, valid_acc: 0.1289924830198288\n",
      "Epoch 412: loss 1.381642e-01, training_accuracy 0.9676923155784607, valid_acc: 0.13145887851715088\n",
      "Epoch 414: loss 1.104242e-01, training_accuracy 0.9776923060417175, valid_acc: 0.1312122344970703\n",
      "Epoch 416: loss 1.362928e-01, training_accuracy 0.9715384840965271, valid_acc: 0.1297324001789093\n",
      "Epoch 418: loss 1.303708e-01, training_accuracy 0.9661538600921631, valid_acc: 0.12985572218894958\n",
      "Epoch 420: loss 1.359063e-01, training_accuracy 0.9638461470603943, valid_acc: 0.13084226846694946\n",
      "Epoch 422: loss 1.368012e-01, training_accuracy 0.9669230580329895, valid_acc: 0.1288691610097885\n",
      "Epoch 424: loss 1.371351e-01, training_accuracy 0.9692307710647583, valid_acc: 0.1304723173379898\n",
      "Epoch 426: loss 1.145185e-01, training_accuracy 0.9776923060417175, valid_acc: 0.1304723173379898\n",
      "Epoch 428: loss 1.254939e-01, training_accuracy 0.9730769395828247, valid_acc: 0.13096559047698975\n",
      "Epoch 430: loss 1.195930e-01, training_accuracy 0.9723076820373535, valid_acc: 0.13330866396427155\n",
      "Epoch 432: loss 1.146704e-01, training_accuracy 0.9769230484962463, valid_acc: 0.13096559047698975\n",
      "Epoch 434: loss 1.301332e-01, training_accuracy 0.9730769395828247, valid_acc: 0.13022567331790924\n",
      "Epoch 436: loss 1.099468e-01, training_accuracy 0.9769230484962463, valid_acc: 0.13158220052719116\n",
      "Epoch 438: loss 9.269045e-02, training_accuracy 0.9776923060417175, valid_acc: 0.13182882964611053\n",
      "Epoch 440: loss 9.310247e-02, training_accuracy 0.9800000190734863, valid_acc: 0.13071896135807037\n",
      "Epoch 442: loss 1.012157e-01, training_accuracy 0.9792307615280151, valid_acc: 0.13330866396427155\n",
      "Epoch 444: loss 1.257302e-01, training_accuracy 0.9715384840965271, valid_acc: 0.13269206881523132\n",
      "Epoch 446: loss 1.124158e-01, training_accuracy 0.9776923060417175, valid_acc: 0.13084226846694946\n",
      "Epoch 448: loss 1.128340e-01, training_accuracy 0.9738461375236511, valid_acc: 0.13219879567623138\n",
      "Epoch 450: loss 9.591199e-02, training_accuracy 0.9784615635871887, valid_acc: 0.13232211768627167\n",
      "Epoch 452: loss 1.240411e-01, training_accuracy 0.9738461375236511, valid_acc: 0.13158220052719116\n",
      "Epoch 454: loss 1.230548e-01, training_accuracy 0.9669230580329895, valid_acc: 0.12948575615882874\n",
      "Epoch 456: loss 1.198448e-01, training_accuracy 0.9746153950691223, valid_acc: 0.13071896135807037\n",
      "Epoch 458: loss 1.059927e-01, training_accuracy 0.9746153950691223, valid_acc: 0.13071896135807037\n",
      "Epoch 460: loss 1.029815e-01, training_accuracy 0.9730769395828247, valid_acc: 0.13219879567623138\n",
      "Epoch 462: loss 7.251246e-02, training_accuracy 0.9861538410186768, valid_acc: 0.13256874680519104\n",
      "Epoch 464: loss 8.665929e-02, training_accuracy 0.9815384745597839, valid_acc: 0.13256874680519104\n",
      "Epoch 466: loss 1.081239e-01, training_accuracy 0.9723076820373535, valid_acc: 0.13256874680519104\n",
      "Epoch 468: loss 1.145604e-01, training_accuracy 0.9730769395828247, valid_acc: 0.13182882964611053\n",
      "Epoch 470: loss 8.666863e-02, training_accuracy 0.9853846430778503, valid_acc: 0.1328153908252716\n",
      "Epoch 472: loss 7.733432e-02, training_accuracy 0.9823076725006104, valid_acc: 0.13195215165615082\n",
      "Epoch 474: loss 9.132217e-02, training_accuracy 0.9792307615280151, valid_acc: 0.13232211768627167\n",
      "Epoch 476: loss 9.298009e-02, training_accuracy 0.9815384745597839, valid_acc: 0.1312122344970703\n",
      "Epoch 478: loss 1.030713e-01, training_accuracy 0.9784615635871887, valid_acc: 0.1329387128353119\n",
      "Epoch 480: loss 9.244638e-02, training_accuracy 0.9761538505554199, valid_acc: 0.13195215165615082\n",
      "Epoch 482: loss 7.910983e-02, training_accuracy 0.9846153855323792, valid_acc: 0.13306203484535217\n",
      "Epoch 484: loss 1.018209e-01, training_accuracy 0.9807692170143127, valid_acc: 0.13158220052719116\n",
      "Epoch 486: loss 1.002631e-01, training_accuracy 0.9792307615280151, valid_acc: 0.13306203484535217\n",
      "Epoch 488: loss 9.603111e-02, training_accuracy 0.9776923060417175, valid_acc: 0.1336786299943924\n",
      "Epoch 490: loss 7.884948e-02, training_accuracy 0.9853846430778503, valid_acc: 0.13170550763607025\n",
      "Epoch 492: loss 8.155189e-02, training_accuracy 0.9815384745597839, valid_acc: 0.13269206881523132\n",
      "Epoch 494: loss 8.764978e-02, training_accuracy 0.9815384745597839, valid_acc: 0.13343198597431183\n",
      "Epoch 496: loss 7.588682e-02, training_accuracy 0.9853846430778503, valid_acc: 0.13219879567623138\n",
      "Epoch 498: loss 8.035289e-02, training_accuracy 0.9830769300460815, valid_acc: 0.13343198597431183\n",
      "Epoch 500: loss 7.625667e-02, training_accuracy 0.983846127986908, valid_acc: 0.1335553079843521\n",
      "Epoch 502: loss 7.387108e-02, training_accuracy 0.9823076725006104, valid_acc: 0.13404859602451324\n",
      "Epoch 504: loss 7.055235e-02, training_accuracy 0.9861538410186768, valid_acc: 0.13540510833263397\n",
      "Epoch 506: loss 9.067140e-02, training_accuracy 0.9776923060417175, valid_acc: 0.13392527401447296\n",
      "Epoch 508: loss 6.141321e-02, training_accuracy 0.989230751991272, valid_acc: 0.1336786299943924\n",
      "Epoch 510: loss 8.230962e-02, training_accuracy 0.9784615635871887, valid_acc: 0.13466519117355347\n",
      "Epoch 512: loss 8.287492e-02, training_accuracy 0.9800000190734863, valid_acc: 0.1336786299943924\n",
      "Epoch 514: loss 7.347219e-02, training_accuracy 0.9846153855323792, valid_acc: 0.13429522514343262\n",
      "Epoch 516: loss 7.425068e-02, training_accuracy 0.9861538410186768, valid_acc: 0.1328153908252716\n",
      "Epoch 518: loss 8.090444e-02, training_accuracy 0.9823076725006104, valid_acc: 0.13330866396427155\n",
      "Epoch 520: loss 6.544092e-02, training_accuracy 0.9884615540504456, valid_acc: 0.13343198597431183\n",
      "Epoch 522: loss 5.760483e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13466519117355347\n",
      "Epoch 524: loss 6.335048e-02, training_accuracy 0.9861538410186768, valid_acc: 0.13195215165615082\n",
      "Epoch 526: loss 7.989471e-02, training_accuracy 0.9823076725006104, valid_acc: 0.13256874680519104\n",
      "Epoch 528: loss 9.070887e-02, training_accuracy 0.9753845930099487, valid_acc: 0.13417190313339233\n",
      "Epoch 530: loss 6.696069e-02, training_accuracy 0.9884615540504456, valid_acc: 0.1358983814716339\n",
      "Epoch 532: loss 7.799932e-02, training_accuracy 0.9846153855323792, valid_acc: 0.13380195200443268\n",
      "Epoch 534: loss 6.836715e-02, training_accuracy 0.986923098564148, valid_acc: 0.1344185471534729\n",
      "Epoch 536: loss 6.126926e-02, training_accuracy 0.986923098564148, valid_acc: 0.13404859602451324\n",
      "Epoch 538: loss 8.802559e-02, training_accuracy 0.9830769300460815, valid_acc: 0.13244542479515076\n",
      "Epoch 540: loss 9.455176e-02, training_accuracy 0.9807692170143127, valid_acc: 0.13318535685539246\n",
      "Epoch 542: loss 7.170758e-02, training_accuracy 0.9830769300460815, valid_acc: 0.1335553079843521\n",
      "Epoch 544: loss 8.695853e-02, training_accuracy 0.9807692170143127, valid_acc: 0.13244542479515076\n",
      "Epoch 546: loss 8.726788e-02, training_accuracy 0.9776923060417175, valid_acc: 0.1320754736661911\n",
      "Epoch 548: loss 6.423194e-02, training_accuracy 0.9884615540504456, valid_acc: 0.13429522514343262\n",
      "Epoch 550: loss 7.137491e-02, training_accuracy 0.9846153855323792, valid_acc: 0.1344185471534729\n",
      "Epoch 552: loss 6.327306e-02, training_accuracy 0.9861538410186768, valid_acc: 0.1329387128353119\n",
      "Epoch 554: loss 5.292929e-02, training_accuracy 0.9876922965049744, valid_acc: 0.1336786299943924\n",
      "Epoch 556: loss 6.949542e-02, training_accuracy 0.983846127986908, valid_acc: 0.13404859602451324\n",
      "Epoch 558: loss 6.442476e-02, training_accuracy 0.983846127986908, valid_acc: 0.13392527401447296\n",
      "Epoch 560: loss 7.023827e-02, training_accuracy 0.9800000190734863, valid_acc: 0.1336786299943924\n",
      "Epoch 562: loss 6.631969e-02, training_accuracy 0.986923098564148, valid_acc: 0.13429522514343262\n",
      "Epoch 564: loss 6.536710e-02, training_accuracy 0.9853846430778503, valid_acc: 0.13318535685539246\n",
      "Epoch 566: loss 5.430761e-02, training_accuracy 0.992307722568512, valid_acc: 0.1351584643125534\n",
      "Epoch 568: loss 5.887627e-02, training_accuracy 0.989230751991272, valid_acc: 0.13417190313339233\n",
      "Epoch 570: loss 6.933438e-02, training_accuracy 0.9830769300460815, valid_acc: 0.1328153908252716\n",
      "Epoch 572: loss 6.849781e-02, training_accuracy 0.9823076725006104, valid_acc: 0.1336786299943924\n",
      "Epoch 574: loss 6.770880e-02, training_accuracy 0.9884615540504456, valid_acc: 0.13404859602451324\n",
      "Epoch 576: loss 5.220204e-02, training_accuracy 0.9884615540504456, valid_acc: 0.1328153908252716\n",
      "Epoch 578: loss 5.362010e-02, training_accuracy 0.9884615540504456, valid_acc: 0.13429522514343262\n",
      "Epoch 580: loss 6.581310e-02, training_accuracy 0.986923098564148, valid_acc: 0.1335553079843521\n",
      "Epoch 582: loss 5.819541e-02, training_accuracy 0.989230751991272, valid_acc: 0.13306203484535217\n",
      "Epoch 584: loss 5.290342e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13318535685539246\n",
      "Epoch 586: loss 5.465454e-02, training_accuracy 0.986923098564148, valid_acc: 0.13454186916351318\n",
      "Epoch 588: loss 5.052791e-02, training_accuracy 0.986923098564148, valid_acc: 0.1336786299943924\n",
      "Epoch 590: loss 7.207418e-02, training_accuracy 0.9846153855323792, valid_acc: 0.13429522514343262\n",
      "Epoch 592: loss 6.188700e-02, training_accuracy 0.986923098564148, valid_acc: 0.13503514230251312\n",
      "Epoch 594: loss 7.946939e-02, training_accuracy 0.9792307615280151, valid_acc: 0.1329387128353119\n",
      "Epoch 596: loss 5.574163e-02, training_accuracy 0.9846153855323792, valid_acc: 0.13478851318359375\n",
      "Epoch 598: loss 4.670040e-02, training_accuracy 0.9900000095367432, valid_acc: 0.13552843034267426\n",
      "Epoch 600: loss 4.455564e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13429522514343262\n",
      "Epoch 602: loss 5.085756e-02, training_accuracy 0.989230751991272, valid_acc: 0.13540510833263397\n",
      "Epoch 604: loss 5.152995e-02, training_accuracy 0.9876922965049744, valid_acc: 0.13417190313339233\n",
      "Epoch 606: loss 5.097749e-02, training_accuracy 0.989230751991272, valid_acc: 0.1360217034816742\n",
      "Epoch 608: loss 5.836851e-02, training_accuracy 0.9846153855323792, valid_acc: 0.13552843034267426\n",
      "Epoch 610: loss 5.327037e-02, training_accuracy 0.9861538410186768, valid_acc: 0.13478851318359375\n",
      "Epoch 612: loss 4.146254e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13454186916351318\n",
      "Epoch 614: loss 4.800999e-02, training_accuracy 0.9907692074775696, valid_acc: 0.13454186916351318\n",
      "Epoch 616: loss 5.513836e-02, training_accuracy 0.9861538410186768, valid_acc: 0.1352817863225937\n",
      "Epoch 618: loss 4.796419e-02, training_accuracy 0.989230751991272, valid_acc: 0.13552843034267426\n",
      "Epoch 620: loss 5.594597e-02, training_accuracy 0.9853846430778503, valid_acc: 0.13503514230251312\n",
      "Epoch 622: loss 5.282335e-02, training_accuracy 0.9853846430778503, valid_acc: 0.13503514230251312\n",
      "Epoch 624: loss 5.201554e-02, training_accuracy 0.9907692074775696, valid_acc: 0.13454186916351318\n",
      "Epoch 626: loss 5.419859e-02, training_accuracy 0.9876922965049744, valid_acc: 0.13454186916351318\n",
      "Epoch 628: loss 6.149538e-02, training_accuracy 0.989230751991272, valid_acc: 0.13404859602451324\n",
      "Epoch 630: loss 5.735158e-02, training_accuracy 0.9876922965049744, valid_acc: 0.13417190313339233\n",
      "Epoch 632: loss 4.581506e-02, training_accuracy 0.9900000095367432, valid_acc: 0.13540510833263397\n",
      "Epoch 634: loss 4.953378e-02, training_accuracy 0.9884615540504456, valid_acc: 0.1351584643125534\n",
      "Epoch 636: loss 5.682991e-02, training_accuracy 0.9900000095367432, valid_acc: 0.13503514230251312\n",
      "Epoch 638: loss 4.990703e-02, training_accuracy 0.9900000095367432, valid_acc: 0.13552843034267426\n",
      "Epoch 640: loss 4.405025e-02, training_accuracy 0.9900000095367432, valid_acc: 0.1351584643125534\n",
      "Epoch 642: loss 4.737291e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13478851318359375\n",
      "Epoch 644: loss 3.941577e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13478851318359375\n",
      "Epoch 646: loss 5.000599e-02, training_accuracy 0.9876922965049744, valid_acc: 0.13503514230251312\n",
      "Epoch 648: loss 5.028352e-02, training_accuracy 0.989230751991272, valid_acc: 0.13565175235271454\n",
      "Epoch 650: loss 4.703589e-02, training_accuracy 0.989230751991272, valid_acc: 0.1344185471534729\n",
      "Epoch 652: loss 5.750373e-02, training_accuracy 0.9884615540504456, valid_acc: 0.13404859602451324\n",
      "Epoch 654: loss 4.329721e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13552843034267426\n",
      "Epoch 656: loss 4.291318e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13417190313339233\n",
      "Epoch 658: loss 4.553891e-02, training_accuracy 0.9907692074775696, valid_acc: 0.13454186916351318\n",
      "Epoch 660: loss 4.020287e-02, training_accuracy 0.9907692074775696, valid_acc: 0.13552843034267426\n",
      "Epoch 662: loss 4.876495e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13503514230251312\n",
      "Epoch 664: loss 3.317412e-02, training_accuracy 0.994615375995636, valid_acc: 0.1352817863225937\n",
      "Epoch 666: loss 3.548717e-02, training_accuracy 0.992307722568512, valid_acc: 0.13478851318359375\n",
      "Epoch 668: loss 5.627031e-02, training_accuracy 0.9915384650230408, valid_acc: 0.1358983814716339\n",
      "Epoch 670: loss 3.811736e-02, training_accuracy 0.9907692074775696, valid_acc: 0.1358983814716339\n",
      "Epoch 672: loss 4.696990e-02, training_accuracy 0.9884615540504456, valid_acc: 0.13466519117355347\n",
      "Epoch 674: loss 5.048742e-02, training_accuracy 0.989230751991272, valid_acc: 0.13552843034267426\n",
      "Epoch 676: loss 4.535719e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13491182029247284\n",
      "Epoch 678: loss 4.542023e-02, training_accuracy 0.9884615540504456, valid_acc: 0.13491182029247284\n",
      "Epoch 680: loss 3.590037e-02, training_accuracy 0.992307722568512, valid_acc: 0.13552843034267426\n",
      "Epoch 682: loss 5.030681e-02, training_accuracy 0.9907692074775696, valid_acc: 0.1358983814716339\n",
      "Epoch 684: loss 4.214248e-02, training_accuracy 0.9930769205093384, valid_acc: 0.1352817863225937\n",
      "Epoch 686: loss 4.814845e-02, training_accuracy 0.989230751991272, valid_acc: 0.13491182029247284\n",
      "Epoch 688: loss 4.500045e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13503514230251312\n",
      "Epoch 690: loss 3.695516e-02, training_accuracy 0.9900000095367432, valid_acc: 0.13392527401447296\n",
      "Epoch 692: loss 4.493139e-02, training_accuracy 0.9900000095367432, valid_acc: 0.13565175235271454\n",
      "Epoch 694: loss 3.337486e-02, training_accuracy 0.994615375995636, valid_acc: 0.13552843034267426\n",
      "Epoch 696: loss 3.738314e-02, training_accuracy 0.992307722568512, valid_acc: 0.13454186916351318\n",
      "Epoch 698: loss 4.295389e-02, training_accuracy 0.989230751991272, valid_acc: 0.13429522514343262\n",
      "Epoch 700: loss 3.729481e-02, training_accuracy 0.992307722568512, valid_acc: 0.13626834750175476\n",
      "Epoch 702: loss 3.644648e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13454186916351318\n",
      "Epoch 704: loss 3.680093e-02, training_accuracy 0.9907692074775696, valid_acc: 0.13614502549171448\n",
      "Epoch 706: loss 4.480742e-02, training_accuracy 0.9900000095367432, valid_acc: 0.1344185471534729\n",
      "Epoch 708: loss 4.425839e-02, training_accuracy 0.989230751991272, valid_acc: 0.13626834750175476\n",
      "Epoch 710: loss 3.709925e-02, training_accuracy 0.992307722568512, valid_acc: 0.13639166951179504\n",
      "Epoch 712: loss 4.729696e-02, training_accuracy 0.989230751991272, valid_acc: 0.1351584643125534\n",
      "Epoch 714: loss 5.164807e-02, training_accuracy 0.983846127986908, valid_acc: 0.13577505946159363\n",
      "Epoch 716: loss 4.197758e-02, training_accuracy 0.989230751991272, valid_acc: 0.1344185471534729\n",
      "Epoch 718: loss 3.765575e-02, training_accuracy 0.992307722568512, valid_acc: 0.1352817863225937\n",
      "Epoch 720: loss 3.884511e-02, training_accuracy 0.992307722568512, valid_acc: 0.13503514230251312\n",
      "Epoch 722: loss 3.385234e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13565175235271454\n",
      "Epoch 724: loss 3.223111e-02, training_accuracy 0.9938461780548096, valid_acc: 0.1351584643125534\n",
      "Epoch 726: loss 3.087314e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13577505946159363\n",
      "Epoch 728: loss 3.172851e-02, training_accuracy 0.994615375995636, valid_acc: 0.13565175235271454\n",
      "Epoch 730: loss 3.900079e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13429522514343262\n",
      "Epoch 732: loss 3.374046e-02, training_accuracy 0.9915384650230408, valid_acc: 0.1351584643125534\n",
      "Epoch 734: loss 4.012312e-02, training_accuracy 0.9900000095367432, valid_acc: 0.13614502549171448\n",
      "Epoch 736: loss 3.691498e-02, training_accuracy 0.992307722568512, valid_acc: 0.1352817863225937\n",
      "Epoch 738: loss 4.248833e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13565175235271454\n",
      "Epoch 740: loss 3.203085e-02, training_accuracy 0.9961538314819336, valid_acc: 0.1358983814716339\n",
      "Epoch 742: loss 4.190647e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13540510833263397\n",
      "Epoch 744: loss 4.309591e-02, training_accuracy 0.989230751991272, valid_acc: 0.13614502549171448\n",
      "Epoch 746: loss 4.145652e-02, training_accuracy 0.986923098564148, valid_acc: 0.1351584643125534\n",
      "Epoch 748: loss 3.673951e-02, training_accuracy 0.9907692074775696, valid_acc: 0.13540510833263397\n",
      "Epoch 750: loss 2.692880e-02, training_accuracy 0.9969230890274048, valid_acc: 0.1352817863225937\n",
      "Epoch 752: loss 3.302550e-02, training_accuracy 0.992307722568512, valid_acc: 0.13552843034267426\n",
      "Epoch 754: loss 4.220729e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13614502549171448\n",
      "Epoch 756: loss 2.776898e-02, training_accuracy 0.994615375995636, valid_acc: 0.1360217034816742\n",
      "Epoch 758: loss 2.549046e-02, training_accuracy 0.994615375995636, valid_acc: 0.1367616206407547\n",
      "Epoch 760: loss 3.410003e-02, training_accuracy 0.9907692074775696, valid_acc: 0.13651499152183533\n",
      "Epoch 762: loss 2.970291e-02, training_accuracy 0.9915384650230408, valid_acc: 0.1360217034816742\n",
      "Epoch 764: loss 3.400777e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13491182029247284\n",
      "Epoch 766: loss 3.525557e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13503514230251312\n",
      "Epoch 768: loss 3.004411e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13688494265079498\n",
      "Epoch 770: loss 4.073456e-02, training_accuracy 0.994615375995636, valid_acc: 0.13663829863071442\n",
      "Epoch 772: loss 4.866405e-02, training_accuracy 0.9861538410186768, valid_acc: 0.13540510833263397\n",
      "Epoch 774: loss 3.168530e-02, training_accuracy 0.9961538314819336, valid_acc: 0.1367616206407547\n",
      "Epoch 776: loss 3.096357e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13688494265079498\n",
      "Epoch 778: loss 3.059666e-02, training_accuracy 0.994615375995636, valid_acc: 0.1358983814716339\n",
      "Epoch 780: loss 3.695970e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13614502549171448\n",
      "Epoch 782: loss 3.596453e-02, training_accuracy 0.992307722568512, valid_acc: 0.13565175235271454\n",
      "Epoch 784: loss 3.055621e-02, training_accuracy 0.9930769205093384, valid_acc: 0.1360217034816742\n",
      "Epoch 786: loss 3.417626e-02, training_accuracy 0.992307722568512, valid_acc: 0.13540510833263397\n",
      "Epoch 788: loss 3.009013e-02, training_accuracy 0.9938461780548096, valid_acc: 0.1360217034816742\n",
      "Epoch 790: loss 2.989295e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13614502549171448\n",
      "Epoch 792: loss 3.477870e-02, training_accuracy 0.994615375995636, valid_acc: 0.13540510833263397\n",
      "Epoch 794: loss 3.271491e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13466519117355347\n",
      "Epoch 796: loss 2.486437e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13466519117355347\n",
      "Epoch 798: loss 3.621340e-02, training_accuracy 0.9907692074775696, valid_acc: 0.13565175235271454\n",
      "Epoch 800: loss 3.412899e-02, training_accuracy 0.994615375995636, valid_acc: 0.13540510833263397\n",
      "Epoch 802: loss 3.166281e-02, training_accuracy 0.992307722568512, valid_acc: 0.13700826466083527\n",
      "Epoch 804: loss 3.472688e-02, training_accuracy 0.9930769205093384, valid_acc: 0.1358983814716339\n",
      "Epoch 806: loss 2.370843e-02, training_accuracy 0.9938461780548096, valid_acc: 0.1367616206407547\n",
      "Epoch 808: loss 3.068884e-02, training_accuracy 0.992307722568512, valid_acc: 0.13651499152183533\n",
      "Epoch 810: loss 2.592522e-02, training_accuracy 0.992307722568512, valid_acc: 0.1352817863225937\n",
      "Epoch 812: loss 3.332508e-02, training_accuracy 0.992307722568512, valid_acc: 0.13700826466083527\n",
      "Epoch 814: loss 2.185945e-02, training_accuracy 0.9961538314819336, valid_acc: 0.1358983814716339\n",
      "Epoch 816: loss 2.970724e-02, training_accuracy 0.9907692074775696, valid_acc: 0.13577505946159363\n",
      "Epoch 818: loss 2.714479e-02, training_accuracy 0.994615375995636, valid_acc: 0.13552843034267426\n",
      "Epoch 820: loss 2.447411e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13565175235271454\n",
      "Epoch 822: loss 2.476866e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13639166951179504\n",
      "Epoch 824: loss 2.448826e-02, training_accuracy 0.994615375995636, valid_acc: 0.1360217034816742\n",
      "Epoch 826: loss 2.796199e-02, training_accuracy 0.994615375995636, valid_acc: 0.13651499152183533\n",
      "Epoch 828: loss 2.365913e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13552843034267426\n",
      "Epoch 830: loss 3.149359e-02, training_accuracy 0.994615375995636, valid_acc: 0.13663829863071442\n",
      "Epoch 832: loss 2.482466e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13713158667087555\n",
      "Epoch 834: loss 3.360942e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13639166951179504\n",
      "Epoch 836: loss 2.249806e-02, training_accuracy 0.9938461780548096, valid_acc: 0.1367616206407547\n",
      "Epoch 838: loss 3.337217e-02, training_accuracy 0.992307722568512, valid_acc: 0.13565175235271454\n",
      "Epoch 840: loss 2.730458e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13540510833263397\n",
      "Epoch 842: loss 2.277827e-02, training_accuracy 0.994615375995636, valid_acc: 0.1360217034816742\n",
      "Epoch 844: loss 2.080823e-02, training_accuracy 0.9953846335411072, valid_acc: 0.1352817863225937\n",
      "Epoch 846: loss 2.246506e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13614502549171448\n",
      "Epoch 848: loss 2.758156e-02, training_accuracy 0.9907692074775696, valid_acc: 0.13565175235271454\n",
      "Epoch 850: loss 3.576034e-02, training_accuracy 0.9900000095367432, valid_acc: 0.1358983814716339\n",
      "Epoch 852: loss 2.712611e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13565175235271454\n",
      "Epoch 854: loss 2.634460e-02, training_accuracy 0.994615375995636, valid_acc: 0.13614502549171448\n",
      "Epoch 856: loss 2.321583e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13639166951179504\n",
      "Epoch 858: loss 2.793670e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13688494265079498\n",
      "Epoch 860: loss 2.758445e-02, training_accuracy 0.9953846335411072, valid_acc: 0.1351584643125534\n",
      "Epoch 862: loss 2.968350e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13503514230251312\n",
      "Epoch 864: loss 1.609542e-02, training_accuracy 0.9992307424545288, valid_acc: 0.13577505946159363\n",
      "Epoch 866: loss 2.910246e-02, training_accuracy 0.992307722568512, valid_acc: 0.1360217034816742\n",
      "Epoch 868: loss 2.535552e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13577505946159363\n",
      "Epoch 870: loss 3.133142e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13663829863071442\n",
      "Epoch 872: loss 2.552395e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13626834750175476\n",
      "Epoch 874: loss 3.035576e-02, training_accuracy 0.994615375995636, valid_acc: 0.13614502549171448\n",
      "Epoch 876: loss 3.318208e-02, training_accuracy 0.9915384650230408, valid_acc: 0.1367616206407547\n",
      "Epoch 878: loss 3.050439e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13503514230251312\n",
      "Epoch 880: loss 2.895401e-02, training_accuracy 0.994615375995636, valid_acc: 0.13663829863071442\n",
      "Epoch 882: loss 2.433648e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13577505946159363\n",
      "Epoch 884: loss 2.781512e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13577505946159363\n",
      "Epoch 886: loss 2.190941e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13614502549171448\n",
      "Epoch 888: loss 2.792030e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13614502549171448\n",
      "Epoch 890: loss 2.571992e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13565175235271454\n",
      "Epoch 892: loss 2.357131e-02, training_accuracy 0.9961538314819336, valid_acc: 0.1360217034816742\n",
      "Epoch 894: loss 2.718252e-02, training_accuracy 0.994615375995636, valid_acc: 0.1352817863225937\n",
      "Epoch 896: loss 2.723580e-02, training_accuracy 0.9961538314819336, valid_acc: 0.1360217034816742\n",
      "Epoch 898: loss 2.664633e-02, training_accuracy 0.994615375995636, valid_acc: 0.13626834750175476\n",
      "Epoch 900: loss 3.149422e-02, training_accuracy 0.992307722568512, valid_acc: 0.13651499152183533\n",
      "Epoch 902: loss 2.165412e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13626834750175476\n",
      "Epoch 904: loss 3.054389e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13688494265079498\n",
      "Epoch 906: loss 2.544244e-02, training_accuracy 0.994615375995636, valid_acc: 0.13737821578979492\n",
      "Epoch 908: loss 1.745516e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13614502549171448\n",
      "Epoch 910: loss 2.404212e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13651499152183533\n",
      "Epoch 912: loss 2.610609e-02, training_accuracy 0.9938461780548096, valid_acc: 0.1375015377998352\n",
      "Epoch 914: loss 3.656226e-02, training_accuracy 0.9907692074775696, valid_acc: 0.13614502549171448\n",
      "Epoch 916: loss 3.286043e-02, training_accuracy 0.992307722568512, valid_acc: 0.13663829863071442\n",
      "Epoch 918: loss 2.600599e-02, training_accuracy 0.9953846335411072, valid_acc: 0.1367616206407547\n",
      "Epoch 920: loss 2.661183e-02, training_accuracy 0.994615375995636, valid_acc: 0.13651499152183533\n",
      "Epoch 922: loss 2.685234e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13626834750175476\n",
      "Epoch 924: loss 3.417503e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13713158667087555\n",
      "Epoch 926: loss 1.960104e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13565175235271454\n",
      "Epoch 928: loss 2.075544e-02, training_accuracy 0.9976922869682312, valid_acc: 0.13614502549171448\n",
      "Epoch 930: loss 1.919978e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13552843034267426\n",
      "Epoch 932: loss 2.995678e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13651499152183533\n",
      "Epoch 934: loss 2.036974e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13614502549171448\n",
      "Epoch 936: loss 2.696572e-02, training_accuracy 0.994615375995636, valid_acc: 0.13626834750175476\n",
      "Epoch 938: loss 2.054065e-02, training_accuracy 0.994615375995636, valid_acc: 0.13663829863071442\n",
      "Epoch 940: loss 1.873147e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13663829863071442\n",
      "Epoch 942: loss 1.677611e-02, training_accuracy 0.9976922869682312, valid_acc: 0.13713158667087555\n",
      "Epoch 944: loss 1.773617e-02, training_accuracy 0.9976922869682312, valid_acc: 0.1358983814716339\n",
      "Epoch 946: loss 2.312746e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13552843034267426\n",
      "Epoch 948: loss 2.298964e-02, training_accuracy 0.9976922869682312, valid_acc: 0.13651499152183533\n",
      "Epoch 950: loss 1.321600e-02, training_accuracy 0.9992307424545288, valid_acc: 0.1358983814716339\n",
      "Epoch 952: loss 2.191757e-02, training_accuracy 0.9961538314819336, valid_acc: 0.1358983814716339\n",
      "Epoch 954: loss 2.518944e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13639166951179504\n",
      "Epoch 956: loss 2.433825e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13651499152183533\n",
      "Epoch 958: loss 2.197244e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13700826466083527\n",
      "Epoch 960: loss 2.152071e-02, training_accuracy 0.994615375995636, valid_acc: 0.13565175235271454\n",
      "Epoch 962: loss 2.508922e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13700826466083527\n",
      "Epoch 964: loss 2.803718e-02, training_accuracy 0.9915384650230408, valid_acc: 0.1358983814716339\n",
      "Epoch 966: loss 2.119132e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13639166951179504\n",
      "Epoch 968: loss 3.146798e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13713158667087555\n",
      "Epoch 970: loss 2.524493e-02, training_accuracy 0.9915384650230408, valid_acc: 0.13577505946159363\n",
      "Epoch 972: loss 1.767143e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13700826466083527\n",
      "Epoch 974: loss 2.334752e-02, training_accuracy 0.992307722568512, valid_acc: 0.13725490868091583\n",
      "Epoch 976: loss 1.460467e-02, training_accuracy 0.9992307424545288, valid_acc: 0.13651499152183533\n",
      "Epoch 978: loss 1.858772e-02, training_accuracy 0.9976922869682312, valid_acc: 0.1367616206407547\n",
      "Epoch 980: loss 2.113404e-02, training_accuracy 0.994615375995636, valid_acc: 0.13614502549171448\n",
      "Epoch 982: loss 1.863064e-02, training_accuracy 0.994615375995636, valid_acc: 0.1360217034816742\n",
      "Epoch 984: loss 1.532485e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13639166951179504\n",
      "Epoch 986: loss 1.788563e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13626834750175476\n",
      "Epoch 988: loss 2.500036e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13713158667087555\n",
      "Epoch 990: loss 1.561630e-02, training_accuracy 0.9961538314819336, valid_acc: 0.1367616206407547\n",
      "Epoch 992: loss 1.499317e-02, training_accuracy 0.9976922869682312, valid_acc: 0.1358983814716339\n",
      "Epoch 994: loss 1.934484e-02, training_accuracy 0.9976922869682312, valid_acc: 0.13639166951179504\n",
      "Epoch 996: loss 2.046124e-02, training_accuracy 0.9976922869682312, valid_acc: 0.13725490868091583\n",
      "Epoch 998: loss 1.862041e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13688494265079498\n",
      "Epoch 1000: loss 1.114933e-02, training_accuracy 0.9992307424545288, valid_acc: 0.13663829863071442\n",
      "Epoch 1002: loss 1.301551e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13688494265079498\n",
      "Epoch 1004: loss 1.773121e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13737821578979492\n",
      "Epoch 1006: loss 1.663647e-02, training_accuracy 0.9976922869682312, valid_acc: 0.1367616206407547\n",
      "Epoch 1008: loss 1.908979e-02, training_accuracy 0.9961538314819336, valid_acc: 0.1358983814716339\n",
      "Epoch 1010: loss 1.554475e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13614502549171448\n",
      "Epoch 1012: loss 1.851840e-02, training_accuracy 0.994615375995636, valid_acc: 0.13651499152183533\n",
      "Epoch 1014: loss 1.689342e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13639166951179504\n",
      "Epoch 1016: loss 2.018756e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13663829863071442\n",
      "Epoch 1018: loss 1.510305e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13737821578979492\n",
      "Epoch 1020: loss 2.007241e-02, training_accuracy 0.9953846335411072, valid_acc: 0.1367616206407547\n",
      "Epoch 1022: loss 1.606777e-02, training_accuracy 0.9984615445137024, valid_acc: 0.13663829863071442\n",
      "Epoch 1024: loss 1.935687e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13688494265079498\n",
      "Epoch 1026: loss 1.401990e-02, training_accuracy 0.9976922869682312, valid_acc: 0.13577505946159363\n",
      "Epoch 1028: loss 1.941434e-02, training_accuracy 0.994615375995636, valid_acc: 0.13725490868091583\n",
      "Epoch 1030: loss 2.273736e-02, training_accuracy 0.994615375995636, valid_acc: 0.13663829863071442\n",
      "Epoch 1032: loss 1.528830e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13639166951179504\n",
      "Epoch 1034: loss 2.026713e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13639166951179504\n",
      "Epoch 1036: loss 1.858776e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13639166951179504\n",
      "Epoch 1038: loss 1.711144e-02, training_accuracy 0.9961538314819336, valid_acc: 0.1360217034816742\n",
      "Epoch 1040: loss 1.774265e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13713158667087555\n",
      "Epoch 1042: loss 1.960456e-02, training_accuracy 0.994615375995636, valid_acc: 0.1367616206407547\n",
      "Epoch 1044: loss 1.425664e-02, training_accuracy 0.9976922869682312, valid_acc: 0.13651499152183533\n",
      "Epoch 1046: loss 2.415100e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13663829863071442\n",
      "Epoch 1048: loss 1.170834e-02, training_accuracy 0.9992307424545288, valid_acc: 0.13639166951179504\n",
      "Epoch 1050: loss 2.516100e-02, training_accuracy 0.9938461780548096, valid_acc: 0.1367616206407547\n",
      "Epoch 1052: loss 2.141276e-02, training_accuracy 0.994615375995636, valid_acc: 0.13639166951179504\n",
      "Epoch 1054: loss 2.991734e-02, training_accuracy 0.994615375995636, valid_acc: 0.13663829863071442\n",
      "Epoch 1056: loss 1.840962e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13577505946159363\n",
      "Epoch 1058: loss 1.885426e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13688494265079498\n",
      "Epoch 1060: loss 2.302613e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13651499152183533\n",
      "Epoch 1062: loss 2.423948e-02, training_accuracy 0.9953846335411072, valid_acc: 0.1360217034816742\n",
      "Epoch 1064: loss 1.259123e-02, training_accuracy 0.9984615445137024, valid_acc: 0.1360217034816742\n",
      "Epoch 1066: loss 2.118730e-02, training_accuracy 0.992307722568512, valid_acc: 0.13700826466083527\n",
      "Epoch 1068: loss 2.388230e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13688494265079498\n",
      "Epoch 1070: loss 1.651929e-02, training_accuracy 0.9961538314819336, valid_acc: 0.1360217034816742\n",
      "Epoch 1072: loss 1.631761e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13663829863071442\n",
      "Epoch 1074: loss 1.622036e-02, training_accuracy 0.9976922869682312, valid_acc: 0.1358983814716339\n",
      "Epoch 1076: loss 1.904669e-02, training_accuracy 0.9938461780548096, valid_acc: 0.1375015377998352\n",
      "Epoch 1078: loss 2.578975e-02, training_accuracy 0.992307722568512, valid_acc: 0.1360217034816742\n",
      "Epoch 1080: loss 1.938326e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13639166951179504\n",
      "Epoch 1082: loss 2.348946e-02, training_accuracy 0.994615375995636, valid_acc: 0.13688494265079498\n",
      "Epoch 1084: loss 1.760346e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13688494265079498\n",
      "Epoch 1086: loss 1.480861e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13577505946159363\n",
      "Epoch 1088: loss 1.537052e-02, training_accuracy 0.994615375995636, valid_acc: 0.13663829863071442\n",
      "Epoch 1090: loss 2.047084e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13713158667087555\n",
      "Epoch 1092: loss 1.065237e-02, training_accuracy 0.9984615445137024, valid_acc: 0.1367616206407547\n",
      "Epoch 1094: loss 1.968817e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13688494265079498\n",
      "Epoch 1096: loss 1.764430e-02, training_accuracy 0.9930769205093384, valid_acc: 0.13614502549171448\n",
      "Epoch 1098: loss 1.998887e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13552843034267426\n",
      "Epoch 1100: loss 1.695029e-02, training_accuracy 0.9976922869682312, valid_acc: 0.13688494265079498\n",
      "Epoch 1102: loss 1.542676e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13688494265079498\n",
      "Epoch 1104: loss 1.661707e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13688494265079498\n",
      "Epoch 1106: loss 1.429662e-02, training_accuracy 0.9976922869682312, valid_acc: 0.13639166951179504\n",
      "Epoch 1108: loss 1.625681e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13725490868091583\n",
      "Epoch 1110: loss 1.212728e-02, training_accuracy 0.9984615445137024, valid_acc: 0.1360217034816742\n",
      "Epoch 1112: loss 1.566667e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13725490868091583\n",
      "Epoch 1114: loss 1.436697e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13639166951179504\n",
      "Epoch 1116: loss 1.713477e-02, training_accuracy 0.994615375995636, valid_acc: 0.13663829863071442\n",
      "Epoch 1118: loss 1.354691e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13688494265079498\n",
      "Epoch 1120: loss 1.160686e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13614502549171448\n",
      "Epoch 1122: loss 1.651571e-02, training_accuracy 0.994615375995636, valid_acc: 0.13713158667087555\n",
      "Epoch 1124: loss 1.741427e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13663829863071442\n",
      "Epoch 1126: loss 2.143632e-02, training_accuracy 0.994615375995636, valid_acc: 0.13713158667087555\n",
      "Epoch 1128: loss 2.382650e-02, training_accuracy 0.992307722568512, valid_acc: 0.13639166951179504\n",
      "Epoch 1130: loss 1.400711e-02, training_accuracy 0.9984615445137024, valid_acc: 0.13737821578979492\n",
      "Epoch 1132: loss 2.562976e-02, training_accuracy 0.9938461780548096, valid_acc: 0.13626834750175476\n",
      "Epoch 1134: loss 2.071336e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13651499152183533\n",
      "Epoch 1136: loss 1.695508e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13663829863071442\n",
      "Epoch 1138: loss 1.183493e-02, training_accuracy 0.9976922869682312, valid_acc: 0.13713158667087555\n",
      "Epoch 1140: loss 1.467834e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13725490868091583\n",
      "Epoch 1142: loss 1.398830e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13725490868091583\n",
      "Epoch 1144: loss 1.334652e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13737821578979492\n",
      "Epoch 1146: loss 1.407574e-02, training_accuracy 0.9976922869682312, valid_acc: 0.13799482583999634\n",
      "Epoch 1148: loss 1.342888e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13725490868091583\n",
      "Epoch 1150: loss 2.313693e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13651499152183533\n",
      "Epoch 1152: loss 2.143006e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13700826466083527\n",
      "Epoch 1154: loss 1.584201e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13688494265079498\n",
      "Epoch 1156: loss 1.929524e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13725490868091583\n",
      "Epoch 1158: loss 1.599790e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13651499152183533\n",
      "Epoch 1160: loss 1.551959e-02, training_accuracy 0.9976922869682312, valid_acc: 0.13811814785003662\n",
      "Epoch 1162: loss 1.265446e-02, training_accuracy 0.9984615445137024, valid_acc: 0.13725490868091583\n",
      "Epoch 1164: loss 1.253675e-02, training_accuracy 0.9984615445137024, valid_acc: 0.1367616206407547\n",
      "Epoch 1166: loss 1.528361e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13725490868091583\n",
      "Epoch 1168: loss 1.166581e-02, training_accuracy 0.9976922869682312, valid_acc: 0.13688494265079498\n",
      "Epoch 1170: loss 1.817483e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13663829863071442\n",
      "Epoch 1172: loss 1.174201e-02, training_accuracy 1.0, valid_acc: 0.13713158667087555\n",
      "Epoch 1174: loss 1.133869e-02, training_accuracy 0.9976922869682312, valid_acc: 0.13688494265079498\n",
      "Epoch 1176: loss 1.116026e-02, training_accuracy 0.9984615445137024, valid_acc: 0.13614502549171448\n",
      "Epoch 1178: loss 1.956507e-02, training_accuracy 0.9961538314819336, valid_acc: 0.13614502549171448\n",
      "Epoch 1180: loss 1.706108e-02, training_accuracy 0.9953846335411072, valid_acc: 0.13725490868091583\n",
      "Epoch 1182: loss 1.903078e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13663829863071442\n",
      "Epoch 1184: loss 1.069912e-02, training_accuracy 0.9969230890274048, valid_acc: 0.13663829863071442\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f8f9834a3d0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mlabel_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mval_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {i}: loss {loss.item():e}, training_accuracy {acc}, valid_acc: {valid_acc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class TransformerSVD(torch.nn.Module):\n",
    "    def __init__(self, seq_length: int, num_embeddings: int, d_model: int, dim_feedforward: int = 2048):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_embeddings = num_embeddings\n",
    "        #self.embed = EmbeddingWithPE(\n",
    "        #    self.num_embeddings, self.d_model, seq_length)\n",
    "\n",
    "        decoder_layer = TransformerDecoderLayerSVD(self.d_model, nhead=4, dim_feedforward=dim_feedforward,\n",
    "                                        dropout=0.1, batch_first=True, norm_first=True)\n",
    "        decoder_norm = LayerNormSVD(self.d_model)\n",
    "\n",
    "        self.decoder = TransformerDecoderSVD(\n",
    "            decoder_layer, num_layers=2, norm=decoder_norm)\n",
    "        self.linear = LinearSVD(\n",
    "            self.d_model, self.num_embeddings, bias=False)\n",
    "        self.mask = Parameter(\n",
    "            torch.ones([seq_length, seq_length]).tril())\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        #x = self.embed(x)\n",
    "        x = self.decoder.forward(x, torch.zeros_like(x), self.mask)\n",
    "        return self.linear(x)\n",
    "\n",
    "    def acc(self, prediction: Tensor, labels: Tensor):\n",
    "        return (torch.argmax(prediction, dim=-2) == labels).float().mean()\n",
    "\n",
    "(train_x, train_y), (valid_x, valid_y) = gen_data(1300, P, device=DEVICE)\n",
    "\n",
    "def to_cat(x):\n",
    "    return F.one_hot(x, 128).float()\n",
    "\n",
    "\n",
    "s = setHouseOrthNHouseHolders(30) # lol I run out of memory\n",
    "exec(s) # insane still!!\n",
    "\n",
    "model = TransformerSVD(train_x.size(-1), P, 128).cuda()\n",
    "\n",
    "\n",
    "\n",
    "opt = getOptimizers(model)\n",
    "train_x = to_cat(train_x)\n",
    "valid_x = to_cat(valid_x)\n",
    "losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for i in range(15_000):\n",
    "    opt[0].zero_grad()\n",
    "    opt[1].zero_grad()\n",
    "    output = model.forward(train_x)\n",
    "    pred = output.transpose(-2, -1)\n",
    "    pred = pred[..., -1:] \n",
    "    label = train_y[:, -1:]\n",
    "\n",
    "    loss = F.cross_entropy(pred, label)\n",
    "    losses.append(loss.item())\n",
    "    acc = model.acc(pred, label)\n",
    "    train_accs.append(acc.item())\n",
    "    with torch.no_grad():\n",
    "        pred_valid = model.forward(valid_x).transpose(-2, -1)[..., -1:]\n",
    "        label_valid = valid_y[:, -1:]\n",
    "        valid_acc = model.acc(pred_valid, label_valid)\n",
    "        val_accs.append(valid_acc.item())\n",
    "    if i % 2 == 0:\n",
    "            print(f\"Epoch {i}: loss {loss.item():e}, training_accuracy {acc}, valid_acc: {valid_acc}\")\n",
    "    loss.backward()\n",
    "    opt[0].step()\n",
    "    opt[1].step()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trained with singular values normed to sqrt(N) for 500 epochs, n_householders=30, ntraining=1,000\n",
    "* It can learn!\n",
    "    * Implementation probably correct\n",
    "* It isn't grokking better\n",
    "* Note: this is from a saved model trained on these parameters, the model is 10GB in size\n",
    "    * Therefore I do not want to \"load\" it or upload it, it will crash so you'll just have to believe us here\n",
    "    * We wouldn't lie about such dissapointing results\n",
    "    * We stopped very early in trainaing because it just takes so long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa1c43205b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = np.arange(len(losses)-1)\n",
    "ax.plot(x, train_accs[:-1], label=\"train acc\")\n",
    "ax.plot(x, val_accs, label=\"test acc\")\n",
    "ax.plot(x, losses[:-1], label = \"losses\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff41d70c9a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = np.arange(len(losses))\n",
    "ax.plot(x, train_accs, label=\"train acc\")\n",
    "ax.plot(x[:-1], val_accs, label=\"test acc\")\n",
    "ax.plot(x, losses, label = \"losses\")\n",
    "ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "#### Bad singular value enforcement\n",
    "* I'll space you the the graph but singular values normed to 1 could not learn\n",
    "* We instead force to sqrt(N) where N is the size of the first householder matrix\n",
    "    * This was learnable, but not small enough to force grokking\n",
    "* In theory their could be a smarter way to enforce singular value rules\n",
    "\n",
    "#### Slowness\n",
    "* Treating every weight matrix as a product of orthognal matrices makes the model incredibly slow\n",
    "    * Even if it was to work without huge improvements to the implementation it isn't reasonable\n",
    "    * fasth the library mentioned earlier does implement it fairly well but it would cause even more memory issues\n",
    "\n",
    "#### Theoretical understandings\n",
    "* We can still learn mnist under strict rules on the singular values\n",
    "* You do need a descent number of householder matrices such that you can learn any task\n",
    "* It is hard to have good initialization values when the matrices are repersented by householder matrices\n",
    "* More work can be put into better understanding good singular value rules to enforce such that you can force generalization - we still fundamentally believe in the idea\n",
    "\n",
    "#### Further work\n",
    "* The code should serve as a good basis for future work\n",
    "* LinearSVD should probably take the norm value for the singular values\n",
    "* Theoretically you could train a model to quicky overfit and then do a decomposition on the weights and train from their - this would be good for speed\n",
    "\n",
    "#### Hypothesis testing\n",
    "* Unfortunately results were never good enough to do a statistical test on - you would have to see improvement for that to make sense and the runtime just doesn't make that tenanble\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('cmsc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84632eeb22439882512e471b7249f8dc904dd5464b6101158ce571edabf38baa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
